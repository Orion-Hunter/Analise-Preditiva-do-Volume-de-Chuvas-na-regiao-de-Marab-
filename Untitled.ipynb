{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5cc43eec-d9da-4e86-b38d-6230e60c8012",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import stats as st\n",
    "#import autosklearn.classification as aml\n",
    "#from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import classification_report, accuracy_score, plot_confusion_matrix, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ada532e6-d4dc-4a5b-925f-c553af0c4893",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gmdhpy.gmdh import MultilayerGMDH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d4c692d0-d8c9-4424-9dce-3dbe971fd539",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_fit_test_data(data, normalize = True):\n",
    "    X = data.drop(columns=['PRM1', 'PRM2', 'PRM3', 'PRM4', 'PRM5', 'PRM6', 'PRM7','PRM8', 'PRM9', 'PRM10', 'PRM11', 'PRM12', 'PRM13', 'PRM14', 'PRM15',\n",
    "                           'PRM16', 'PRM17', 'PRM18', 'PRM19', 'PRM20', 'PRM21', 'PRM22', 'PRM23','PRM24'])\n",
    "    y = data['PRM1']\n",
    "        #['PRM1', 'PRM2', 'PRM3', 'PRM4', 'PRM5', 'PRM6', 'PRM7','PRM8', 'PRM9', 'PRM10', 'PRM11', 'PRM12', 'PRM13', 'PRM14', 'PRM15',\n",
    "         #                  'PRM16', 'PRM17', 'PRM18', 'PRM19', 'PRM20', 'PRM21', 'PRM22', 'PRM23','PRM24']]\n",
    "    \n",
    "    if normalize:\n",
    "        scaler = MinMaxScaler()\n",
    "        scaler.fit(X)\n",
    "        X = scaler.transform(X)\n",
    "        scaler.fit(y)\n",
    "        y = scaler.transform([y])\n",
    "    else:\n",
    "        \n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=42) \n",
    "    \n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fb8e6b0d-5a47-470c-a570-78aa8bc1ee20",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_fit_test_data(data, normalize = True):\n",
    "    \n",
    "        #['PRM1', 'PRM2', 'PRM3', 'PRM4', 'PRM5', 'PRM6', 'PRM7','PRM8', 'PRM9', 'PRM10', 'PRM11', 'PRM12', 'PRM13', 'PRM14', 'PRM15',\n",
    "        #                   'PRM16', 'PRM17', 'PRM18', 'PRM19', 'PRM20', 'PRM21', 'PRM22', 'PRM23','PRM24']\n",
    "    if normalize:\n",
    "        scaler = MinMaxScaler()\n",
    "        scaler.fit(data)\n",
    "        data = scaler.transform(data)\n",
    "        #X = scaler.transform(X)\n",
    "        #scaler.fit([y])\n",
    "        #y = scaler.transform([y])\n",
    "        df = pd.DataFrame(data)\n",
    "        X = df.drop(columns=[df.columns[len(df.columns)-1]])\n",
    "        y = df[len(df.columns)-1]\n",
    "    else:\n",
    "        X = data.drop(columns=['PRM1'])\n",
    "        y = data['PRM1']\n",
    "    \n",
    "    \n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=42) \n",
    "    \n",
    "    return pd.DataFrame(X_train), pd.DataFrame(X_test), pd.DataFrame(y_train), pd.DataFrame(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b5bb0caa-db07-4ca6-b257-e2f198f760fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TSM-PS12(5)</th>\n",
       "      <th>TSM-AS10(11)</th>\n",
       "      <th>TSM-AS34(6)</th>\n",
       "      <th>TSM-PS20(6)</th>\n",
       "      <th>TSM-PS19(5)</th>\n",
       "      <th>PRM1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Data</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1982-12-01</th>\n",
       "      <td>20.58</td>\n",
       "      <td>25.96</td>\n",
       "      <td>19.75</td>\n",
       "      <td>19.31</td>\n",
       "      <td>20.07</td>\n",
       "      <td>178.19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1983-01-01</th>\n",
       "      <td>19.97</td>\n",
       "      <td>26.89</td>\n",
       "      <td>18.50</td>\n",
       "      <td>18.20</td>\n",
       "      <td>19.69</td>\n",
       "      <td>184.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1983-02-01</th>\n",
       "      <td>20.01</td>\n",
       "      <td>27.69</td>\n",
       "      <td>18.28</td>\n",
       "      <td>17.77</td>\n",
       "      <td>19.87</td>\n",
       "      <td>292.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1983-03-01</th>\n",
       "      <td>20.58</td>\n",
       "      <td>27.42</td>\n",
       "      <td>18.81</td>\n",
       "      <td>18.12</td>\n",
       "      <td>20.37</td>\n",
       "      <td>338.77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1983-04-01</th>\n",
       "      <td>21.48</td>\n",
       "      <td>26.64</td>\n",
       "      <td>18.73</td>\n",
       "      <td>18.54</td>\n",
       "      <td>20.41</td>\n",
       "      <td>132.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-08-01</th>\n",
       "      <td>26.43</td>\n",
       "      <td>23.13</td>\n",
       "      <td>23.23</td>\n",
       "      <td>24.48</td>\n",
       "      <td>23.67</td>\n",
       "      <td>34.94</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-09-01</th>\n",
       "      <td>26.02</td>\n",
       "      <td>23.43</td>\n",
       "      <td>23.00</td>\n",
       "      <td>24.45</td>\n",
       "      <td>23.55</td>\n",
       "      <td>9.46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-10-01</th>\n",
       "      <td>23.88</td>\n",
       "      <td>24.66</td>\n",
       "      <td>21.87</td>\n",
       "      <td>23.17</td>\n",
       "      <td>21.93</td>\n",
       "      <td>22.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-11-01</th>\n",
       "      <td>22.14</td>\n",
       "      <td>25.89</td>\n",
       "      <td>20.21</td>\n",
       "      <td>20.80</td>\n",
       "      <td>20.88</td>\n",
       "      <td>172.26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-12-01</th>\n",
       "      <td>20.22</td>\n",
       "      <td>27.56</td>\n",
       "      <td>19.24</td>\n",
       "      <td>19.07</td>\n",
       "      <td>19.42</td>\n",
       "      <td>124.39</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>456 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            TSM-PS12(5)  TSM-AS10(11)  TSM-AS34(6)  TSM-PS20(6)  TSM-PS19(5)  \\\n",
       "Data                                                                           \n",
       "1982-12-01        20.58         25.96        19.75        19.31        20.07   \n",
       "1983-01-01        19.97         26.89        18.50        18.20        19.69   \n",
       "1983-02-01        20.01         27.69        18.28        17.77        19.87   \n",
       "1983-03-01        20.58         27.42        18.81        18.12        20.37   \n",
       "1983-04-01        21.48         26.64        18.73        18.54        20.41   \n",
       "...                 ...           ...          ...          ...          ...   \n",
       "2020-08-01        26.43         23.13        23.23        24.48        23.67   \n",
       "2020-09-01        26.02         23.43        23.00        24.45        23.55   \n",
       "2020-10-01        23.88         24.66        21.87        23.17        21.93   \n",
       "2020-11-01        22.14         25.89        20.21        20.80        20.88   \n",
       "2020-12-01        20.22         27.56        19.24        19.07        19.42   \n",
       "\n",
       "              PRM1  \n",
       "Data                \n",
       "1982-12-01  178.19  \n",
       "1983-01-01  184.08  \n",
       "1983-02-01  292.01  \n",
       "1983-03-01  338.77  \n",
       "1983-04-01  132.12  \n",
       "...            ...  \n",
       "2020-08-01   34.94  \n",
       "2020-09-01    9.46  \n",
       "2020-10-01   22.30  \n",
       "2020-11-01  172.26  \n",
       "2020-12-01  124.39  \n",
       "\n",
       "[456 rows x 6 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('content/base_treino_teste.csv', index_col=[0])\n",
    "data = data[data.columns].round(2)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "fa76982d-4425-42d1-9bc5-0206663cc7af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cdeacaf6-daed-4907-a83a-e67bdb2f0f30",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = gen_fit_test_data(data, False)\n",
    "#X,y = gen_fit_test_data(data, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "14735c33-d561-4e47-b382-fb697b866ea3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train layer0 in 0.11 sec\n",
      "train layer1 in 0.28 sec\n",
      "train layer2 in 0.27 sec\n",
      "train layer3 in 0.27 sec\n",
      "train layer4 in 0.27 sec\n",
      "train layer5 in 0.27 sec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fabricio/.cache/pypoetry/virtualenvs/modelo-preditor-A4158a_0-py3.9/lib/python3.9/site-packages/scipy/sparse/linalg/isolve/lsqr.py:421: RuntimeWarning: invalid value encountered in multiply\n",
      "  u = (1/beta) * u\n",
      "/home/fabricio/.cache/pypoetry/virtualenvs/modelo-preditor-A4158a_0-py3.9/lib/python3.9/site-packages/scipy/sparse/linalg/isolve/lsqr.py:423: RuntimeWarning: invalid value encountered in multiply\n",
      "  v = A.rmatvec(u) - beta * v\n",
      "/home/fabricio/.cache/pypoetry/virtualenvs/modelo-preditor-A4158a_0-py3.9/lib/python3.9/site-packages/scipy/sparse/linalg/isolve/lsqr.py:431: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cs1 = rhobar / rhobar1\n",
      "/home/fabricio/.cache/pypoetry/virtualenvs/modelo-preditor-A4158a_0-py3.9/lib/python3.9/site-packages/scipy/sparse/linalg/isolve/lsqr.py:89: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  tau = b / a\n",
      "/home/fabricio/.cache/pypoetry/virtualenvs/modelo-preditor-A4158a_0-py3.9/lib/python3.9/site-packages/scipy/sparse/linalg/isolve/lsqr.py:421: RuntimeWarning: invalid value encountered in multiply\n",
      "  u = (1/beta) * u\n",
      "/home/fabricio/.cache/pypoetry/virtualenvs/modelo-preditor-A4158a_0-py3.9/lib/python3.9/site-packages/scipy/sparse/linalg/isolve/lsqr.py:423: RuntimeWarning: invalid value encountered in multiply\n",
      "  v = A.rmatvec(u) - beta * v\n",
      "/home/fabricio/.cache/pypoetry/virtualenvs/modelo-preditor-A4158a_0-py3.9/lib/python3.9/site-packages/scipy/sparse/linalg/isolve/lsqr.py:431: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cs1 = rhobar / rhobar1\n",
      "/home/fabricio/.cache/pypoetry/virtualenvs/modelo-preditor-A4158a_0-py3.9/lib/python3.9/site-packages/scipy/sparse/linalg/isolve/lsqr.py:89: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  tau = b / a\n",
      "/home/fabricio/.cache/pypoetry/virtualenvs/modelo-preditor-A4158a_0-py3.9/lib/python3.9/site-packages/scipy/sparse/linalg/isolve/lsqr.py:421: RuntimeWarning: invalid value encountered in multiply\n",
      "  u = (1/beta) * u\n",
      "/home/fabricio/.cache/pypoetry/virtualenvs/modelo-preditor-A4158a_0-py3.9/lib/python3.9/site-packages/scipy/sparse/linalg/isolve/lsqr.py:423: RuntimeWarning: invalid value encountered in multiply\n",
      "  v = A.rmatvec(u) - beta * v\n",
      "/home/fabricio/.cache/pypoetry/virtualenvs/modelo-preditor-A4158a_0-py3.9/lib/python3.9/site-packages/scipy/sparse/linalg/isolve/lsqr.py:431: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cs1 = rhobar / rhobar1\n",
      "/home/fabricio/.cache/pypoetry/virtualenvs/modelo-preditor-A4158a_0-py3.9/lib/python3.9/site-packages/scipy/sparse/linalg/isolve/lsqr.py:89: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  tau = b / a\n",
      "/home/fabricio/.cache/pypoetry/virtualenvs/modelo-preditor-A4158a_0-py3.9/lib/python3.9/site-packages/scipy/sparse/linalg/isolve/lsqr.py:421: RuntimeWarning: invalid value encountered in multiply\n",
      "  u = (1/beta) * u\n",
      "/home/fabricio/.cache/pypoetry/virtualenvs/modelo-preditor-A4158a_0-py3.9/lib/python3.9/site-packages/scipy/sparse/linalg/isolve/lsqr.py:423: RuntimeWarning: invalid value encountered in multiply\n",
      "  v = A.rmatvec(u) - beta * v\n",
      "/home/fabricio/.cache/pypoetry/virtualenvs/modelo-preditor-A4158a_0-py3.9/lib/python3.9/site-packages/scipy/sparse/linalg/isolve/lsqr.py:431: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  cs1 = rhobar / rhobar1\n",
      "/home/fabricio/.cache/pypoetry/virtualenvs/modelo-preditor-A4158a_0-py3.9/lib/python3.9/site-packages/scipy/sparse/linalg/isolve/lsqr.py:89: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  tau = b / a\n",
      "/home/fabricio/.cache/pypoetry/virtualenvs/modelo-preditor-A4158a_0-py3.9/lib/python3.9/site-packages/gmdhpy/neuron.py:340: RuntimeWarning: overflow encountered in multiply\n",
      "  a[:, 9] = a[:, 6] * u2x\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Input contains NaN, infinity or a value too large for dtype('float64').",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_77420/1526512471.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMultilayerGMDH\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcriterion_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'bias_retrain'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mref_functions\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'linear_cov'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'quadratic'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'cubic'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'linear'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnormalize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/.cache/pypoetry/virtualenvs/modelo-preditor-A4158a_0-py3.9/lib/python3.9/site-packages/gmdhpy/gmdh.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, data_x, data_y, validation_data, dataset_split, verbose)\u001b[0m\n\u001b[1;32m    623\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    624\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pre_fit_check\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidate_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 625\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfit_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    626\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    627\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.cache/pypoetry/virtualenvs/modelo-preditor-A4158a_0-py3.9/lib/python3.9/site-packages/gmdhpy/gmdh.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, fit_data)\u001b[0m\n\u001b[1;32m    500\u001b[0m             \u001b[0;31m# using specified criterion\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    501\u001b[0m             \u001b[0mt0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 502\u001b[0;31m             \u001b[0mlayer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfit_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpool\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfit_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    503\u001b[0m             \u001b[0mt1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    504\u001b[0m             \u001b[0mtotal_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mt1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mt0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.cache/pypoetry/virtualenvs/modelo-preditor-A4158a_0-py3.9/lib/python3.9/site-packages/gmdhpy/gmdh.py\u001b[0m in \u001b[0;36m_create_layer\u001b[0;34m(self, pool, fit_data)\u001b[0m\n\u001b[1;32m    373\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    374\u001b[0m         \u001b[0;31m# calculate neuron coefficients (weights)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 375\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_fit_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlayer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpool\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_fit_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfit_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    376\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    377\u001b[0m         \u001b[0;31m# sort neurons in ascending error order according to specified criterion\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.cache/pypoetry/virtualenvs/modelo-preditor-A4158a_0-py3.9/lib/python3.9/site-packages/gmdhpy/gmdh.py\u001b[0m in \u001b[0;36m_fit_layer\u001b[0;34m(self, layer, pool, fit_data, fit_params)\u001b[0m\n\u001b[1;32m    825\u001b[0m             \u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfitted_neurons\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    826\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 827\u001b[0;31m             \u001b[0mfit_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob_args\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    828\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    829\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.cache/pypoetry/virtualenvs/modelo-preditor-A4158a_0-py3.9/lib/python3.9/site-packages/gmdhpy/neuron.py\u001b[0m in \u001b[0;36mfit_layer\u001b[0;34m(fit_layer_data)\u001b[0m\n\u001b[1;32m    442\u001b[0m     \u001b[0msublayer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfit_layer_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msublayer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    443\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mneuron\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msublayer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 444\u001b[0;31m         neuron.fit(fit_layer_data.train_x,\n\u001b[0m\u001b[1;32m    445\u001b[0m                    \u001b[0mfit_layer_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_y\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    446\u001b[0m                    \u001b[0mfit_layer_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalidate_x\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.cache/pypoetry/virtualenvs/modelo-preditor-A4158a_0-py3.9/lib/python3.9/site-packages/gmdhpy/neuron.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, train_x, train_y, validate_x, validate_y, params)\u001b[0m\n\u001b[1;32m    365\u001b[0m         \u001b[0mTrain\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mneuron\u001b[0m \u001b[0musing\u001b[0m \u001b[0mtrain\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mvalidate\u001b[0m \u001b[0msets\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    366\u001b[0m         \"\"\"\n\u001b[0;32m--> 367\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    368\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mneed_bias_stuff\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'criterion_type'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    369\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalidate_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidate_y\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.cache/pypoetry/virtualenvs/modelo-preditor-A4158a_0-py3.9/lib/python3.9/site-packages/gmdhpy/neuron.py\u001b[0m in \u001b[0;36m_fit_regressor\u001b[0;34m(self, x, y, params)\u001b[0m\n\u001b[1;32m    345\u001b[0m         \u001b[0mreg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlinear_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRidge\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'l2'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msolver\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'lsqr'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    346\u001b[0m         \u001b[0ma2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 347\u001b[0;31m         \u001b[0mreg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    348\u001b[0m         \u001b[0mw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mempty\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcoef_\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdouble\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    349\u001b[0m         \u001b[0mw\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintercept_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.cache/pypoetry/virtualenvs/modelo-preditor-A4158a_0-py3.9/lib/python3.9/site-packages/sklearn/linear_model/_ridge.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    760\u001b[0m         \u001b[0mself\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mreturns\u001b[0m \u001b[0man\u001b[0m \u001b[0minstance\u001b[0m \u001b[0mof\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    761\u001b[0m         \"\"\"\n\u001b[0;32m--> 762\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    763\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    764\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.cache/pypoetry/virtualenvs/modelo-preditor-A4158a_0-py3.9/lib/python3.9/site-packages/sklearn/linear_model/_ridge.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    540\u001b[0m         _accept_sparse = _get_valid_accept_sparse(sparse.issparse(X),\n\u001b[1;32m    541\u001b[0m                                                   self.solver)\n\u001b[0;32m--> 542\u001b[0;31m         X, y = self._validate_data(X, y,\n\u001b[0m\u001b[1;32m    543\u001b[0m                                    \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_accept_sparse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    544\u001b[0m                                    \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_dtype\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.cache/pypoetry/virtualenvs/modelo-preditor-A4158a_0-py3.9/lib/python3.9/site-packages/sklearn/base.py\u001b[0m in \u001b[0;36m_validate_data\u001b[0;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[1;32m    431\u001b[0m                 \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_y_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    432\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 433\u001b[0;31m                 \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_X_y\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcheck_params\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    434\u001b[0m             \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    435\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.cache/pypoetry/virtualenvs/modelo-preditor-A4158a_0-py3.9/lib/python3.9/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0;31m# extra_args > 0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.cache/pypoetry/virtualenvs/modelo-preditor-A4158a_0-py3.9/lib/python3.9/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_X_y\u001b[0;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[1;32m    869\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"y cannot be None\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    870\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 871\u001b[0;31m     X = check_array(X, accept_sparse=accept_sparse,\n\u001b[0m\u001b[1;32m    872\u001b[0m                     \u001b[0maccept_large_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maccept_large_sparse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    873\u001b[0m                     \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.cache/pypoetry/virtualenvs/modelo-preditor-A4158a_0-py3.9/lib/python3.9/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36minner_f\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[0;34m<=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m             \u001b[0;31m# extra_args > 0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.cache/pypoetry/virtualenvs/modelo-preditor-A4158a_0-py3.9/lib/python3.9/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator)\u001b[0m\n\u001b[1;32m    718\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    719\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mforce_all_finite\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 720\u001b[0;31m             _assert_all_finite(array,\n\u001b[0m\u001b[1;32m    721\u001b[0m                                allow_nan=force_all_finite == 'allow-nan')\n\u001b[1;32m    722\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.cache/pypoetry/virtualenvs/modelo-preditor-A4158a_0-py3.9/lib/python3.9/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36m_assert_all_finite\u001b[0;34m(X, allow_nan, msg_dtype)\u001b[0m\n\u001b[1;32m    101\u001b[0m                 not allow_nan and not np.isfinite(X).all()):\n\u001b[1;32m    102\u001b[0m             \u001b[0mtype_err\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'infinity'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mallow_nan\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m'NaN, infinity'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m             raise ValueError(\n\u001b[0m\u001b[1;32m    104\u001b[0m                     \u001b[0mmsg_err\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m                     (type_err,\n",
      "\u001b[0;31mValueError\u001b[0m: Input contains NaN, infinity or a value too large for dtype('float64')."
     ]
    }
   ],
   "source": [
    "from gmdhpy.gmdh import Regressor\n",
    "\n",
    "model = MultilayerGMDH(criterion_type='bias_retrain', ref_functions=('linear_cov', 'quadratic', 'cubic', 'linear'), normalize=True)\n",
    "model.fit(X_train.to_numpy(), y_train.to_numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8b755f0f-e19f-4252-b2a2-5daf34ccab5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model.predict(X_test.to_numpy())\n",
    "#cm = confusion_matrix(y_test, pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "bc8b55f5-5f3c-4162-b31b-1eac6dd016b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10760051413499.643, -656470491.2889353)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score, mean_squared_error\n",
    "\n",
    "mean_squared_error(y_test.to_numpy(), pred), r2_score(y_test.to_numpy(), pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b173b610-13e5-4c5b-a224-0b42cd07d2f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>304</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>341</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>218</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>155</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.999999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>416</th>\n",
       "      <td>0.999999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>138 rows Ã— 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            5\n",
       "304  1.000000\n",
       "39   1.000000\n",
       "341  1.000000\n",
       "218  1.000000\n",
       "155  1.000000\n",
       "..        ...\n",
       "195  1.000000\n",
       "26   1.000000\n",
       "7    0.999999\n",
       "416  0.999999\n",
       "108  1.000000\n",
       "\n",
       "[138 rows x 1 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "b044423c-de09-4140-853d-4012d2161ab8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#plt.scatter(X_train, y_train, label=\"ground truth\")\n",
    "#plt.scatter(x, train_y, label=\"training points\")\n",
    "plt.scatter(range(0,len(y_test)), y_test, label=\"fit\")\n",
    "#plt.scatter(range(0,len(pred)), pred, label=\"predict\")\n",
    "\n",
    "plt.legend(loc='lower left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e082ad82-8ea3-449a-910e-6649f8c21d7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(319,)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "e498ad9c-f745-4121-84e8-a9c4f0200d3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([29.63, 29.09, 28.68, 29.45, 28.76, 28.81, 28.6 , 28.96, 29.14,\n",
       "        26.5 , 29.06]),\n",
       " 2)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.to_numpy()\n",
    "\n",
    "\n",
    "y_train.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "dce6315c-068b-479b-896b-0c2f06948b2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.reshape(X_train, (X_train.shape[0], 1, X_train.shape[1]))\n",
    "X_test = np.reshape(X_test, (X_test.shape[0], 1, X_test.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b0d55f08-1924-4ddc-b1a6-2d0446522634",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(319, 1, 34)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6609af7f-fb12-42e0-8166-b09802efdb06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "32/32 - 2s - loss: 4.2207 - accuracy: 0.0533\n",
      "Epoch 2/300\n",
      "32/32 - 0s - loss: 4.2204 - accuracy: 0.0408\n",
      "Epoch 3/300\n",
      "32/32 - 0s - loss: 4.2204 - accuracy: 0.0282\n",
      "Epoch 4/300\n",
      "32/32 - 0s - loss: 4.2203 - accuracy: 0.0313\n",
      "Epoch 5/300\n",
      "32/32 - 0s - loss: 4.2203 - accuracy: 0.0345\n",
      "Epoch 6/300\n",
      "32/32 - 0s - loss: 4.2203 - accuracy: 0.0376\n",
      "Epoch 7/300\n",
      "32/32 - 0s - loss: 4.2203 - accuracy: 0.0439\n",
      "Epoch 8/300\n",
      "32/32 - 0s - loss: 4.2203 - accuracy: 0.0470\n",
      "Epoch 9/300\n",
      "32/32 - 0s - loss: 4.2203 - accuracy: 0.0502\n",
      "Epoch 10/300\n",
      "32/32 - 0s - loss: 4.2203 - accuracy: 0.0533\n",
      "Epoch 11/300\n",
      "32/32 - 0s - loss: 4.2203 - accuracy: 0.0470\n",
      "Epoch 12/300\n",
      "32/32 - 0s - loss: 4.2203 - accuracy: 0.0533\n",
      "Epoch 13/300\n",
      "32/32 - 0s - loss: 4.2203 - accuracy: 0.0564\n",
      "Epoch 14/300\n",
      "32/32 - 0s - loss: 4.2203 - accuracy: 0.0533\n",
      "Epoch 15/300\n",
      "32/32 - 0s - loss: 4.2203 - accuracy: 0.0564\n",
      "Epoch 16/300\n",
      "32/32 - 0s - loss: 4.2203 - accuracy: 0.0564\n",
      "Epoch 17/300\n",
      "32/32 - 0s - loss: 4.2203 - accuracy: 0.0564\n",
      "Epoch 18/300\n",
      "32/32 - 0s - loss: 4.2203 - accuracy: 0.0533\n",
      "Epoch 19/300\n",
      "32/32 - 0s - loss: 4.2203 - accuracy: 0.0533\n",
      "Epoch 20/300\n",
      "32/32 - 0s - loss: 4.2203 - accuracy: 0.0564\n",
      "Epoch 21/300\n",
      "32/32 - 0s - loss: 4.2203 - accuracy: 0.0533\n",
      "Epoch 22/300\n",
      "32/32 - 0s - loss: 4.2203 - accuracy: 0.0564\n",
      "Epoch 23/300\n",
      "32/32 - 0s - loss: 4.2203 - accuracy: 0.0564\n",
      "Epoch 24/300\n",
      "32/32 - 0s - loss: 4.2203 - accuracy: 0.0533\n",
      "Epoch 25/300\n",
      "32/32 - 0s - loss: 4.2203 - accuracy: 0.0564\n",
      "Epoch 26/300\n",
      "32/32 - 0s - loss: 4.2203 - accuracy: 0.0533\n",
      "Epoch 27/300\n",
      "32/32 - 0s - loss: 4.2203 - accuracy: 0.0564\n",
      "Epoch 28/300\n",
      "32/32 - 0s - loss: 4.2203 - accuracy: 0.0502\n",
      "Epoch 29/300\n",
      "32/32 - 0s - loss: 4.2203 - accuracy: 0.0533\n",
      "Epoch 30/300\n",
      "32/32 - 0s - loss: 4.2203 - accuracy: 0.0533\n",
      "Epoch 31/300\n",
      "32/32 - 0s - loss: 4.2203 - accuracy: 0.0533\n",
      "Epoch 32/300\n",
      "32/32 - 0s - loss: 4.2203 - accuracy: 0.0502\n",
      "Epoch 33/300\n",
      "32/32 - 0s - loss: 4.2203 - accuracy: 0.0533\n",
      "Epoch 34/300\n",
      "32/32 - 0s - loss: 4.2203 - accuracy: 0.0596\n",
      "Epoch 35/300\n",
      "32/32 - 0s - loss: 4.2203 - accuracy: 0.0502\n",
      "Epoch 36/300\n",
      "32/32 - 0s - loss: 4.2203 - accuracy: 0.0533\n",
      "Epoch 37/300\n",
      "32/32 - 0s - loss: 4.2203 - accuracy: 0.0596\n",
      "Epoch 38/300\n",
      "32/32 - 0s - loss: 4.2203 - accuracy: 0.0564\n",
      "Epoch 39/300\n",
      "32/32 - 0s - loss: 4.2203 - accuracy: 0.0564\n",
      "Epoch 40/300\n",
      "32/32 - 0s - loss: 4.2203 - accuracy: 0.0627\n",
      "Epoch 41/300\n",
      "32/32 - 0s - loss: 4.2203 - accuracy: 0.0564\n",
      "Epoch 42/300\n",
      "32/32 - 0s - loss: 4.2203 - accuracy: 0.0627\n",
      "Epoch 43/300\n",
      "32/32 - 0s - loss: 4.2203 - accuracy: 0.0658\n",
      "Epoch 44/300\n",
      "32/32 - 0s - loss: 4.2203 - accuracy: 0.0721\n",
      "Epoch 45/300\n",
      "32/32 - 0s - loss: 4.2203 - accuracy: 0.0596\n",
      "Epoch 46/300\n",
      "32/32 - 0s - loss: 4.2203 - accuracy: 0.0627\n",
      "Epoch 47/300\n",
      "32/32 - 0s - loss: 4.2203 - accuracy: 0.0721\n",
      "Epoch 48/300\n",
      "32/32 - 0s - loss: 4.2203 - accuracy: 0.0596\n",
      "Epoch 49/300\n",
      "32/32 - 0s - loss: 4.2203 - accuracy: 0.0721\n",
      "Epoch 50/300\n",
      "32/32 - 0s - loss: 4.2203 - accuracy: 0.0627\n",
      "Epoch 51/300\n",
      "32/32 - 0s - loss: 4.2203 - accuracy: 0.0658\n",
      "Epoch 52/300\n",
      "32/32 - 0s - loss: 4.2203 - accuracy: 0.0658\n",
      "Epoch 53/300\n",
      "32/32 - 0s - loss: 4.2203 - accuracy: 0.0596\n",
      "Epoch 54/300\n",
      "32/32 - 0s - loss: 4.2203 - accuracy: 0.0690\n",
      "Epoch 55/300\n",
      "32/32 - 0s - loss: 4.2203 - accuracy: 0.0690\n",
      "Epoch 56/300\n",
      "32/32 - 0s - loss: 4.2203 - accuracy: 0.0627\n",
      "Epoch 57/300\n",
      "32/32 - 0s - loss: 4.2203 - accuracy: 0.0690\n",
      "Epoch 58/300\n",
      "32/32 - 0s - loss: 4.2203 - accuracy: 0.0627\n",
      "Epoch 59/300\n",
      "32/32 - 0s - loss: 4.2203 - accuracy: 0.0690\n",
      "Epoch 60/300\n",
      "32/32 - 0s - loss: 4.2203 - accuracy: 0.0690\n",
      "Epoch 61/300\n",
      "32/32 - 0s - loss: 4.2203 - accuracy: 0.0533\n",
      "Epoch 62/300\n",
      "32/32 - 0s - loss: 4.2203 - accuracy: 0.0690\n",
      "Epoch 63/300\n",
      "32/32 - 0s - loss: 4.2203 - accuracy: 0.0690\n",
      "Epoch 64/300\n",
      "32/32 - 0s - loss: 4.2203 - accuracy: 0.0690\n",
      "Epoch 65/300\n",
      "32/32 - 0s - loss: 4.2203 - accuracy: 0.0596\n",
      "Epoch 66/300\n",
      "32/32 - 0s - loss: 4.2203 - accuracy: 0.0752\n",
      "Epoch 67/300\n",
      "32/32 - 0s - loss: 4.2203 - accuracy: 0.0658\n",
      "Epoch 68/300\n",
      "32/32 - 0s - loss: 4.2203 - accuracy: 0.0627\n",
      "Epoch 69/300\n",
      "32/32 - 0s - loss: 4.2203 - accuracy: 0.0690\n",
      "Epoch 70/300\n",
      "32/32 - 0s - loss: 4.2203 - accuracy: 0.0721\n",
      "Epoch 71/300\n",
      "32/32 - 0s - loss: 4.2203 - accuracy: 0.0658\n",
      "Epoch 72/300\n",
      "32/32 - 0s - loss: 4.2203 - accuracy: 0.0752\n",
      "Epoch 73/300\n",
      "32/32 - 0s - loss: 4.2203 - accuracy: 0.0596\n",
      "Epoch 74/300\n",
      "32/32 - 0s - loss: 4.2203 - accuracy: 0.0752\n",
      "Epoch 75/300\n",
      "32/32 - 0s - loss: 4.2203 - accuracy: 0.0752\n",
      "Epoch 76/300\n",
      "32/32 - 0s - loss: 4.2203 - accuracy: 0.0721\n",
      "Epoch 77/300\n",
      "32/32 - 0s - loss: 4.2203 - accuracy: 0.0690\n",
      "Epoch 78/300\n",
      "32/32 - 0s - loss: 4.2203 - accuracy: 0.0690\n",
      "Epoch 79/300\n",
      "32/32 - 0s - loss: 4.2203 - accuracy: 0.0784\n",
      "Epoch 80/300\n",
      "32/32 - 0s - loss: 4.2203 - accuracy: 0.0784\n",
      "Epoch 81/300\n",
      "32/32 - 0s - loss: 4.2203 - accuracy: 0.0721\n",
      "Epoch 82/300\n",
      "32/32 - 0s - loss: 4.2203 - accuracy: 0.0658\n",
      "Epoch 83/300\n",
      "32/32 - 0s - loss: 4.2203 - accuracy: 0.0721\n",
      "Epoch 84/300\n",
      "32/32 - 0s - loss: 4.2203 - accuracy: 0.0815\n",
      "Epoch 85/300\n",
      "32/32 - 0s - loss: 4.2203 - accuracy: 0.0752\n",
      "Epoch 86/300\n",
      "32/32 - 0s - loss: 4.2203 - accuracy: 0.0721\n",
      "Epoch 87/300\n",
      "32/32 - 0s - loss: 4.2203 - accuracy: 0.0752\n",
      "Epoch 88/300\n",
      "32/32 - 0s - loss: 4.2203 - accuracy: 0.0752\n",
      "Epoch 89/300\n",
      "32/32 - 0s - loss: 4.2203 - accuracy: 0.0846\n",
      "Epoch 90/300\n",
      "32/32 - 0s - loss: 4.2203 - accuracy: 0.0721\n",
      "Epoch 91/300\n",
      "32/32 - 0s - loss: 4.2203 - accuracy: 0.0878\n",
      "Epoch 92/300\n",
      "32/32 - 0s - loss: 4.2203 - accuracy: 0.0815\n",
      "Epoch 93/300\n",
      "32/32 - 0s - loss: 4.2203 - accuracy: 0.0752\n",
      "Epoch 94/300\n",
      "32/32 - 0s - loss: 4.2203 - accuracy: 0.0846\n",
      "Epoch 95/300\n",
      "32/32 - 0s - loss: 4.2203 - accuracy: 0.0752\n",
      "Epoch 96/300\n",
      "32/32 - 0s - loss: 4.2203 - accuracy: 0.0846\n",
      "Epoch 97/300\n",
      "32/32 - 0s - loss: 4.2203 - accuracy: 0.0658\n",
      "Epoch 98/300\n",
      "32/32 - 0s - loss: 4.2203 - accuracy: 0.0784\n",
      "Epoch 99/300\n",
      "32/32 - 0s - loss: 4.2203 - accuracy: 0.0721\n",
      "Epoch 100/300\n",
      "32/32 - 0s - loss: 4.2203 - accuracy: 0.0940\n",
      "Epoch 101/300\n",
      "32/32 - 0s - loss: 4.2203 - accuracy: 0.0846\n",
      "Epoch 102/300\n",
      "32/32 - 0s - loss: 4.2203 - accuracy: 0.0815\n",
      "Epoch 103/300\n",
      "32/32 - 0s - loss: 4.2203 - accuracy: 0.0815\n",
      "Epoch 104/300\n",
      "32/32 - 0s - loss: 4.2203 - accuracy: 0.0721\n",
      "Epoch 105/300\n",
      "32/32 - 0s - loss: 4.2203 - accuracy: 0.0909\n",
      "Epoch 106/300\n",
      "32/32 - 0s - loss: 4.2203 - accuracy: 0.0878\n",
      "Epoch 107/300\n",
      "32/32 - 0s - loss: 4.2203 - accuracy: 0.0909\n",
      "Epoch 108/300\n",
      "32/32 - 0s - loss: 4.2203 - accuracy: 0.0815\n",
      "Epoch 109/300\n",
      "32/32 - 0s - loss: 4.2203 - accuracy: 0.0846\n",
      "Epoch 110/300\n",
      "32/32 - 0s - loss: 4.2203 - accuracy: 0.0909\n",
      "Epoch 111/300\n",
      "32/32 - 0s - loss: 4.2203 - accuracy: 0.0815\n",
      "Epoch 112/300\n",
      "32/32 - 0s - loss: 4.2203 - accuracy: 0.0815\n",
      "Epoch 113/300\n",
      "32/32 - 0s - loss: 4.2203 - accuracy: 0.0846\n",
      "Epoch 114/300\n",
      "32/32 - 0s - loss: 4.2203 - accuracy: 0.0940\n",
      "Epoch 115/300\n",
      "32/32 - 0s - loss: 4.2203 - accuracy: 0.0940\n",
      "Epoch 116/300\n",
      "32/32 - 0s - loss: 4.2203 - accuracy: 0.0815\n",
      "Epoch 117/300\n",
      "32/32 - 0s - loss: 4.2203 - accuracy: 0.0815\n",
      "Epoch 118/300\n",
      "32/32 - 0s - loss: 4.2203 - accuracy: 0.0878\n",
      "Epoch 119/300\n",
      "32/32 - 0s - loss: 4.2203 - accuracy: 0.1003\n",
      "Epoch 120/300\n",
      "32/32 - 0s - loss: 4.2203 - accuracy: 0.0784\n",
      "Epoch 121/300\n",
      "32/32 - 0s - loss: 4.2203 - accuracy: 0.0909\n",
      "Epoch 122/300\n",
      "32/32 - 0s - loss: 4.2203 - accuracy: 0.0909\n",
      "Epoch 123/300\n",
      "32/32 - 0s - loss: 4.2203 - accuracy: 0.0909\n",
      "Epoch 124/300\n",
      "32/32 - 0s - loss: 4.2203 - accuracy: 0.0784\n",
      "Epoch 125/300\n",
      "32/32 - 0s - loss: 4.2203 - accuracy: 0.0784\n",
      "Epoch 126/300\n",
      "32/32 - 0s - loss: 4.2203 - accuracy: 0.0909\n",
      "Epoch 127/300\n",
      "32/32 - 0s - loss: 4.2203 - accuracy: 0.0815\n",
      "Epoch 128/300\n",
      "32/32 - 0s - loss: 4.2203 - accuracy: 0.0721\n",
      "Epoch 129/300\n",
      "32/32 - 0s - loss: 4.2203 - accuracy: 0.0940\n",
      "Epoch 130/300\n",
      "32/32 - 0s - loss: 4.2203 - accuracy: 0.0972\n",
      "Epoch 131/300\n",
      "32/32 - 0s - loss: 4.2203 - accuracy: 0.0846\n",
      "Epoch 132/300\n",
      "32/32 - 0s - loss: 4.2203 - accuracy: 0.0909\n",
      "Epoch 133/300\n",
      "32/32 - 0s - loss: 4.2203 - accuracy: 0.0909\n",
      "Epoch 134/300\n",
      "32/32 - 0s - loss: 4.2203 - accuracy: 0.0752\n",
      "Epoch 135/300\n",
      "32/32 - 0s - loss: 4.2203 - accuracy: 0.0846\n",
      "Epoch 136/300\n",
      "32/32 - 0s - loss: 4.2203 - accuracy: 0.0846\n",
      "Epoch 137/300\n",
      "32/32 - 0s - loss: 4.2203 - accuracy: 0.0972\n",
      "Epoch 138/300\n",
      "32/32 - 0s - loss: 4.2203 - accuracy: 0.0784\n",
      "Epoch 139/300\n",
      "32/32 - 0s - loss: 4.2203 - accuracy: 0.0878\n",
      "Epoch 140/300\n",
      "32/32 - 0s - loss: 4.2203 - accuracy: 0.0878\n",
      "Epoch 141/300\n",
      "32/32 - 0s - loss: 4.2203 - accuracy: 0.0846\n",
      "Epoch 142/300\n",
      "32/32 - 0s - loss: 4.2203 - accuracy: 0.0846\n",
      "Epoch 143/300\n",
      "32/32 - 0s - loss: 4.2203 - accuracy: 0.0815\n",
      "Epoch 144/300\n",
      "32/32 - 0s - loss: 4.2203 - accuracy: 0.0752\n",
      "Epoch 145/300\n",
      "32/32 - 0s - loss: 4.2203 - accuracy: 0.0846\n",
      "Epoch 146/300\n",
      "32/32 - 0s - loss: 4.2203 - accuracy: 0.0815\n",
      "Epoch 147/300\n",
      "32/32 - 0s - loss: 4.2203 - accuracy: 0.0690\n",
      "Epoch 148/300\n",
      "32/32 - 0s - loss: 4.2203 - accuracy: 0.0909\n",
      "Epoch 149/300\n",
      "32/32 - 0s - loss: 4.2203 - accuracy: 0.0846\n",
      "Epoch 150/300\n",
      "32/32 - 0s - loss: 4.2203 - accuracy: 0.0784\n",
      "Epoch 151/300\n",
      "32/32 - 0s - loss: 4.2203 - accuracy: 0.0627\n",
      "Epoch 152/300\n",
      "32/32 - 0s - loss: 4.2203 - accuracy: 0.0784\n",
      "Epoch 153/300\n",
      "32/32 - 0s - loss: 4.2203 - accuracy: 0.0846\n",
      "Epoch 154/300\n",
      "32/32 - 0s - loss: 4.2203 - accuracy: 0.0627\n",
      "Epoch 155/300\n",
      "32/32 - 0s - loss: 4.2203 - accuracy: 0.0940\n",
      "Epoch 156/300\n",
      "32/32 - 0s - loss: 4.2203 - accuracy: 0.0721\n",
      "Epoch 157/300\n",
      "32/32 - 0s - loss: 4.2203 - accuracy: 0.0690\n",
      "Epoch 158/300\n",
      "32/32 - 0s - loss: 4.2203 - accuracy: 0.0815\n",
      "Epoch 159/300\n",
      "32/32 - 0s - loss: 4.2203 - accuracy: 0.0940\n",
      "Epoch 160/300\n",
      "32/32 - 0s - loss: 4.2203 - accuracy: 0.0909\n",
      "Epoch 161/300\n",
      "32/32 - 0s - loss: 4.2203 - accuracy: 0.0721\n",
      "Epoch 162/300\n",
      "32/32 - 0s - loss: 4.2203 - accuracy: 0.0878\n",
      "Epoch 163/300\n",
      "32/32 - 0s - loss: 4.2203 - accuracy: 0.0815\n",
      "Epoch 164/300\n",
      "32/32 - 0s - loss: 4.2203 - accuracy: 0.0815\n",
      "Epoch 165/300\n",
      "32/32 - 0s - loss: 4.2203 - accuracy: 0.0627\n",
      "Epoch 166/300\n",
      "32/32 - 0s - loss: 4.2203 - accuracy: 0.0878\n",
      "Epoch 167/300\n",
      "32/32 - 0s - loss: 4.2203 - accuracy: 0.0846\n",
      "Epoch 168/300\n",
      "32/32 - 0s - loss: 4.2203 - accuracy: 0.0721\n",
      "Epoch 169/300\n",
      "32/32 - 0s - loss: 4.2203 - accuracy: 0.1003\n",
      "Epoch 170/300\n",
      "32/32 - 0s - loss: 4.2203 - accuracy: 0.0752\n",
      "Epoch 171/300\n",
      "32/32 - 0s - loss: 4.2203 - accuracy: 0.0909\n",
      "Epoch 172/300\n",
      "32/32 - 0s - loss: 4.2203 - accuracy: 0.0846\n",
      "Epoch 173/300\n",
      "32/32 - 0s - loss: 4.2203 - accuracy: 0.0815\n",
      "Epoch 174/300\n",
      "32/32 - 0s - loss: 4.2203 - accuracy: 0.0752\n",
      "Epoch 175/300\n",
      "32/32 - 0s - loss: 4.2203 - accuracy: 0.0721\n",
      "Epoch 176/300\n",
      "32/32 - 0s - loss: 4.2203 - accuracy: 0.0752\n",
      "Epoch 177/300\n",
      "32/32 - 0s - loss: 4.2203 - accuracy: 0.0846\n",
      "Epoch 178/300\n",
      "32/32 - 0s - loss: 4.2203 - accuracy: 0.0909\n",
      "Epoch 179/300\n",
      "32/32 - 0s - loss: 4.2203 - accuracy: 0.0909\n",
      "Epoch 180/300\n",
      "32/32 - 0s - loss: 4.2203 - accuracy: 0.0784\n",
      "Epoch 181/300\n",
      "32/32 - 0s - loss: 4.2203 - accuracy: 0.0690\n",
      "Epoch 182/300\n",
      "32/32 - 0s - loss: 4.2203 - accuracy: 0.0846\n",
      "Epoch 183/300\n",
      "32/32 - 0s - loss: 4.2203 - accuracy: 0.0658\n",
      "Epoch 184/300\n",
      "32/32 - 0s - loss: 4.2203 - accuracy: 0.0784\n",
      "Epoch 185/300\n",
      "32/32 - 0s - loss: 4.2203 - accuracy: 0.0658\n",
      "Epoch 186/300\n",
      "32/32 - 0s - loss: 4.2203 - accuracy: 0.0815\n",
      "Epoch 187/300\n",
      "32/32 - 0s - loss: 4.2203 - accuracy: 0.0878\n",
      "Epoch 188/300\n",
      "32/32 - 0s - loss: 4.2203 - accuracy: 0.0815\n",
      "Epoch 189/300\n",
      "32/32 - 0s - loss: 4.2203 - accuracy: 0.0815\n",
      "Epoch 190/300\n",
      "32/32 - 0s - loss: 4.2203 - accuracy: 0.0784\n",
      "Epoch 191/300\n",
      "32/32 - 0s - loss: 4.2203 - accuracy: 0.0972\n",
      "Epoch 192/300\n",
      "32/32 - 0s - loss: 4.2203 - accuracy: 0.0752\n",
      "Epoch 193/300\n",
      "32/32 - 0s - loss: 4.2203 - accuracy: 0.0972\n",
      "Epoch 194/300\n",
      "32/32 - 0s - loss: 4.2203 - accuracy: 0.0784\n",
      "Epoch 195/300\n",
      "32/32 - 0s - loss: 4.2203 - accuracy: 0.0784\n",
      "Epoch 196/300\n",
      "32/32 - 0s - loss: 4.2203 - accuracy: 0.0815\n",
      "Epoch 197/300\n",
      "32/32 - 0s - loss: 4.2203 - accuracy: 0.0815\n",
      "Epoch 198/300\n",
      "32/32 - 0s - loss: 4.2203 - accuracy: 0.0878\n",
      "Epoch 199/300\n",
      "32/32 - 0s - loss: 4.2203 - accuracy: 0.0690\n",
      "Epoch 200/300\n",
      "32/32 - 0s - loss: 4.2203 - accuracy: 0.0815\n",
      "Epoch 201/300\n",
      "32/32 - 0s - loss: 4.2203 - accuracy: 0.0752\n",
      "Epoch 202/300\n",
      "32/32 - 0s - loss: 4.2203 - accuracy: 0.0721\n",
      "Epoch 203/300\n",
      "32/32 - 0s - loss: 4.2203 - accuracy: 0.1066\n",
      "Epoch 204/300\n",
      "32/32 - 0s - loss: 4.2203 - accuracy: 0.0784\n",
      "Epoch 205/300\n",
      "32/32 - 0s - loss: 4.2203 - accuracy: 0.0752\n",
      "Epoch 206/300\n",
      "32/32 - 0s - loss: 4.2203 - accuracy: 0.0846\n",
      "Epoch 207/300\n",
      "32/32 - 0s - loss: 4.2203 - accuracy: 0.0815\n",
      "Epoch 208/300\n",
      "32/32 - 0s - loss: 4.2203 - accuracy: 0.0815\n",
      "Epoch 209/300\n",
      "32/32 - 0s - loss: 4.2203 - accuracy: 0.0784\n",
      "Epoch 210/300\n",
      "32/32 - 0s - loss: 4.2203 - accuracy: 0.0784\n",
      "Epoch 211/300\n",
      "32/32 - 0s - loss: 4.2203 - accuracy: 0.0721\n",
      "Epoch 212/300\n",
      "32/32 - 0s - loss: 4.2203 - accuracy: 0.0815\n",
      "Epoch 213/300\n",
      "32/32 - 0s - loss: 4.2203 - accuracy: 0.1003\n",
      "Epoch 214/300\n",
      "32/32 - 0s - loss: 4.2203 - accuracy: 0.0846\n",
      "Epoch 215/300\n",
      "32/32 - 0s - loss: 4.2203 - accuracy: 0.0784\n",
      "Epoch 216/300\n",
      "32/32 - 0s - loss: 4.2203 - accuracy: 0.0909\n",
      "Epoch 217/300\n",
      "32/32 - 0s - loss: 4.2203 - accuracy: 0.0940\n",
      "Epoch 218/300\n",
      "32/32 - 0s - loss: 4.2203 - accuracy: 0.0846\n",
      "Epoch 219/300\n",
      "32/32 - 0s - loss: 4.2203 - accuracy: 0.0752\n",
      "Epoch 220/300\n",
      "32/32 - 0s - loss: 4.2203 - accuracy: 0.0972\n",
      "Epoch 221/300\n",
      "32/32 - 0s - loss: 4.2203 - accuracy: 0.0784\n",
      "Epoch 222/300\n",
      "32/32 - 0s - loss: 4.2203 - accuracy: 0.0940\n",
      "Epoch 223/300\n",
      "32/32 - 0s - loss: 4.2203 - accuracy: 0.0846\n",
      "Epoch 224/300\n",
      "32/32 - 0s - loss: 4.2203 - accuracy: 0.0846\n",
      "Epoch 225/300\n",
      "32/32 - 0s - loss: 4.2203 - accuracy: 0.0972\n",
      "Epoch 226/300\n",
      "32/32 - 0s - loss: 4.2203 - accuracy: 0.1066\n",
      "Epoch 227/300\n",
      "32/32 - 0s - loss: 4.2203 - accuracy: 0.0846\n",
      "Epoch 228/300\n",
      "32/32 - 0s - loss: 4.2203 - accuracy: 0.0846\n",
      "Epoch 229/300\n",
      "32/32 - 0s - loss: 4.2203 - accuracy: 0.0784\n",
      "Epoch 230/300\n",
      "32/32 - 0s - loss: 4.2203 - accuracy: 0.0878\n",
      "Epoch 231/300\n",
      "32/32 - 0s - loss: 4.2203 - accuracy: 0.0909\n",
      "Epoch 232/300\n",
      "32/32 - 0s - loss: 4.2203 - accuracy: 0.0878\n",
      "Epoch 233/300\n",
      "32/32 - 0s - loss: 4.2203 - accuracy: 0.0878\n",
      "Epoch 234/300\n",
      "32/32 - 0s - loss: 4.2203 - accuracy: 0.0815\n",
      "Epoch 235/300\n",
      "32/32 - 0s - loss: 4.2203 - accuracy: 0.0909\n",
      "Epoch 236/300\n",
      "32/32 - 0s - loss: 4.2203 - accuracy: 0.0752\n",
      "Epoch 237/300\n",
      "32/32 - 0s - loss: 4.2203 - accuracy: 0.0784\n",
      "Epoch 238/300\n",
      "32/32 - 0s - loss: 4.2203 - accuracy: 0.1034\n",
      "Epoch 239/300\n",
      "32/32 - 0s - loss: 4.2203 - accuracy: 0.0846\n",
      "Epoch 240/300\n",
      "32/32 - 0s - loss: 4.2203 - accuracy: 0.0784\n",
      "Epoch 241/300\n",
      "32/32 - 0s - loss: 4.2203 - accuracy: 0.1160\n",
      "Epoch 242/300\n",
      "32/32 - 0s - loss: 4.2203 - accuracy: 0.0909\n",
      "Epoch 243/300\n",
      "32/32 - 0s - loss: 4.2203 - accuracy: 0.0815\n",
      "Epoch 244/300\n",
      "32/32 - 0s - loss: 4.2203 - accuracy: 0.1003\n",
      "Epoch 245/300\n",
      "32/32 - 0s - loss: 4.2203 - accuracy: 0.0878\n",
      "Epoch 246/300\n",
      "32/32 - 0s - loss: 4.2203 - accuracy: 0.0721\n",
      "Epoch 247/300\n",
      "32/32 - 0s - loss: 4.2203 - accuracy: 0.0972\n",
      "Epoch 248/300\n",
      "32/32 - 0s - loss: 4.2203 - accuracy: 0.0909\n",
      "Epoch 249/300\n",
      "32/32 - 0s - loss: 4.2203 - accuracy: 0.0878\n",
      "Epoch 250/300\n",
      "32/32 - 0s - loss: 4.2203 - accuracy: 0.0972\n",
      "Epoch 251/300\n",
      "32/32 - 0s - loss: 4.2203 - accuracy: 0.0878\n",
      "Epoch 252/300\n",
      "32/32 - 0s - loss: 4.2203 - accuracy: 0.0752\n",
      "Epoch 253/300\n",
      "32/32 - 0s - loss: 4.2203 - accuracy: 0.0909\n",
      "Epoch 254/300\n",
      "32/32 - 0s - loss: 4.2203 - accuracy: 0.1160\n",
      "Epoch 255/300\n",
      "32/32 - 0s - loss: 4.2203 - accuracy: 0.1097\n",
      "Epoch 256/300\n",
      "32/32 - 0s - loss: 4.2203 - accuracy: 0.0846\n",
      "Epoch 257/300\n",
      "32/32 - 0s - loss: 4.2203 - accuracy: 0.0972\n",
      "Epoch 258/300\n",
      "32/32 - 0s - loss: 4.2203 - accuracy: 0.0721\n",
      "Epoch 259/300\n",
      "32/32 - 0s - loss: 4.2203 - accuracy: 0.0815\n",
      "Epoch 260/300\n",
      "32/32 - 0s - loss: 4.2203 - accuracy: 0.0940\n",
      "Epoch 261/300\n",
      "32/32 - 0s - loss: 4.2203 - accuracy: 0.0909\n",
      "Epoch 262/300\n",
      "32/32 - 0s - loss: 4.2203 - accuracy: 0.1003\n",
      "Epoch 263/300\n",
      "32/32 - 0s - loss: 4.2203 - accuracy: 0.1129\n",
      "Epoch 264/300\n",
      "32/32 - 0s - loss: 4.2203 - accuracy: 0.0909\n",
      "Epoch 265/300\n",
      "32/32 - 0s - loss: 4.2203 - accuracy: 0.0972\n",
      "Epoch 266/300\n",
      "32/32 - 0s - loss: 4.2203 - accuracy: 0.1160\n",
      "Epoch 267/300\n",
      "32/32 - 0s - loss: 4.2203 - accuracy: 0.1034\n",
      "Epoch 268/300\n",
      "32/32 - 0s - loss: 4.2203 - accuracy: 0.1003\n",
      "Epoch 269/300\n",
      "32/32 - 0s - loss: 4.2203 - accuracy: 0.1191\n",
      "Epoch 270/300\n",
      "32/32 - 0s - loss: 4.2203 - accuracy: 0.0940\n",
      "Epoch 271/300\n",
      "32/32 - 0s - loss: 4.2203 - accuracy: 0.1066\n",
      "Epoch 272/300\n",
      "32/32 - 0s - loss: 4.2203 - accuracy: 0.1066\n",
      "Epoch 273/300\n",
      "32/32 - 0s - loss: 4.2203 - accuracy: 0.0752\n",
      "Epoch 274/300\n",
      "32/32 - 0s - loss: 4.2203 - accuracy: 0.0846\n",
      "Epoch 275/300\n",
      "32/32 - 0s - loss: 4.2203 - accuracy: 0.0846\n",
      "Epoch 276/300\n",
      "32/32 - 0s - loss: 4.2203 - accuracy: 0.0627\n",
      "Epoch 277/300\n",
      "32/32 - 0s - loss: 4.2203 - accuracy: 0.0784\n",
      "Epoch 278/300\n",
      "32/32 - 0s - loss: 4.2203 - accuracy: 0.0940\n",
      "Epoch 279/300\n",
      "32/32 - 0s - loss: 4.2203 - accuracy: 0.0878\n",
      "Epoch 280/300\n",
      "32/32 - 0s - loss: 4.2203 - accuracy: 0.0784\n",
      "Epoch 281/300\n",
      "32/32 - 0s - loss: 4.2203 - accuracy: 0.0940\n",
      "Epoch 282/300\n",
      "32/32 - 0s - loss: 4.2203 - accuracy: 0.0846\n",
      "Epoch 283/300\n",
      "32/32 - 0s - loss: 4.2203 - accuracy: 0.0972\n",
      "Epoch 284/300\n",
      "32/32 - 0s - loss: 4.2203 - accuracy: 0.1034\n",
      "Epoch 285/300\n",
      "32/32 - 0s - loss: 4.2203 - accuracy: 0.1066\n",
      "Epoch 286/300\n",
      "32/32 - 0s - loss: 4.2203 - accuracy: 0.1254\n",
      "Epoch 287/300\n",
      "32/32 - 0s - loss: 4.2203 - accuracy: 0.0846\n",
      "Epoch 288/300\n",
      "32/32 - 0s - loss: 4.2203 - accuracy: 0.0940\n",
      "Epoch 289/300\n",
      "32/32 - 0s - loss: 4.2203 - accuracy: 0.1097\n",
      "Epoch 290/300\n",
      "32/32 - 0s - loss: 4.2203 - accuracy: 0.0690\n",
      "Epoch 291/300\n",
      "32/32 - 0s - loss: 4.2203 - accuracy: 0.1066\n",
      "Epoch 292/300\n",
      "32/32 - 0s - loss: 4.2203 - accuracy: 0.0784\n",
      "Epoch 293/300\n",
      "32/32 - 0s - loss: 4.2203 - accuracy: 0.0752\n",
      "Epoch 294/300\n",
      "32/32 - 0s - loss: 4.2203 - accuracy: 0.1097\n",
      "Epoch 295/300\n",
      "32/32 - 0s - loss: 4.2203 - accuracy: 0.0721\n",
      "Epoch 296/300\n",
      "32/32 - 0s - loss: 4.2203 - accuracy: 0.1160\n",
      "Epoch 297/300\n",
      "32/32 - 0s - loss: 4.2203 - accuracy: 0.0752\n",
      "Epoch 298/300\n",
      "32/32 - 0s - loss: 4.2203 - accuracy: 0.0846\n",
      "Epoch 299/300\n",
      "32/32 - 0s - loss: 4.2203 - accuracy: 0.1003\n",
      "Epoch 300/300\n",
      "32/32 - 0s - loss: 4.2203 - accuracy: 0.1003\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fb26413c9a0>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(LSTM(10, input_shape=(1,34), activation='tanh', recurrent_activation='exponential', use_bias=False))\n",
    "\n",
    "model.add(Dense(units=15,input_dim=34,kernel_initializer='glorot_uniform',bias_initializer='zeros',activation='softmax'))\n",
    "\n",
    "#model.add(Dense(units=5,input_dim=320,kernel_initializer='glorot_uniform',bias_initializer='zeros',activation='softmax'))\n",
    "\n",
    "model.compile(loss='mean_squared_error', optimizer='adam', metrics=['accuracy'])\n",
    "model.fit(X_train, y_train, epochs=300, batch_size=10, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "3c2bb60d-53ad-4553-9346-4f074953a25a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.3126934984520124, 0.2517985611510791)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "3da87392-f58b-4dfa-ac80-f5915ee0bdb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "3/3 [==============================] - 1s 71ms/step - loss: 3.8844 - accuracy: 0.1749 - val_loss: 4.3924 - val_accuracy: 0.1979\n",
      "Epoch 2/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 3.8729 - accuracy: 0.1749 - val_loss: 4.3825 - val_accuracy: 0.1979\n",
      "Epoch 3/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 3.8628 - accuracy: 0.1749 - val_loss: 4.3742 - val_accuracy: 0.1979\n",
      "Epoch 4/1000\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 3.8543 - accuracy: 0.1749 - val_loss: 4.3677 - val_accuracy: 0.1979\n",
      "Epoch 5/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 3.8479 - accuracy: 0.1749 - val_loss: 4.3629 - val_accuracy: 0.1979\n",
      "Epoch 6/1000\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 3.8431 - accuracy: 0.1749 - val_loss: 4.3595 - val_accuracy: 0.1979\n",
      "Epoch 7/1000\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 3.8397 - accuracy: 0.1749 - val_loss: 4.3571 - val_accuracy: 0.1979\n",
      "Epoch 8/1000\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 3.8373 - accuracy: 0.1749 - val_loss: 4.3554 - val_accuracy: 0.1979\n",
      "Epoch 9/1000\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 3.8356 - accuracy: 0.1749 - val_loss: 4.3543 - val_accuracy: 0.1979\n",
      "Epoch 10/1000\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 3.8346 - accuracy: 0.1749 - val_loss: 4.3537 - val_accuracy: 0.1875\n",
      "Epoch 11/1000\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 3.8339 - accuracy: 0.1883 - val_loss: 4.3533 - val_accuracy: 0.2188\n",
      "Epoch 12/1000\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 3.8336 - accuracy: 0.2018 - val_loss: 4.3531 - val_accuracy: 0.2500\n",
      "Epoch 13/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 3.8333 - accuracy: 0.1973 - val_loss: 4.3530 - val_accuracy: 0.2500\n",
      "Epoch 14/1000\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 3.8332 - accuracy: 0.2063 - val_loss: 4.3529 - val_accuracy: 0.2500\n",
      "Epoch 15/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 3.8331 - accuracy: 0.2332 - val_loss: 4.3528 - val_accuracy: 0.2708\n",
      "Epoch 16/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 3.8331 - accuracy: 0.2466 - val_loss: 4.3528 - val_accuracy: 0.2396\n",
      "Epoch 17/1000\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 3.8330 - accuracy: 0.2332 - val_loss: 4.3527 - val_accuracy: 0.2604\n",
      "Epoch 18/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 3.8330 - accuracy: 0.2287 - val_loss: 4.3527 - val_accuracy: 0.2500\n",
      "Epoch 19/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 3.8330 - accuracy: 0.2511 - val_loss: 4.3527 - val_accuracy: 0.2396\n",
      "Epoch 20/1000\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 3.8330 - accuracy: 0.2511 - val_loss: 4.3527 - val_accuracy: 0.2500\n",
      "Epoch 21/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 3.8330 - accuracy: 0.2287 - val_loss: 4.3527 - val_accuracy: 0.2396\n",
      "Epoch 22/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 3.8330 - accuracy: 0.2242 - val_loss: 4.3527 - val_accuracy: 0.2292\n",
      "Epoch 23/1000\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 3.8329 - accuracy: 0.2108 - val_loss: 4.3526 - val_accuracy: 0.2188\n",
      "Epoch 24/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 3.8329 - accuracy: 0.2063 - val_loss: 4.3526 - val_accuracy: 0.2188\n",
      "Epoch 25/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 3.8329 - accuracy: 0.1928 - val_loss: 4.3526 - val_accuracy: 0.2188\n",
      "Epoch 26/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 3.8329 - accuracy: 0.1928 - val_loss: 4.3526 - val_accuracy: 0.2083\n",
      "Epoch 27/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 3.8329 - accuracy: 0.1794 - val_loss: 4.3526 - val_accuracy: 0.2083\n",
      "Epoch 28/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 3.8329 - accuracy: 0.1704 - val_loss: 4.3526 - val_accuracy: 0.2083\n",
      "Epoch 29/1000\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 3.8329 - accuracy: 0.1704 - val_loss: 4.3526 - val_accuracy: 0.1979\n",
      "Epoch 30/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 3.8329 - accuracy: 0.1659 - val_loss: 4.3526 - val_accuracy: 0.1979\n",
      "Epoch 31/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 3.8329 - accuracy: 0.1614 - val_loss: 4.3526 - val_accuracy: 0.1979\n",
      "Epoch 32/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 3.8329 - accuracy: 0.1570 - val_loss: 4.3526 - val_accuracy: 0.1979\n",
      "Epoch 33/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 3.8329 - accuracy: 0.1659 - val_loss: 4.3526 - val_accuracy: 0.2188\n",
      "Epoch 34/1000\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 3.8329 - accuracy: 0.1928 - val_loss: 4.3526 - val_accuracy: 0.2083\n",
      "Epoch 35/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 3.8329 - accuracy: 0.1973 - val_loss: 4.3526 - val_accuracy: 0.2083\n",
      "Epoch 36/1000\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 3.8329 - accuracy: 0.1973 - val_loss: 4.3526 - val_accuracy: 0.2083\n",
      "Epoch 37/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 3.8329 - accuracy: 0.2018 - val_loss: 4.3526 - val_accuracy: 0.1875\n",
      "Epoch 38/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 3.8329 - accuracy: 0.1973 - val_loss: 4.3526 - val_accuracy: 0.1771\n",
      "Epoch 39/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 3.8329 - accuracy: 0.2018 - val_loss: 4.3526 - val_accuracy: 0.1771\n",
      "Epoch 40/1000\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 3.8329 - accuracy: 0.1973 - val_loss: 4.3526 - val_accuracy: 0.1667\n",
      "Epoch 41/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 3.8329 - accuracy: 0.1839 - val_loss: 4.3526 - val_accuracy: 0.1771\n",
      "Epoch 42/1000\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 3.8329 - accuracy: 0.1839 - val_loss: 4.3526 - val_accuracy: 0.1771\n",
      "Epoch 43/1000\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 3.8329 - accuracy: 0.1883 - val_loss: 4.3526 - val_accuracy: 0.1875\n",
      "Epoch 44/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 3.8329 - accuracy: 0.1928 - val_loss: 4.3526 - val_accuracy: 0.1875\n",
      "Epoch 45/1000\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 3.8329 - accuracy: 0.1928 - val_loss: 4.3526 - val_accuracy: 0.1771\n",
      "Epoch 46/1000\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 3.8329 - accuracy: 0.2018 - val_loss: 4.3526 - val_accuracy: 0.1875\n",
      "Epoch 47/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 3.8329 - accuracy: 0.2018 - val_loss: 4.3526 - val_accuracy: 0.1875\n",
      "Epoch 48/1000\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 3.8329 - accuracy: 0.2018 - val_loss: 4.3526 - val_accuracy: 0.1875\n",
      "Epoch 49/1000\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 3.8329 - accuracy: 0.2018 - val_loss: 4.3526 - val_accuracy: 0.1979\n",
      "Epoch 50/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 3.8329 - accuracy: 0.2018 - val_loss: 4.3526 - val_accuracy: 0.1979\n",
      "Epoch 51/1000\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 3.8329 - accuracy: 0.2018 - val_loss: 4.3526 - val_accuracy: 0.1979\n",
      "Epoch 52/1000\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 3.8329 - accuracy: 0.2063 - val_loss: 4.3526 - val_accuracy: 0.1979\n",
      "Epoch 53/1000\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 3.8329 - accuracy: 0.2063 - val_loss: 4.3526 - val_accuracy: 0.1979\n",
      "Epoch 54/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 3.8329 - accuracy: 0.2063 - val_loss: 4.3526 - val_accuracy: 0.1979\n",
      "Epoch 55/1000\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 3.8329 - accuracy: 0.2063 - val_loss: 4.3526 - val_accuracy: 0.1979\n",
      "Epoch 56/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 3.8329 - accuracy: 0.2063 - val_loss: 4.3526 - val_accuracy: 0.1979\n",
      "Epoch 57/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 3.8329 - accuracy: 0.2063 - val_loss: 4.3526 - val_accuracy: 0.2083\n",
      "Epoch 58/1000\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 3.8329 - accuracy: 0.2063 - val_loss: 4.3526 - val_accuracy: 0.2188\n",
      "Epoch 59/1000\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 3.8329 - accuracy: 0.2152 - val_loss: 4.3526 - val_accuracy: 0.2188\n",
      "Epoch 60/1000\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 3.8329 - accuracy: 0.2152 - val_loss: 4.3526 - val_accuracy: 0.2188\n",
      "Epoch 61/1000\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 3.8329 - accuracy: 0.2063 - val_loss: 4.3526 - val_accuracy: 0.2188\n",
      "Epoch 62/1000\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 3.8329 - accuracy: 0.2108 - val_loss: 4.3526 - val_accuracy: 0.2188\n",
      "Epoch 63/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 3.8329 - accuracy: 0.2108 - val_loss: 4.3526 - val_accuracy: 0.2188\n",
      "Epoch 64/1000\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 3.8329 - accuracy: 0.2152 - val_loss: 4.3526 - val_accuracy: 0.2292\n",
      "Epoch 65/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 3.8329 - accuracy: 0.2152 - val_loss: 4.3526 - val_accuracy: 0.2188\n",
      "Epoch 66/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 3.8329 - accuracy: 0.2108 - val_loss: 4.3526 - val_accuracy: 0.2188\n",
      "Epoch 67/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 3.8329 - accuracy: 0.2152 - val_loss: 4.3525 - val_accuracy: 0.2083\n",
      "Epoch 68/1000\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 3.8329 - accuracy: 0.2197 - val_loss: 4.3525 - val_accuracy: 0.2188\n",
      "Epoch 69/1000\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 3.8329 - accuracy: 0.2197 - val_loss: 4.3525 - val_accuracy: 0.2083\n",
      "Epoch 70/1000\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 3.8329 - accuracy: 0.2152 - val_loss: 4.3525 - val_accuracy: 0.2188\n",
      "Epoch 71/1000\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 3.8329 - accuracy: 0.2152 - val_loss: 4.3525 - val_accuracy: 0.2292\n",
      "Epoch 72/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 3.8329 - accuracy: 0.2197 - val_loss: 4.3525 - val_accuracy: 0.2292\n",
      "Epoch 73/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 3.8329 - accuracy: 0.2197 - val_loss: 4.3525 - val_accuracy: 0.2188\n",
      "Epoch 74/1000\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 3.8329 - accuracy: 0.2197 - val_loss: 4.3525 - val_accuracy: 0.2188\n",
      "Epoch 75/1000\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 3.8329 - accuracy: 0.2197 - val_loss: 4.3525 - val_accuracy: 0.2188\n",
      "Epoch 76/1000\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 3.8329 - accuracy: 0.2242 - val_loss: 4.3525 - val_accuracy: 0.2292\n",
      "Epoch 77/1000\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 3.8329 - accuracy: 0.2287 - val_loss: 4.3525 - val_accuracy: 0.2292\n",
      "Epoch 78/1000\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 3.8329 - accuracy: 0.2287 - val_loss: 4.3525 - val_accuracy: 0.2292\n",
      "Epoch 79/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 3.8329 - accuracy: 0.2287 - val_loss: 4.3525 - val_accuracy: 0.2292\n",
      "Epoch 80/1000\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 3.8329 - accuracy: 0.2287 - val_loss: 4.3525 - val_accuracy: 0.2188\n",
      "Epoch 81/1000\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 3.8329 - accuracy: 0.2332 - val_loss: 4.3525 - val_accuracy: 0.2188\n",
      "Epoch 82/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 3.8329 - accuracy: 0.2332 - val_loss: 4.3525 - val_accuracy: 0.2083\n",
      "Epoch 83/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 3.8329 - accuracy: 0.2332 - val_loss: 4.3525 - val_accuracy: 0.2083\n",
      "Epoch 84/1000\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 3.8329 - accuracy: 0.2332 - val_loss: 4.3525 - val_accuracy: 0.2083\n",
      "Epoch 85/1000\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 3.8329 - accuracy: 0.2332 - val_loss: 4.3525 - val_accuracy: 0.2083\n",
      "Epoch 86/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 3.8329 - accuracy: 0.2332 - val_loss: 4.3525 - val_accuracy: 0.2083\n",
      "Epoch 87/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 3.8329 - accuracy: 0.2332 - val_loss: 4.3525 - val_accuracy: 0.2083\n",
      "Epoch 88/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 3.8329 - accuracy: 0.2332 - val_loss: 4.3525 - val_accuracy: 0.2083\n",
      "Epoch 89/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 3.8329 - accuracy: 0.2332 - val_loss: 4.3525 - val_accuracy: 0.2083\n",
      "Epoch 90/1000\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 3.8329 - accuracy: 0.2332 - val_loss: 4.3525 - val_accuracy: 0.2083\n",
      "Epoch 91/1000\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 3.8329 - accuracy: 0.2287 - val_loss: 4.3525 - val_accuracy: 0.2083\n",
      "Epoch 92/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 3.8329 - accuracy: 0.2332 - val_loss: 4.3525 - val_accuracy: 0.2083\n",
      "Epoch 93/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 3.8329 - accuracy: 0.2332 - val_loss: 4.3525 - val_accuracy: 0.1979\n",
      "Epoch 94/1000\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 3.8329 - accuracy: 0.2332 - val_loss: 4.3525 - val_accuracy: 0.1979\n",
      "Epoch 95/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 3.8329 - accuracy: 0.2332 - val_loss: 4.3525 - val_accuracy: 0.1979\n",
      "Epoch 96/1000\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 3.8329 - accuracy: 0.2377 - val_loss: 4.3525 - val_accuracy: 0.1979\n",
      "Epoch 97/1000\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 3.8329 - accuracy: 0.2332 - val_loss: 4.3525 - val_accuracy: 0.1979\n",
      "Epoch 98/1000\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 3.8329 - accuracy: 0.2332 - val_loss: 4.3525 - val_accuracy: 0.1875\n",
      "Epoch 99/1000\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 3.8329 - accuracy: 0.2377 - val_loss: 4.3525 - val_accuracy: 0.1875\n",
      "Epoch 100/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 3.8329 - accuracy: 0.2332 - val_loss: 4.3525 - val_accuracy: 0.1875\n",
      "Epoch 101/1000\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 3.8329 - accuracy: 0.2332 - val_loss: 4.3525 - val_accuracy: 0.1875\n",
      "Epoch 102/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 3.8329 - accuracy: 0.2377 - val_loss: 4.3525 - val_accuracy: 0.1875\n",
      "Epoch 103/1000\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 3.8329 - accuracy: 0.2422 - val_loss: 4.3525 - val_accuracy: 0.1875\n",
      "Epoch 104/1000\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 3.8329 - accuracy: 0.2377 - val_loss: 4.3525 - val_accuracy: 0.1875\n",
      "Epoch 105/1000\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 3.8329 - accuracy: 0.2377 - val_loss: 4.3525 - val_accuracy: 0.1875\n",
      "Epoch 106/1000\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 3.8329 - accuracy: 0.2377 - val_loss: 4.3525 - val_accuracy: 0.1875\n",
      "Epoch 107/1000\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 3.8329 - accuracy: 0.2377 - val_loss: 4.3525 - val_accuracy: 0.1771\n",
      "Epoch 108/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 3.8329 - accuracy: 0.2377 - val_loss: 4.3525 - val_accuracy: 0.1771\n",
      "Epoch 109/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 3.8329 - accuracy: 0.2377 - val_loss: 4.3525 - val_accuracy: 0.1667\n",
      "Epoch 110/1000\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 3.8329 - accuracy: 0.2377 - val_loss: 4.3525 - val_accuracy: 0.1667\n",
      "Epoch 111/1000\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 3.8329 - accuracy: 0.2377 - val_loss: 4.3525 - val_accuracy: 0.1667\n",
      "Epoch 112/1000\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 3.8329 - accuracy: 0.2422 - val_loss: 4.3525 - val_accuracy: 0.1667\n",
      "Epoch 113/1000\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 3.8329 - accuracy: 0.2422 - val_loss: 4.3525 - val_accuracy: 0.1771\n",
      "Epoch 114/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 3.8329 - accuracy: 0.2422 - val_loss: 4.3525 - val_accuracy: 0.1771\n",
      "Epoch 115/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 3.8329 - accuracy: 0.2422 - val_loss: 4.3525 - val_accuracy: 0.1875\n",
      "Epoch 116/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 3.8329 - accuracy: 0.2377 - val_loss: 4.3525 - val_accuracy: 0.1875\n",
      "Epoch 117/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 3.8329 - accuracy: 0.2377 - val_loss: 4.3525 - val_accuracy: 0.1875\n",
      "Epoch 118/1000\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 3.8329 - accuracy: 0.2377 - val_loss: 4.3525 - val_accuracy: 0.1875\n",
      "Epoch 119/1000\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 3.8329 - accuracy: 0.2377 - val_loss: 4.3525 - val_accuracy: 0.1875\n",
      "Epoch 120/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 3.8329 - accuracy: 0.2377 - val_loss: 4.3525 - val_accuracy: 0.1979\n",
      "Epoch 121/1000\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 3.8329 - accuracy: 0.2377 - val_loss: 4.3525 - val_accuracy: 0.1979\n",
      "Epoch 122/1000\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 3.8329 - accuracy: 0.2377 - val_loss: 4.3525 - val_accuracy: 0.1875\n",
      "Epoch 123/1000\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 3.8329 - accuracy: 0.2377 - val_loss: 4.3525 - val_accuracy: 0.1875\n",
      "Epoch 124/1000\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 3.8329 - accuracy: 0.2332 - val_loss: 4.3525 - val_accuracy: 0.1875\n",
      "Epoch 125/1000\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 3.8329 - accuracy: 0.2332 - val_loss: 4.3525 - val_accuracy: 0.1875\n",
      "Epoch 126/1000\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 3.8329 - accuracy: 0.2287 - val_loss: 4.3525 - val_accuracy: 0.1875\n",
      "Epoch 127/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 3.8329 - accuracy: 0.2287 - val_loss: 4.3525 - val_accuracy: 0.1875\n",
      "Epoch 128/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 3.8329 - accuracy: 0.2242 - val_loss: 4.3525 - val_accuracy: 0.1875\n",
      "Epoch 129/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 3.8329 - accuracy: 0.2287 - val_loss: 4.3525 - val_accuracy: 0.1875\n",
      "Epoch 130/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 3.8329 - accuracy: 0.2287 - val_loss: 4.3525 - val_accuracy: 0.1875\n",
      "Epoch 131/1000\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 3.8328 - accuracy: 0.2287 - val_loss: 4.3525 - val_accuracy: 0.1875\n",
      "Epoch 132/1000\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 3.8329 - accuracy: 0.2287 - val_loss: 4.3525 - val_accuracy: 0.1875\n",
      "Epoch 133/1000\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 3.8328 - accuracy: 0.2287 - val_loss: 4.3525 - val_accuracy: 0.1875\n",
      "Epoch 134/1000\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 3.8328 - accuracy: 0.2287 - val_loss: 4.3525 - val_accuracy: 0.1875\n",
      "Epoch 135/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 3.8328 - accuracy: 0.2287 - val_loss: 4.3525 - val_accuracy: 0.1875\n",
      "Epoch 136/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 3.8328 - accuracy: 0.2287 - val_loss: 4.3525 - val_accuracy: 0.1875\n",
      "Epoch 137/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 3.8328 - accuracy: 0.2287 - val_loss: 4.3525 - val_accuracy: 0.1875\n",
      "Epoch 138/1000\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 3.8328 - accuracy: 0.2287 - val_loss: 4.3525 - val_accuracy: 0.1875\n",
      "Epoch 139/1000\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 3.8328 - accuracy: 0.2287 - val_loss: 4.3525 - val_accuracy: 0.1875\n",
      "Epoch 140/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 3.8328 - accuracy: 0.2287 - val_loss: 4.3525 - val_accuracy: 0.1875\n",
      "Epoch 141/1000\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 3.8328 - accuracy: 0.2287 - val_loss: 4.3525 - val_accuracy: 0.1875\n",
      "Epoch 142/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 3.8328 - accuracy: 0.2287 - val_loss: 4.3525 - val_accuracy: 0.1875\n",
      "Epoch 143/1000\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 3.8328 - accuracy: 0.2332 - val_loss: 4.3525 - val_accuracy: 0.1875\n",
      "Epoch 144/1000\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 3.8328 - accuracy: 0.2332 - val_loss: 4.3525 - val_accuracy: 0.1875\n",
      "Epoch 145/1000\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 3.8328 - accuracy: 0.2377 - val_loss: 4.3525 - val_accuracy: 0.1875\n",
      "Epoch 146/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 3.8328 - accuracy: 0.2377 - val_loss: 4.3525 - val_accuracy: 0.1875\n",
      "Epoch 147/1000\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 3.8328 - accuracy: 0.2332 - val_loss: 4.3525 - val_accuracy: 0.1875\n",
      "Epoch 148/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 3.8328 - accuracy: 0.2287 - val_loss: 4.3525 - val_accuracy: 0.1875\n",
      "Epoch 149/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 3.8328 - accuracy: 0.2287 - val_loss: 4.3525 - val_accuracy: 0.1875\n",
      "Epoch 150/1000\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 3.8328 - accuracy: 0.2287 - val_loss: 4.3525 - val_accuracy: 0.1875\n",
      "Epoch 151/1000\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 3.8328 - accuracy: 0.2332 - val_loss: 4.3525 - val_accuracy: 0.1875\n",
      "Epoch 152/1000\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 3.8328 - accuracy: 0.2332 - val_loss: 4.3525 - val_accuracy: 0.1875\n",
      "Epoch 153/1000\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 3.8328 - accuracy: 0.2332 - val_loss: 4.3525 - val_accuracy: 0.1875\n",
      "Epoch 154/1000\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 3.8328 - accuracy: 0.2332 - val_loss: 4.3525 - val_accuracy: 0.1875\n",
      "Epoch 155/1000\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 3.8328 - accuracy: 0.2287 - val_loss: 4.3525 - val_accuracy: 0.1875\n",
      "Epoch 156/1000\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 3.8328 - accuracy: 0.2287 - val_loss: 4.3525 - val_accuracy: 0.1875\n",
      "Epoch 157/1000\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 3.8328 - accuracy: 0.2332 - val_loss: 4.3525 - val_accuracy: 0.1875\n",
      "Epoch 158/1000\n",
      "3/3 [==============================] - 0s 40ms/step - loss: 3.8328 - accuracy: 0.2332 - val_loss: 4.3525 - val_accuracy: 0.1875\n",
      "Epoch 159/1000\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 3.8328 - accuracy: 0.2332 - val_loss: 4.3525 - val_accuracy: 0.1875\n",
      "Epoch 160/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 3.8328 - accuracy: 0.2332 - val_loss: 4.3525 - val_accuracy: 0.1771\n",
      "Epoch 161/1000\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 3.8328 - accuracy: 0.2332 - val_loss: 4.3525 - val_accuracy: 0.1771\n",
      "Epoch 162/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 3.8328 - accuracy: 0.2332 - val_loss: 4.3525 - val_accuracy: 0.1875\n",
      "Epoch 163/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 3.8328 - accuracy: 0.2332 - val_loss: 4.3525 - val_accuracy: 0.1875\n",
      "Epoch 164/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 3.8328 - accuracy: 0.2377 - val_loss: 4.3525 - val_accuracy: 0.1771\n",
      "Epoch 165/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 3.8328 - accuracy: 0.2332 - val_loss: 4.3525 - val_accuracy: 0.1771\n",
      "Epoch 166/1000\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 3.8328 - accuracy: 0.2332 - val_loss: 4.3525 - val_accuracy: 0.1771\n",
      "Epoch 167/1000\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 3.8328 - accuracy: 0.2332 - val_loss: 4.3525 - val_accuracy: 0.1771\n",
      "Epoch 168/1000\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 3.8328 - accuracy: 0.2332 - val_loss: 4.3525 - val_accuracy: 0.1771\n",
      "Epoch 169/1000\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 3.8328 - accuracy: 0.2332 - val_loss: 4.3525 - val_accuracy: 0.1771\n",
      "Epoch 170/1000\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 3.8328 - accuracy: 0.2332 - val_loss: 4.3525 - val_accuracy: 0.1771\n",
      "Epoch 171/1000\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 3.8328 - accuracy: 0.2287 - val_loss: 4.3525 - val_accuracy: 0.1771\n",
      "Epoch 172/1000\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 3.8328 - accuracy: 0.2287 - val_loss: 4.3525 - val_accuracy: 0.1771\n",
      "Epoch 173/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 3.8328 - accuracy: 0.2287 - val_loss: 4.3525 - val_accuracy: 0.1771\n",
      "Epoch 174/1000\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 3.8328 - accuracy: 0.2287 - val_loss: 4.3525 - val_accuracy: 0.1771\n",
      "Epoch 175/1000\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 3.8328 - accuracy: 0.2287 - val_loss: 4.3525 - val_accuracy: 0.1771\n",
      "Epoch 176/1000\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 3.8328 - accuracy: 0.2287 - val_loss: 4.3525 - val_accuracy: 0.1771\n",
      "Epoch 177/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 3.8328 - accuracy: 0.2287 - val_loss: 4.3525 - val_accuracy: 0.1771\n",
      "Epoch 178/1000\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 3.8328 - accuracy: 0.2287 - val_loss: 4.3525 - val_accuracy: 0.1771\n",
      "Epoch 179/1000\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 3.8328 - accuracy: 0.2332 - val_loss: 4.3525 - val_accuracy: 0.1771\n",
      "Epoch 180/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 3.8328 - accuracy: 0.2332 - val_loss: 4.3525 - val_accuracy: 0.1771\n",
      "Epoch 181/1000\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 3.8328 - accuracy: 0.2332 - val_loss: 4.3525 - val_accuracy: 0.1771\n",
      "Epoch 182/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 3.8328 - accuracy: 0.2287 - val_loss: 4.3525 - val_accuracy: 0.1771\n",
      "Epoch 183/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 3.8328 - accuracy: 0.2287 - val_loss: 4.3525 - val_accuracy: 0.1771\n",
      "Epoch 184/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 3.8328 - accuracy: 0.2287 - val_loss: 4.3525 - val_accuracy: 0.1771\n",
      "Epoch 185/1000\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 3.8328 - accuracy: 0.2287 - val_loss: 4.3525 - val_accuracy: 0.1771\n",
      "Epoch 186/1000\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 3.8328 - accuracy: 0.2287 - val_loss: 4.3525 - val_accuracy: 0.1771\n",
      "Epoch 187/1000\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 3.8328 - accuracy: 0.2287 - val_loss: 4.3525 - val_accuracy: 0.1771\n",
      "Epoch 188/1000\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 3.8328 - accuracy: 0.2332 - val_loss: 4.3525 - val_accuracy: 0.1771\n",
      "Epoch 189/1000\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 3.8328 - accuracy: 0.2332 - val_loss: 4.3525 - val_accuracy: 0.1771\n",
      "Epoch 190/1000\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 3.8328 - accuracy: 0.2332 - val_loss: 4.3525 - val_accuracy: 0.1667\n",
      "Epoch 191/1000\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 3.8328 - accuracy: 0.2332 - val_loss: 4.3525 - val_accuracy: 0.1667\n",
      "Epoch 192/1000\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 3.8328 - accuracy: 0.2332 - val_loss: 4.3525 - val_accuracy: 0.1667\n",
      "Epoch 193/1000\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 3.8328 - accuracy: 0.2332 - val_loss: 4.3525 - val_accuracy: 0.1667\n",
      "Epoch 194/1000\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 3.8328 - accuracy: 0.2332 - val_loss: 4.3525 - val_accuracy: 0.1667\n",
      "Epoch 195/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 3.8328 - accuracy: 0.2332 - val_loss: 4.3525 - val_accuracy: 0.1667\n",
      "Epoch 196/1000\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 3.8328 - accuracy: 0.2332 - val_loss: 4.3525 - val_accuracy: 0.1667\n",
      "Epoch 197/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 3.8328 - accuracy: 0.2332 - val_loss: 4.3525 - val_accuracy: 0.1667\n",
      "Epoch 198/1000\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 3.8328 - accuracy: 0.2332 - val_loss: 4.3525 - val_accuracy: 0.1562\n",
      "Epoch 199/1000\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 3.8328 - accuracy: 0.2332 - val_loss: 4.3525 - val_accuracy: 0.1562\n",
      "Epoch 200/1000\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 3.8328 - accuracy: 0.2332 - val_loss: 4.3525 - val_accuracy: 0.1562\n",
      "Epoch 201/1000\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 3.8328 - accuracy: 0.2332 - val_loss: 4.3525 - val_accuracy: 0.1562\n",
      "Epoch 202/1000\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 3.8328 - accuracy: 0.2332 - val_loss: 4.3525 - val_accuracy: 0.1562\n",
      "Epoch 203/1000\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 3.8328 - accuracy: 0.2332 - val_loss: 4.3525 - val_accuracy: 0.1562\n",
      "Epoch 204/1000\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 3.8328 - accuracy: 0.2332 - val_loss: 4.3525 - val_accuracy: 0.1562\n",
      "Epoch 205/1000\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 3.8328 - accuracy: 0.2332 - val_loss: 4.3525 - val_accuracy: 0.1562\n",
      "Epoch 206/1000\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 3.8328 - accuracy: 0.2332 - val_loss: 4.3525 - val_accuracy: 0.1562\n",
      "Epoch 207/1000\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 3.8328 - accuracy: 0.2332 - val_loss: 4.3525 - val_accuracy: 0.1562\n",
      "Epoch 208/1000\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 3.8328 - accuracy: 0.2332 - val_loss: 4.3525 - val_accuracy: 0.1562\n",
      "Epoch 209/1000\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 3.8328 - accuracy: 0.2332 - val_loss: 4.3525 - val_accuracy: 0.1562\n",
      "Epoch 210/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 3.8328 - accuracy: 0.2332 - val_loss: 4.3525 - val_accuracy: 0.1562\n",
      "Epoch 211/1000\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 3.8328 - accuracy: 0.2332 - val_loss: 4.3525 - val_accuracy: 0.1562\n",
      "Epoch 212/1000\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 3.8328 - accuracy: 0.2332 - val_loss: 4.3525 - val_accuracy: 0.1562\n",
      "Epoch 213/1000\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 3.8328 - accuracy: 0.2332 - val_loss: 4.3525 - val_accuracy: 0.1562\n",
      "Epoch 214/1000\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 3.8328 - accuracy: 0.2332 - val_loss: 4.3525 - val_accuracy: 0.1562\n",
      "Epoch 215/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 3.8328 - accuracy: 0.2332 - val_loss: 4.3525 - val_accuracy: 0.1562\n",
      "Epoch 216/1000\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 3.8328 - accuracy: 0.2332 - val_loss: 4.3525 - val_accuracy: 0.1562\n",
      "Epoch 217/1000\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 3.8328 - accuracy: 0.2377 - val_loss: 4.3525 - val_accuracy: 0.1562\n",
      "Epoch 218/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 3.8328 - accuracy: 0.2377 - val_loss: 4.3525 - val_accuracy: 0.1562\n",
      "Epoch 219/1000\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 3.8328 - accuracy: 0.2377 - val_loss: 4.3525 - val_accuracy: 0.1562\n",
      "Epoch 220/1000\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 3.8328 - accuracy: 0.2377 - val_loss: 4.3525 - val_accuracy: 0.1562\n",
      "Epoch 221/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 3.8328 - accuracy: 0.2377 - val_loss: 4.3525 - val_accuracy: 0.1562\n",
      "Epoch 222/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 3.8328 - accuracy: 0.2332 - val_loss: 4.3525 - val_accuracy: 0.1562\n",
      "Epoch 223/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 3.8328 - accuracy: 0.2332 - val_loss: 4.3525 - val_accuracy: 0.1562\n",
      "Epoch 224/1000\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 3.8328 - accuracy: 0.2332 - val_loss: 4.3525 - val_accuracy: 0.1562\n",
      "Epoch 225/1000\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 3.8328 - accuracy: 0.2332 - val_loss: 4.3525 - val_accuracy: 0.1562\n",
      "Epoch 226/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 3.8328 - accuracy: 0.2332 - val_loss: 4.3525 - val_accuracy: 0.1562\n",
      "Epoch 227/1000\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 3.8328 - accuracy: 0.2332 - val_loss: 4.3525 - val_accuracy: 0.1562\n",
      "Epoch 228/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 3.8328 - accuracy: 0.2332 - val_loss: 4.3525 - val_accuracy: 0.1562\n",
      "Epoch 229/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 3.8328 - accuracy: 0.2332 - val_loss: 4.3525 - val_accuracy: 0.1562\n",
      "Epoch 230/1000\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 3.8328 - accuracy: 0.2332 - val_loss: 4.3525 - val_accuracy: 0.1562\n",
      "Epoch 231/1000\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 3.8328 - accuracy: 0.2332 - val_loss: 4.3525 - val_accuracy: 0.1562\n",
      "Epoch 232/1000\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 3.8328 - accuracy: 0.2332 - val_loss: 4.3525 - val_accuracy: 0.1562\n",
      "Epoch 233/1000\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 3.8328 - accuracy: 0.2332 - val_loss: 4.3525 - val_accuracy: 0.1667\n",
      "Epoch 234/1000\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 3.8328 - accuracy: 0.2332 - val_loss: 4.3525 - val_accuracy: 0.1667\n",
      "Epoch 235/1000\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 3.8328 - accuracy: 0.2332 - val_loss: 4.3525 - val_accuracy: 0.1667\n",
      "Epoch 236/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 3.8328 - accuracy: 0.2377 - val_loss: 4.3525 - val_accuracy: 0.1667\n",
      "Epoch 237/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 3.8328 - accuracy: 0.2377 - val_loss: 4.3525 - val_accuracy: 0.1667\n",
      "Epoch 238/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 3.8328 - accuracy: 0.2377 - val_loss: 4.3525 - val_accuracy: 0.1667\n",
      "Epoch 239/1000\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 3.8328 - accuracy: 0.2377 - val_loss: 4.3525 - val_accuracy: 0.1667\n",
      "Epoch 240/1000\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 3.8328 - accuracy: 0.2332 - val_loss: 4.3525 - val_accuracy: 0.1667\n",
      "Epoch 241/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 3.8328 - accuracy: 0.2332 - val_loss: 4.3525 - val_accuracy: 0.1667\n",
      "Epoch 242/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 3.8328 - accuracy: 0.2332 - val_loss: 4.3525 - val_accuracy: 0.1667\n",
      "Epoch 243/1000\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 3.8328 - accuracy: 0.2332 - val_loss: 4.3525 - val_accuracy: 0.1667\n",
      "Epoch 244/1000\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 3.8328 - accuracy: 0.2332 - val_loss: 4.3525 - val_accuracy: 0.1562\n",
      "Epoch 245/1000\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 3.8328 - accuracy: 0.2332 - val_loss: 4.3525 - val_accuracy: 0.1667\n",
      "Epoch 246/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 3.8328 - accuracy: 0.2332 - val_loss: 4.3525 - val_accuracy: 0.1667\n",
      "Epoch 247/1000\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 3.8328 - accuracy: 0.2377 - val_loss: 4.3525 - val_accuracy: 0.1667\n",
      "Epoch 248/1000\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 3.8328 - accuracy: 0.2377 - val_loss: 4.3525 - val_accuracy: 0.1667\n",
      "Epoch 249/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 3.8328 - accuracy: 0.2377 - val_loss: 4.3525 - val_accuracy: 0.1667\n",
      "Epoch 250/1000\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 3.8328 - accuracy: 0.2377 - val_loss: 4.3525 - val_accuracy: 0.1667\n",
      "Epoch 251/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 3.8328 - accuracy: 0.2377 - val_loss: 4.3525 - val_accuracy: 0.1667\n",
      "Epoch 252/1000\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 3.8328 - accuracy: 0.2377 - val_loss: 4.3525 - val_accuracy: 0.1667\n",
      "Epoch 253/1000\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 3.8328 - accuracy: 0.2377 - val_loss: 4.3525 - val_accuracy: 0.1667\n",
      "Epoch 254/1000\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 3.8328 - accuracy: 0.2377 - val_loss: 4.3525 - val_accuracy: 0.1667\n",
      "Epoch 255/1000\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 3.8328 - accuracy: 0.2377 - val_loss: 4.3525 - val_accuracy: 0.1667\n",
      "Epoch 256/1000\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 3.8328 - accuracy: 0.2377 - val_loss: 4.3525 - val_accuracy: 0.1667\n",
      "Epoch 257/1000\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 3.8328 - accuracy: 0.2377 - val_loss: 4.3525 - val_accuracy: 0.1667\n",
      "Epoch 258/1000\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 3.8328 - accuracy: 0.2377 - val_loss: 4.3525 - val_accuracy: 0.1667\n",
      "Epoch 259/1000\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 3.8328 - accuracy: 0.2377 - val_loss: 4.3525 - val_accuracy: 0.1667\n",
      "Epoch 260/1000\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 3.8328 - accuracy: 0.2377 - val_loss: 4.3525 - val_accuracy: 0.1667\n",
      "Epoch 261/1000\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 3.8328 - accuracy: 0.2377 - val_loss: 4.3525 - val_accuracy: 0.1667\n",
      "Epoch 262/1000\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 3.8328 - accuracy: 0.2377 - val_loss: 4.3525 - val_accuracy: 0.1667\n",
      "Epoch 263/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 3.8328 - accuracy: 0.2377 - val_loss: 4.3525 - val_accuracy: 0.1667\n",
      "Epoch 264/1000\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 3.8328 - accuracy: 0.2377 - val_loss: 4.3525 - val_accuracy: 0.1667\n",
      "Epoch 265/1000\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 3.8328 - accuracy: 0.2422 - val_loss: 4.3525 - val_accuracy: 0.1667\n",
      "Epoch 266/1000\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 3.8328 - accuracy: 0.2422 - val_loss: 4.3525 - val_accuracy: 0.1667\n",
      "Epoch 267/1000\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 3.8328 - accuracy: 0.2422 - val_loss: 4.3525 - val_accuracy: 0.1667\n",
      "Epoch 268/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 3.8328 - accuracy: 0.2422 - val_loss: 4.3525 - val_accuracy: 0.1667\n",
      "Epoch 269/1000\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 3.8328 - accuracy: 0.2466 - val_loss: 4.3525 - val_accuracy: 0.1667\n",
      "Epoch 270/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 3.8328 - accuracy: 0.2466 - val_loss: 4.3525 - val_accuracy: 0.1667\n",
      "Epoch 271/1000\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 3.8328 - accuracy: 0.2466 - val_loss: 4.3525 - val_accuracy: 0.1667\n",
      "Epoch 272/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 3.8328 - accuracy: 0.2466 - val_loss: 4.3525 - val_accuracy: 0.1667\n",
      "Epoch 273/1000\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 3.8328 - accuracy: 0.2466 - val_loss: 4.3525 - val_accuracy: 0.1667\n",
      "Epoch 274/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 3.8328 - accuracy: 0.2466 - val_loss: 4.3525 - val_accuracy: 0.1667\n",
      "Epoch 275/1000\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 3.8328 - accuracy: 0.2466 - val_loss: 4.3525 - val_accuracy: 0.1667\n",
      "Epoch 276/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 3.8328 - accuracy: 0.2511 - val_loss: 4.3525 - val_accuracy: 0.1771\n",
      "Epoch 277/1000\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 3.8328 - accuracy: 0.2511 - val_loss: 4.3525 - val_accuracy: 0.1771\n",
      "Epoch 278/1000\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 3.8328 - accuracy: 0.2511 - val_loss: 4.3525 - val_accuracy: 0.1771\n",
      "Epoch 279/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 3.8328 - accuracy: 0.2511 - val_loss: 4.3525 - val_accuracy: 0.1771\n",
      "Epoch 280/1000\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 3.8328 - accuracy: 0.2511 - val_loss: 4.3525 - val_accuracy: 0.1771\n",
      "Epoch 281/1000\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 3.8328 - accuracy: 0.2511 - val_loss: 4.3525 - val_accuracy: 0.1771\n",
      "Epoch 282/1000\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 3.8328 - accuracy: 0.2511 - val_loss: 4.3525 - val_accuracy: 0.1771\n",
      "Epoch 283/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 3.8328 - accuracy: 0.2511 - val_loss: 4.3525 - val_accuracy: 0.1771\n",
      "Epoch 284/1000\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 3.8328 - accuracy: 0.2511 - val_loss: 4.3525 - val_accuracy: 0.1771\n",
      "Epoch 285/1000\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 3.8328 - accuracy: 0.2511 - val_loss: 4.3525 - val_accuracy: 0.1771\n",
      "Epoch 286/1000\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 3.8328 - accuracy: 0.2511 - val_loss: 4.3525 - val_accuracy: 0.1771\n",
      "Epoch 287/1000\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 3.8328 - accuracy: 0.2511 - val_loss: 4.3525 - val_accuracy: 0.1771\n",
      "Epoch 288/1000\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 3.8328 - accuracy: 0.2466 - val_loss: 4.3525 - val_accuracy: 0.1667\n",
      "Epoch 289/1000\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 3.8328 - accuracy: 0.2466 - val_loss: 4.3525 - val_accuracy: 0.1667\n",
      "Epoch 290/1000\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 3.8328 - accuracy: 0.2422 - val_loss: 4.3525 - val_accuracy: 0.1667\n",
      "Epoch 291/1000\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 3.8328 - accuracy: 0.2422 - val_loss: 4.3525 - val_accuracy: 0.1667\n",
      "Epoch 292/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 3.8328 - accuracy: 0.2422 - val_loss: 4.3525 - val_accuracy: 0.1667\n",
      "Epoch 293/1000\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 3.8328 - accuracy: 0.2422 - val_loss: 4.3525 - val_accuracy: 0.1667\n",
      "Epoch 294/1000\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 3.8328 - accuracy: 0.2422 - val_loss: 4.3525 - val_accuracy: 0.1667\n",
      "Epoch 295/1000\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 3.8328 - accuracy: 0.2422 - val_loss: 4.3525 - val_accuracy: 0.1667\n",
      "Epoch 296/1000\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 3.8328 - accuracy: 0.2422 - val_loss: 4.3525 - val_accuracy: 0.1667\n",
      "Epoch 297/1000\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 3.8328 - accuracy: 0.2422 - val_loss: 4.3525 - val_accuracy: 0.1667\n",
      "Epoch 298/1000\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 3.8328 - accuracy: 0.2422 - val_loss: 4.3525 - val_accuracy: 0.1667\n",
      "Epoch 299/1000\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 3.8328 - accuracy: 0.2422 - val_loss: 4.3525 - val_accuracy: 0.1667\n",
      "Epoch 300/1000\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 3.8328 - accuracy: 0.2422 - val_loss: 4.3525 - val_accuracy: 0.1667\n",
      "Epoch 301/1000\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 3.8328 - accuracy: 0.2422 - val_loss: 4.3525 - val_accuracy: 0.1667\n",
      "Epoch 302/1000\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 3.8328 - accuracy: 0.2422 - val_loss: 4.3525 - val_accuracy: 0.1667\n",
      "Epoch 303/1000\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 3.8328 - accuracy: 0.2422 - val_loss: 4.3525 - val_accuracy: 0.1667\n",
      "Epoch 304/1000\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 3.8328 - accuracy: 0.2422 - val_loss: 4.3525 - val_accuracy: 0.1667\n",
      "Epoch 305/1000\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 3.8328 - accuracy: 0.2422 - val_loss: 4.3525 - val_accuracy: 0.1667\n",
      "Epoch 306/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 3.8328 - accuracy: 0.2422 - val_loss: 4.3525 - val_accuracy: 0.1667\n",
      "Epoch 307/1000\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 3.8328 - accuracy: 0.2422 - val_loss: 4.3525 - val_accuracy: 0.1667\n",
      "Epoch 308/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 3.8328 - accuracy: 0.2422 - val_loss: 4.3525 - val_accuracy: 0.1667\n",
      "Epoch 309/1000\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 3.8328 - accuracy: 0.2422 - val_loss: 4.3525 - val_accuracy: 0.1667\n",
      "Epoch 310/1000\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 3.8328 - accuracy: 0.2422 - val_loss: 4.3525 - val_accuracy: 0.1562\n",
      "Epoch 311/1000\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 3.8328 - accuracy: 0.2377 - val_loss: 4.3525 - val_accuracy: 0.1562\n",
      "Epoch 312/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 3.8328 - accuracy: 0.2377 - val_loss: 4.3525 - val_accuracy: 0.1562\n",
      "Epoch 313/1000\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 3.8328 - accuracy: 0.2377 - val_loss: 4.3525 - val_accuracy: 0.1562\n",
      "Epoch 314/1000\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 3.8328 - accuracy: 0.2377 - val_loss: 4.3525 - val_accuracy: 0.1562\n",
      "Epoch 315/1000\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 3.8328 - accuracy: 0.2377 - val_loss: 4.3525 - val_accuracy: 0.1562\n",
      "Epoch 316/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 3.8328 - accuracy: 0.2377 - val_loss: 4.3525 - val_accuracy: 0.1562\n",
      "Epoch 317/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 3.8328 - accuracy: 0.2377 - val_loss: 4.3525 - val_accuracy: 0.1562\n",
      "Epoch 318/1000\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 3.8328 - accuracy: 0.2377 - val_loss: 4.3525 - val_accuracy: 0.1562\n",
      "Epoch 319/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 3.8328 - accuracy: 0.2377 - val_loss: 4.3525 - val_accuracy: 0.1562\n",
      "Epoch 320/1000\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 3.8328 - accuracy: 0.2377 - val_loss: 4.3525 - val_accuracy: 0.1562\n",
      "Epoch 321/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 3.8328 - accuracy: 0.2377 - val_loss: 4.3525 - val_accuracy: 0.1562\n",
      "Epoch 322/1000\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 3.8328 - accuracy: 0.2377 - val_loss: 4.3525 - val_accuracy: 0.1562\n",
      "Epoch 323/1000\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 3.8328 - accuracy: 0.2377 - val_loss: 4.3525 - val_accuracy: 0.1562\n",
      "Epoch 324/1000\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 3.8328 - accuracy: 0.2377 - val_loss: 4.3525 - val_accuracy: 0.1562\n",
      "Epoch 325/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 3.8328 - accuracy: 0.2377 - val_loss: 4.3525 - val_accuracy: 0.1562\n",
      "Epoch 326/1000\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 3.8328 - accuracy: 0.2332 - val_loss: 4.3525 - val_accuracy: 0.1562\n",
      "Epoch 327/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 3.8328 - accuracy: 0.2332 - val_loss: 4.3525 - val_accuracy: 0.1562\n",
      "Epoch 328/1000\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 3.8328 - accuracy: 0.2332 - val_loss: 4.3525 - val_accuracy: 0.1562\n",
      "Epoch 329/1000\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 3.8328 - accuracy: 0.2332 - val_loss: 4.3525 - val_accuracy: 0.1562\n",
      "Epoch 330/1000\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 3.8328 - accuracy: 0.2332 - val_loss: 4.3525 - val_accuracy: 0.1562\n",
      "Epoch 331/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 3.8328 - accuracy: 0.2332 - val_loss: 4.3525 - val_accuracy: 0.1562\n",
      "Epoch 332/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 3.8328 - accuracy: 0.2332 - val_loss: 4.3525 - val_accuracy: 0.1562\n",
      "Epoch 333/1000\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 3.8328 - accuracy: 0.2332 - val_loss: 4.3525 - val_accuracy: 0.1562\n",
      "Epoch 334/1000\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 3.8328 - accuracy: 0.2332 - val_loss: 4.3525 - val_accuracy: 0.1458\n",
      "Epoch 335/1000\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 3.8328 - accuracy: 0.2332 - val_loss: 4.3525 - val_accuracy: 0.1458\n",
      "Epoch 336/1000\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 3.8328 - accuracy: 0.2332 - val_loss: 4.3525 - val_accuracy: 0.1458\n",
      "Epoch 337/1000\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 3.8328 - accuracy: 0.2332 - val_loss: 4.3525 - val_accuracy: 0.1458\n",
      "Epoch 338/1000\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 3.8328 - accuracy: 0.2332 - val_loss: 4.3525 - val_accuracy: 0.1458\n",
      "Epoch 339/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 3.8328 - accuracy: 0.2332 - val_loss: 4.3525 - val_accuracy: 0.1458\n",
      "Epoch 340/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 3.8328 - accuracy: 0.2332 - val_loss: 4.3525 - val_accuracy: 0.1458\n",
      "Epoch 341/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 3.8328 - accuracy: 0.2332 - val_loss: 4.3525 - val_accuracy: 0.1458\n",
      "Epoch 342/1000\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 3.8328 - accuracy: 0.2332 - val_loss: 4.3525 - val_accuracy: 0.1458\n",
      "Epoch 343/1000\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 3.8328 - accuracy: 0.2377 - val_loss: 4.3525 - val_accuracy: 0.1458\n",
      "Epoch 344/1000\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 3.8328 - accuracy: 0.2377 - val_loss: 4.3525 - val_accuracy: 0.1458\n",
      "Epoch 345/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 3.8328 - accuracy: 0.2377 - val_loss: 4.3525 - val_accuracy: 0.1458\n",
      "Epoch 346/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 3.8328 - accuracy: 0.2377 - val_loss: 4.3525 - val_accuracy: 0.1458\n",
      "Epoch 347/1000\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 3.8328 - accuracy: 0.2422 - val_loss: 4.3525 - val_accuracy: 0.1458\n",
      "Epoch 348/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 3.8328 - accuracy: 0.2422 - val_loss: 4.3525 - val_accuracy: 0.1458\n",
      "Epoch 349/1000\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 3.8328 - accuracy: 0.2422 - val_loss: 4.3525 - val_accuracy: 0.1458\n",
      "Epoch 350/1000\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 3.8328 - accuracy: 0.2422 - val_loss: 4.3525 - val_accuracy: 0.1458\n",
      "Epoch 351/1000\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 3.8328 - accuracy: 0.2422 - val_loss: 4.3525 - val_accuracy: 0.1458\n",
      "Epoch 352/1000\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 3.8328 - accuracy: 0.2422 - val_loss: 4.3525 - val_accuracy: 0.1458\n",
      "Epoch 353/1000\n",
      "3/3 [==============================] - 0s 59ms/step - loss: 3.8328 - accuracy: 0.2377 - val_loss: 4.3525 - val_accuracy: 0.1458\n",
      "Epoch 354/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 3.8328 - accuracy: 0.2377 - val_loss: 4.3525 - val_accuracy: 0.1458\n",
      "Epoch 355/1000\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 3.8328 - accuracy: 0.2377 - val_loss: 4.3525 - val_accuracy: 0.1458\n",
      "Epoch 356/1000\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 3.8328 - accuracy: 0.2377 - val_loss: 4.3525 - val_accuracy: 0.1458\n",
      "Epoch 357/1000\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 3.8328 - accuracy: 0.2377 - val_loss: 4.3525 - val_accuracy: 0.1458\n",
      "Epoch 358/1000\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 3.8328 - accuracy: 0.2377 - val_loss: 4.3525 - val_accuracy: 0.1458\n",
      "Epoch 359/1000\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 3.8328 - accuracy: 0.2377 - val_loss: 4.3525 - val_accuracy: 0.1458\n",
      "Epoch 360/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 3.8328 - accuracy: 0.2377 - val_loss: 4.3525 - val_accuracy: 0.1458\n",
      "Epoch 361/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 3.8328 - accuracy: 0.2422 - val_loss: 4.3525 - val_accuracy: 0.1458\n",
      "Epoch 362/1000\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 3.8328 - accuracy: 0.2422 - val_loss: 4.3525 - val_accuracy: 0.1458\n",
      "Epoch 363/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 3.8328 - accuracy: 0.2422 - val_loss: 4.3525 - val_accuracy: 0.1458\n",
      "Epoch 364/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 3.8328 - accuracy: 0.2422 - val_loss: 4.3525 - val_accuracy: 0.1458\n",
      "Epoch 365/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 3.8328 - accuracy: 0.2422 - val_loss: 4.3525 - val_accuracy: 0.1458\n",
      "Epoch 366/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 3.8328 - accuracy: 0.2422 - val_loss: 4.3525 - val_accuracy: 0.1458\n",
      "Epoch 367/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 3.8328 - accuracy: 0.2422 - val_loss: 4.3525 - val_accuracy: 0.1458\n",
      "Epoch 368/1000\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 3.8328 - accuracy: 0.2422 - val_loss: 4.3525 - val_accuracy: 0.1458\n",
      "Epoch 369/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 3.8328 - accuracy: 0.2422 - val_loss: 4.3525 - val_accuracy: 0.1458\n",
      "Epoch 370/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 3.8328 - accuracy: 0.2422 - val_loss: 4.3525 - val_accuracy: 0.1458\n",
      "Epoch 371/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 3.8328 - accuracy: 0.2422 - val_loss: 4.3525 - val_accuracy: 0.1458\n",
      "Epoch 372/1000\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 3.8328 - accuracy: 0.2422 - val_loss: 4.3525 - val_accuracy: 0.1458\n",
      "Epoch 373/1000\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 3.8328 - accuracy: 0.2422 - val_loss: 4.3525 - val_accuracy: 0.1458\n",
      "Epoch 374/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 3.8328 - accuracy: 0.2422 - val_loss: 4.3525 - val_accuracy: 0.1458\n",
      "Epoch 375/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 3.8328 - accuracy: 0.2422 - val_loss: 4.3525 - val_accuracy: 0.1458\n",
      "Epoch 376/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 3.8328 - accuracy: 0.2422 - val_loss: 4.3525 - val_accuracy: 0.1458\n",
      "Epoch 377/1000\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 3.8328 - accuracy: 0.2422 - val_loss: 4.3525 - val_accuracy: 0.1458\n",
      "Epoch 378/1000\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 3.8328 - accuracy: 0.2422 - val_loss: 4.3525 - val_accuracy: 0.1458\n",
      "Epoch 379/1000\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 3.8328 - accuracy: 0.2422 - val_loss: 4.3525 - val_accuracy: 0.1458\n",
      "Epoch 380/1000\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 3.8328 - accuracy: 0.2422 - val_loss: 4.3525 - val_accuracy: 0.1458\n",
      "Epoch 381/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 3.8328 - accuracy: 0.2422 - val_loss: 4.3525 - val_accuracy: 0.1458\n",
      "Epoch 382/1000\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 3.8328 - accuracy: 0.2422 - val_loss: 4.3525 - val_accuracy: 0.1458\n",
      "Epoch 383/1000\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 3.8328 - accuracy: 0.2422 - val_loss: 4.3525 - val_accuracy: 0.1458\n",
      "Epoch 384/1000\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 3.8328 - accuracy: 0.2422 - val_loss: 4.3525 - val_accuracy: 0.1458\n",
      "Epoch 385/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 3.8328 - accuracy: 0.2422 - val_loss: 4.3525 - val_accuracy: 0.1458\n",
      "Epoch 386/1000\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 3.8328 - accuracy: 0.2422 - val_loss: 4.3525 - val_accuracy: 0.1458\n",
      "Epoch 387/1000\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 3.8328 - accuracy: 0.2422 - val_loss: 4.3525 - val_accuracy: 0.1562\n",
      "Epoch 388/1000\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 3.8328 - accuracy: 0.2422 - val_loss: 4.3525 - val_accuracy: 0.1562\n",
      "Epoch 389/1000\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 3.8328 - accuracy: 0.2422 - val_loss: 4.3525 - val_accuracy: 0.1562\n",
      "Epoch 390/1000\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 3.8328 - accuracy: 0.2422 - val_loss: 4.3525 - val_accuracy: 0.1562\n",
      "Epoch 391/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 3.8328 - accuracy: 0.2422 - val_loss: 4.3525 - val_accuracy: 0.1562\n",
      "Epoch 392/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 3.8328 - accuracy: 0.2422 - val_loss: 4.3525 - val_accuracy: 0.1562\n",
      "Epoch 393/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 3.8328 - accuracy: 0.2422 - val_loss: 4.3525 - val_accuracy: 0.1562\n",
      "Epoch 394/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 3.8328 - accuracy: 0.2422 - val_loss: 4.3525 - val_accuracy: 0.1562\n",
      "Epoch 395/1000\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 3.8328 - accuracy: 0.2422 - val_loss: 4.3525 - val_accuracy: 0.1458\n",
      "Epoch 396/1000\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 3.8328 - accuracy: 0.2422 - val_loss: 4.3525 - val_accuracy: 0.1458\n",
      "Epoch 397/1000\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 3.8328 - accuracy: 0.2422 - val_loss: 4.3525 - val_accuracy: 0.1458\n",
      "Epoch 398/1000\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 3.8328 - accuracy: 0.2422 - val_loss: 4.3525 - val_accuracy: 0.1458\n",
      "Epoch 399/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 3.8328 - accuracy: 0.2422 - val_loss: 4.3525 - val_accuracy: 0.1042\n",
      "Epoch 400/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 3.8328 - accuracy: 0.0807 - val_loss: 4.3525 - val_accuracy: 0.1042\n",
      "Epoch 401/1000\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 3.8328 - accuracy: 0.0807 - val_loss: 4.3525 - val_accuracy: 0.1042\n",
      "Epoch 402/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 3.8328 - accuracy: 0.0807 - val_loss: 4.3525 - val_accuracy: 0.1042\n",
      "Epoch 403/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 3.8328 - accuracy: 0.0807 - val_loss: 4.3525 - val_accuracy: 0.1042\n",
      "Epoch 404/1000\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 3.8328 - accuracy: 0.0807 - val_loss: 4.3525 - val_accuracy: 0.1042\n",
      "Epoch 405/1000\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 3.8328 - accuracy: 0.0807 - val_loss: 4.3525 - val_accuracy: 0.1042\n",
      "Epoch 406/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 3.8328 - accuracy: 0.0807 - val_loss: 4.3525 - val_accuracy: 0.1042\n",
      "Epoch 407/1000\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 3.8328 - accuracy: 0.0807 - val_loss: 4.3525 - val_accuracy: 0.1042\n",
      "Epoch 408/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 3.8328 - accuracy: 0.0807 - val_loss: 4.3525 - val_accuracy: 0.1458\n",
      "Epoch 409/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 3.8328 - accuracy: 0.2422 - val_loss: 4.3525 - val_accuracy: 0.1458\n",
      "Epoch 410/1000\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 3.8328 - accuracy: 0.2422 - val_loss: 4.3525 - val_accuracy: 0.1458\n",
      "Epoch 411/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 3.8328 - accuracy: 0.2422 - val_loss: 4.3525 - val_accuracy: 0.1458\n",
      "Epoch 412/1000\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 3.8328 - accuracy: 0.2422 - val_loss: 4.3525 - val_accuracy: 0.1458\n",
      "Epoch 413/1000\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 3.8328 - accuracy: 0.2422 - val_loss: 4.3525 - val_accuracy: 0.1458\n",
      "Epoch 414/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 3.8328 - accuracy: 0.2422 - val_loss: 4.3525 - val_accuracy: 0.1458\n",
      "Epoch 415/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 3.8328 - accuracy: 0.2422 - val_loss: 4.3525 - val_accuracy: 0.1458\n",
      "Epoch 416/1000\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 3.8328 - accuracy: 0.2422 - val_loss: 4.3525 - val_accuracy: 0.1458\n",
      "Epoch 417/1000\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 3.8328 - accuracy: 0.2422 - val_loss: 4.3525 - val_accuracy: 0.1458\n",
      "Epoch 418/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 3.8328 - accuracy: 0.2422 - val_loss: 4.3525 - val_accuracy: 0.1458\n",
      "Epoch 419/1000\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 3.8328 - accuracy: 0.2422 - val_loss: 4.3525 - val_accuracy: 0.1458\n",
      "Epoch 420/1000\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 3.8328 - accuracy: 0.2422 - val_loss: 4.3525 - val_accuracy: 0.1458\n",
      "Epoch 421/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 3.8328 - accuracy: 0.2422 - val_loss: 4.3525 - val_accuracy: 0.1458\n",
      "Epoch 422/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 3.8328 - accuracy: 0.2422 - val_loss: 4.3525 - val_accuracy: 0.1458\n",
      "Epoch 423/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 3.8328 - accuracy: 0.2422 - val_loss: 4.3525 - val_accuracy: 0.1458\n",
      "Epoch 424/1000\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 3.8328 - accuracy: 0.2422 - val_loss: 4.3525 - val_accuracy: 0.1458\n",
      "Epoch 425/1000\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 3.8328 - accuracy: 0.2422 - val_loss: 4.3525 - val_accuracy: 0.1458\n",
      "Epoch 426/1000\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 3.8328 - accuracy: 0.2422 - val_loss: 4.3525 - val_accuracy: 0.1458\n",
      "Epoch 427/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 3.8328 - accuracy: 0.2422 - val_loss: 4.3525 - val_accuracy: 0.1458\n",
      "Epoch 428/1000\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 3.8328 - accuracy: 0.2466 - val_loss: 4.3525 - val_accuracy: 0.1458\n",
      "Epoch 429/1000\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 3.8328 - accuracy: 0.2466 - val_loss: 4.3525 - val_accuracy: 0.1458\n",
      "Epoch 430/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 3.8328 - accuracy: 0.2466 - val_loss: 4.3525 - val_accuracy: 0.1458\n",
      "Epoch 431/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 3.8328 - accuracy: 0.2466 - val_loss: 4.3525 - val_accuracy: 0.1458\n",
      "Epoch 432/1000\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 3.8328 - accuracy: 0.2466 - val_loss: 4.3525 - val_accuracy: 0.1458\n",
      "Epoch 433/1000\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 3.8328 - accuracy: 0.2466 - val_loss: 4.3525 - val_accuracy: 0.1458\n",
      "Epoch 434/1000\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 3.8328 - accuracy: 0.2466 - val_loss: 4.3525 - val_accuracy: 0.1458\n",
      "Epoch 435/1000\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 3.8328 - accuracy: 0.2466 - val_loss: 4.3525 - val_accuracy: 0.1458\n",
      "Epoch 436/1000\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 3.8328 - accuracy: 0.2466 - val_loss: 4.3525 - val_accuracy: 0.1458\n",
      "Epoch 437/1000\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 3.8328 - accuracy: 0.2466 - val_loss: 4.3525 - val_accuracy: 0.1458\n",
      "Epoch 438/1000\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 3.8328 - accuracy: 0.2466 - val_loss: 4.3525 - val_accuracy: 0.1458\n",
      "Epoch 439/1000\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 3.8328 - accuracy: 0.2466 - val_loss: 4.3525 - val_accuracy: 0.1458\n",
      "Epoch 440/1000\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 3.8328 - accuracy: 0.2466 - val_loss: 4.3525 - val_accuracy: 0.1458\n",
      "Epoch 441/1000\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 3.8328 - accuracy: 0.2466 - val_loss: 4.3525 - val_accuracy: 0.1458\n",
      "Epoch 442/1000\n",
      "3/3 [==============================] - 0s 68ms/step - loss: 3.8328 - accuracy: 0.2466 - val_loss: 4.3525 - val_accuracy: 0.1458\n",
      "Epoch 443/1000\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 3.8328 - accuracy: 0.1659 - val_loss: 4.3525 - val_accuracy: 0.1146\n",
      "Epoch 444/1000\n",
      "3/3 [==============================] - 0s 49ms/step - loss: 3.8328 - accuracy: 0.0807 - val_loss: 4.3525 - val_accuracy: 0.1146\n",
      "Epoch 445/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 3.8328 - accuracy: 0.0807 - val_loss: 4.3525 - val_accuracy: 0.1146\n",
      "Epoch 446/1000\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 3.8328 - accuracy: 0.0807 - val_loss: 4.3525 - val_accuracy: 0.1146\n",
      "Epoch 447/1000\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 3.8328 - accuracy: 0.0807 - val_loss: 4.3525 - val_accuracy: 0.1146\n",
      "Epoch 448/1000\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 3.8328 - accuracy: 0.0807 - val_loss: 4.3525 - val_accuracy: 0.1146\n",
      "Epoch 449/1000\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 3.8328 - accuracy: 0.0807 - val_loss: 4.3525 - val_accuracy: 0.1146\n",
      "Epoch 450/1000\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 3.8328 - accuracy: 0.0807 - val_loss: 4.3525 - val_accuracy: 0.1146\n",
      "Epoch 451/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 3.8328 - accuracy: 0.0807 - val_loss: 4.3525 - val_accuracy: 0.1146\n",
      "Epoch 452/1000\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 3.8328 - accuracy: 0.0807 - val_loss: 4.3525 - val_accuracy: 0.1146\n",
      "Epoch 453/1000\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 3.8328 - accuracy: 0.0807 - val_loss: 4.3525 - val_accuracy: 0.1146\n",
      "Epoch 454/1000\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 3.8328 - accuracy: 0.0807 - val_loss: 4.3525 - val_accuracy: 0.1146\n",
      "Epoch 455/1000\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 3.8328 - accuracy: 0.0807 - val_loss: 4.3525 - val_accuracy: 0.1146\n",
      "Epoch 456/1000\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 3.8328 - accuracy: 0.0807 - val_loss: 4.3525 - val_accuracy: 0.1146\n",
      "Epoch 457/1000\n",
      "3/3 [==============================] - 0s 40ms/step - loss: 3.8328 - accuracy: 0.0807 - val_loss: 4.3525 - val_accuracy: 0.1146\n",
      "Epoch 458/1000\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 3.8328 - accuracy: 0.0807 - val_loss: 4.3525 - val_accuracy: 0.1146\n",
      "Epoch 459/1000\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 3.8328 - accuracy: 0.0762 - val_loss: 4.3525 - val_accuracy: 0.1146\n",
      "Epoch 460/1000\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 3.8328 - accuracy: 0.0762 - val_loss: 4.3525 - val_accuracy: 0.1146\n",
      "Epoch 461/1000\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 3.8328 - accuracy: 0.0762 - val_loss: 4.3525 - val_accuracy: 0.1146\n",
      "Epoch 462/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 3.8328 - accuracy: 0.0762 - val_loss: 4.3525 - val_accuracy: 0.1146\n",
      "Epoch 463/1000\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 3.8328 - accuracy: 0.0762 - val_loss: 4.3525 - val_accuracy: 0.1146\n",
      "Epoch 464/1000\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 3.8328 - accuracy: 0.0762 - val_loss: 4.3525 - val_accuracy: 0.1146\n",
      "Epoch 465/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 3.8328 - accuracy: 0.0762 - val_loss: 4.3525 - val_accuracy: 0.1146\n",
      "Epoch 466/1000\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 3.8328 - accuracy: 0.0762 - val_loss: 4.3525 - val_accuracy: 0.1146\n",
      "Epoch 467/1000\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 3.8328 - accuracy: 0.0762 - val_loss: 4.3525 - val_accuracy: 0.1042\n",
      "Epoch 468/1000\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 3.8328 - accuracy: 0.0762 - val_loss: 4.3525 - val_accuracy: 0.1042\n",
      "Epoch 469/1000\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 3.8328 - accuracy: 0.0762 - val_loss: 4.3525 - val_accuracy: 0.1042\n",
      "Epoch 470/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 3.8328 - accuracy: 0.0762 - val_loss: 4.3525 - val_accuracy: 0.1042\n",
      "Epoch 471/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 3.8328 - accuracy: 0.0762 - val_loss: 4.3525 - val_accuracy: 0.1042\n",
      "Epoch 472/1000\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 3.8328 - accuracy: 0.0762 - val_loss: 4.3525 - val_accuracy: 0.1042\n",
      "Epoch 473/1000\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 3.8328 - accuracy: 0.0762 - val_loss: 4.3525 - val_accuracy: 0.1042\n",
      "Epoch 474/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 3.8328 - accuracy: 0.0762 - val_loss: 4.3525 - val_accuracy: 0.1042\n",
      "Epoch 475/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 3.8328 - accuracy: 0.0762 - val_loss: 4.3525 - val_accuracy: 0.1042\n",
      "Epoch 476/1000\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 3.8328 - accuracy: 0.0762 - val_loss: 4.3525 - val_accuracy: 0.1042\n",
      "Epoch 477/1000\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 3.8328 - accuracy: 0.0762 - val_loss: 4.3525 - val_accuracy: 0.1042\n",
      "Epoch 478/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 3.8328 - accuracy: 0.0762 - val_loss: 4.3525 - val_accuracy: 0.1042\n",
      "Epoch 479/1000\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 3.8328 - accuracy: 0.0762 - val_loss: 4.3525 - val_accuracy: 0.1042\n",
      "Epoch 480/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 3.8328 - accuracy: 0.0762 - val_loss: 4.3525 - val_accuracy: 0.1042\n",
      "Epoch 481/1000\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 3.8328 - accuracy: 0.0762 - val_loss: 4.3525 - val_accuracy: 0.1042\n",
      "Epoch 482/1000\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 3.8328 - accuracy: 0.0762 - val_loss: 4.3525 - val_accuracy: 0.1042\n",
      "Epoch 483/1000\n",
      "3/3 [==============================] - 0s 40ms/step - loss: 3.8328 - accuracy: 0.0762 - val_loss: 4.3525 - val_accuracy: 0.1042\n",
      "Epoch 484/1000\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 3.8328 - accuracy: 0.1076 - val_loss: 4.3525 - val_accuracy: 0.1354\n",
      "Epoch 485/1000\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 3.8328 - accuracy: 0.2422 - val_loss: 4.3525 - val_accuracy: 0.1354\n",
      "Epoch 486/1000\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 3.8328 - accuracy: 0.2422 - val_loss: 4.3525 - val_accuracy: 0.1354\n",
      "Epoch 487/1000\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 3.8328 - accuracy: 0.2422 - val_loss: 4.3525 - val_accuracy: 0.1354\n",
      "Epoch 488/1000\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 3.8328 - accuracy: 0.2422 - val_loss: 4.3525 - val_accuracy: 0.1354\n",
      "Epoch 489/1000\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 3.8328 - accuracy: 0.2422 - val_loss: 4.3525 - val_accuracy: 0.1354\n",
      "Epoch 490/1000\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 3.8328 - accuracy: 0.2422 - val_loss: 4.3525 - val_accuracy: 0.1354\n",
      "Epoch 491/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 3.8328 - accuracy: 0.2422 - val_loss: 4.3525 - val_accuracy: 0.1354\n",
      "Epoch 492/1000\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 3.8328 - accuracy: 0.2422 - val_loss: 4.3525 - val_accuracy: 0.1354\n",
      "Epoch 493/1000\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 3.8328 - accuracy: 0.2422 - val_loss: 4.3525 - val_accuracy: 0.1354\n",
      "Epoch 494/1000\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 3.8328 - accuracy: 0.2422 - val_loss: 4.3525 - val_accuracy: 0.1354\n",
      "Epoch 495/1000\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 3.8328 - accuracy: 0.2422 - val_loss: 4.3525 - val_accuracy: 0.1354\n",
      "Epoch 496/1000\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 3.8328 - accuracy: 0.2422 - val_loss: 4.3525 - val_accuracy: 0.1354\n",
      "Epoch 497/1000\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 3.8328 - accuracy: 0.2422 - val_loss: 4.3525 - val_accuracy: 0.1354\n",
      "Epoch 498/1000\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 3.8328 - accuracy: 0.2422 - val_loss: 4.3525 - val_accuracy: 0.1354\n",
      "Epoch 499/1000\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 3.8328 - accuracy: 0.2422 - val_loss: 4.3525 - val_accuracy: 0.1354\n",
      "Epoch 500/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 3.8328 - accuracy: 0.2466 - val_loss: 4.3525 - val_accuracy: 0.1354\n",
      "Epoch 501/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 3.8328 - accuracy: 0.2466 - val_loss: 4.3525 - val_accuracy: 0.1354\n",
      "Epoch 502/1000\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 3.8328 - accuracy: 0.2466 - val_loss: 4.3525 - val_accuracy: 0.1354\n",
      "Epoch 503/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 3.8328 - accuracy: 0.2466 - val_loss: 4.3525 - val_accuracy: 0.1354\n",
      "Epoch 504/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 3.8328 - accuracy: 0.2422 - val_loss: 4.3525 - val_accuracy: 0.1354\n",
      "Epoch 505/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 3.8328 - accuracy: 0.2422 - val_loss: 4.3525 - val_accuracy: 0.1354\n",
      "Epoch 506/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 3.8328 - accuracy: 0.2422 - val_loss: 4.3525 - val_accuracy: 0.1354\n",
      "Epoch 507/1000\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 3.8328 - accuracy: 0.2422 - val_loss: 4.3525 - val_accuracy: 0.1354\n",
      "Epoch 508/1000\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 3.8328 - accuracy: 0.2422 - val_loss: 4.3525 - val_accuracy: 0.1042\n",
      "Epoch 509/1000\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 3.8328 - accuracy: 0.0807 - val_loss: 4.3525 - val_accuracy: 0.1042\n",
      "Epoch 510/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 3.8328 - accuracy: 0.0807 - val_loss: 4.3525 - val_accuracy: 0.1042\n",
      "Epoch 511/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 3.8328 - accuracy: 0.0807 - val_loss: 4.3525 - val_accuracy: 0.1042\n",
      "Epoch 512/1000\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 3.8328 - accuracy: 0.0807 - val_loss: 4.3525 - val_accuracy: 0.1042\n",
      "Epoch 513/1000\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 3.8328 - accuracy: 0.0807 - val_loss: 4.3525 - val_accuracy: 0.1042\n",
      "Epoch 514/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 3.8328 - accuracy: 0.0807 - val_loss: 4.3525 - val_accuracy: 0.1042\n",
      "Epoch 515/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 3.8328 - accuracy: 0.0807 - val_loss: 4.3525 - val_accuracy: 0.1042\n",
      "Epoch 516/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 3.8328 - accuracy: 0.0807 - val_loss: 4.3525 - val_accuracy: 0.1042\n",
      "Epoch 517/1000\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 3.8328 - accuracy: 0.0807 - val_loss: 4.3525 - val_accuracy: 0.1042\n",
      "Epoch 518/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 3.8328 - accuracy: 0.0807 - val_loss: 4.3525 - val_accuracy: 0.1042\n",
      "Epoch 519/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 3.8328 - accuracy: 0.0807 - val_loss: 4.3525 - val_accuracy: 0.1042\n",
      "Epoch 520/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 3.8328 - accuracy: 0.0807 - val_loss: 4.3525 - val_accuracy: 0.1042\n",
      "Epoch 521/1000\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 3.8328 - accuracy: 0.0807 - val_loss: 4.3525 - val_accuracy: 0.1042\n",
      "Epoch 522/1000\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 3.8328 - accuracy: 0.0807 - val_loss: 4.3525 - val_accuracy: 0.1042\n",
      "Epoch 523/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 3.8328 - accuracy: 0.1480 - val_loss: 4.3525 - val_accuracy: 0.1354\n",
      "Epoch 524/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 3.8328 - accuracy: 0.2422 - val_loss: 4.3525 - val_accuracy: 0.1354\n",
      "Epoch 525/1000\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 3.8328 - accuracy: 0.2422 - val_loss: 4.3525 - val_accuracy: 0.1354\n",
      "Epoch 526/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 3.8328 - accuracy: 0.2422 - val_loss: 4.3525 - val_accuracy: 0.1354\n",
      "Epoch 527/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 3.8328 - accuracy: 0.2422 - val_loss: 4.3525 - val_accuracy: 0.1354\n",
      "Epoch 528/1000\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 3.8328 - accuracy: 0.2422 - val_loss: 4.3525 - val_accuracy: 0.1354\n",
      "Epoch 529/1000\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 3.8328 - accuracy: 0.2422 - val_loss: 4.3525 - val_accuracy: 0.1354\n",
      "Epoch 530/1000\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 3.8328 - accuracy: 0.2422 - val_loss: 4.3525 - val_accuracy: 0.1354\n",
      "Epoch 531/1000\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 3.8328 - accuracy: 0.2422 - val_loss: 4.3525 - val_accuracy: 0.1354\n",
      "Epoch 532/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 3.8328 - accuracy: 0.2422 - val_loss: 4.3525 - val_accuracy: 0.1354\n",
      "Epoch 533/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 3.8328 - accuracy: 0.2422 - val_loss: 4.3525 - val_accuracy: 0.1354\n",
      "Epoch 534/1000\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 3.8328 - accuracy: 0.2422 - val_loss: 4.3525 - val_accuracy: 0.1354\n",
      "Epoch 535/1000\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 3.8328 - accuracy: 0.2422 - val_loss: 4.3525 - val_accuracy: 0.1354\n",
      "Epoch 536/1000\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 3.8328 - accuracy: 0.2422 - val_loss: 4.3525 - val_accuracy: 0.1354\n",
      "Epoch 537/1000\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 3.8328 - accuracy: 0.2422 - val_loss: 4.3525 - val_accuracy: 0.1354\n",
      "Epoch 538/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 3.8328 - accuracy: 0.2422 - val_loss: 4.3525 - val_accuracy: 0.1354\n",
      "Epoch 539/1000\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 3.8328 - accuracy: 0.2422 - val_loss: 4.3525 - val_accuracy: 0.1354\n",
      "Epoch 540/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 3.8328 - accuracy: 0.2422 - val_loss: 4.3525 - val_accuracy: 0.1354\n",
      "Epoch 541/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 3.8328 - accuracy: 0.2422 - val_loss: 4.3525 - val_accuracy: 0.1354\n",
      "Epoch 542/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 3.8328 - accuracy: 0.2422 - val_loss: 4.3525 - val_accuracy: 0.1354\n",
      "Epoch 543/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 3.8328 - accuracy: 0.2422 - val_loss: 4.3525 - val_accuracy: 0.1354\n",
      "Epoch 544/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 3.8328 - accuracy: 0.2422 - val_loss: 4.3525 - val_accuracy: 0.1354\n",
      "Epoch 545/1000\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 3.8328 - accuracy: 0.2422 - val_loss: 4.3525 - val_accuracy: 0.1354\n",
      "Epoch 546/1000\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 3.8328 - accuracy: 0.2422 - val_loss: 4.3525 - val_accuracy: 0.1354\n",
      "Epoch 547/1000\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 3.8328 - accuracy: 0.2422 - val_loss: 4.3525 - val_accuracy: 0.1354\n",
      "Epoch 548/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 3.8328 - accuracy: 0.2422 - val_loss: 4.3525 - val_accuracy: 0.1354\n",
      "Epoch 549/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 3.8328 - accuracy: 0.2422 - val_loss: 4.3525 - val_accuracy: 0.1042\n",
      "Epoch 550/1000\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 3.8328 - accuracy: 0.0807 - val_loss: 4.3525 - val_accuracy: 0.1042\n",
      "Epoch 551/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 3.8328 - accuracy: 0.0807 - val_loss: 4.3525 - val_accuracy: 0.1042\n",
      "Epoch 552/1000\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 3.8328 - accuracy: 0.0807 - val_loss: 4.3525 - val_accuracy: 0.1042\n",
      "Epoch 553/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 3.8328 - accuracy: 0.0807 - val_loss: 4.3525 - val_accuracy: 0.1042\n",
      "Epoch 554/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 3.8328 - accuracy: 0.0807 - val_loss: 4.3525 - val_accuracy: 0.1042\n",
      "Epoch 555/1000\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 3.8328 - accuracy: 0.0807 - val_loss: 4.3525 - val_accuracy: 0.1042\n",
      "Epoch 556/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 3.8328 - accuracy: 0.0807 - val_loss: 4.3525 - val_accuracy: 0.1042\n",
      "Epoch 557/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 3.8328 - accuracy: 0.0807 - val_loss: 4.3525 - val_accuracy: 0.1042\n",
      "Epoch 558/1000\n",
      "3/3 [==============================] - 0s 11ms/step - loss: 3.8328 - accuracy: 0.0807 - val_loss: 4.3525 - val_accuracy: 0.1042\n",
      "Epoch 559/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 3.8328 - accuracy: 0.0807 - val_loss: 4.3525 - val_accuracy: 0.1042\n",
      "Epoch 560/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 3.8328 - accuracy: 0.0807 - val_loss: 4.3525 - val_accuracy: 0.1042\n",
      "Epoch 561/1000\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 3.8328 - accuracy: 0.0807 - val_loss: 4.3525 - val_accuracy: 0.1042\n",
      "Epoch 562/1000\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 3.8328 - accuracy: 0.0807 - val_loss: 4.3525 - val_accuracy: 0.1042\n",
      "Epoch 563/1000\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 3.8328 - accuracy: 0.0852 - val_loss: 4.3525 - val_accuracy: 0.1042\n",
      "Epoch 564/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 3.8328 - accuracy: 0.0852 - val_loss: 4.3525 - val_accuracy: 0.1042\n",
      "Epoch 565/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 3.8328 - accuracy: 0.0852 - val_loss: 4.3525 - val_accuracy: 0.1042\n",
      "Epoch 566/1000\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 3.8328 - accuracy: 0.0852 - val_loss: 4.3525 - val_accuracy: 0.1042\n",
      "Epoch 567/1000\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 3.8328 - accuracy: 0.0852 - val_loss: 4.3525 - val_accuracy: 0.1042\n",
      "Epoch 568/1000\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 3.8328 - accuracy: 0.0852 - val_loss: 4.3525 - val_accuracy: 0.1042\n",
      "Epoch 569/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 3.8328 - accuracy: 0.0852 - val_loss: 4.3525 - val_accuracy: 0.1042\n",
      "Epoch 570/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 3.8328 - accuracy: 0.0852 - val_loss: 4.3525 - val_accuracy: 0.1042\n",
      "Epoch 571/1000\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 3.8328 - accuracy: 0.0852 - val_loss: 4.3525 - val_accuracy: 0.1042\n",
      "Epoch 572/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 3.8328 - accuracy: 0.0852 - val_loss: 4.3525 - val_accuracy: 0.1042\n",
      "Epoch 573/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 3.8328 - accuracy: 0.0852 - val_loss: 4.3525 - val_accuracy: 0.1042\n",
      "Epoch 574/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 3.8328 - accuracy: 0.0852 - val_loss: 4.3525 - val_accuracy: 0.1042\n",
      "Epoch 575/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 3.8328 - accuracy: 0.0852 - val_loss: 4.3525 - val_accuracy: 0.1042\n",
      "Epoch 576/1000\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 3.8328 - accuracy: 0.0852 - val_loss: 4.3525 - val_accuracy: 0.1042\n",
      "Epoch 577/1000\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 3.8328 - accuracy: 0.0852 - val_loss: 4.3525 - val_accuracy: 0.1042\n",
      "Epoch 578/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 3.8328 - accuracy: 0.0852 - val_loss: 4.3525 - val_accuracy: 0.1042\n",
      "Epoch 579/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 3.8328 - accuracy: 0.0852 - val_loss: 4.3525 - val_accuracy: 0.1042\n",
      "Epoch 580/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 3.8328 - accuracy: 0.0852 - val_loss: 4.3525 - val_accuracy: 0.1042\n",
      "Epoch 581/1000\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 3.8328 - accuracy: 0.0852 - val_loss: 4.3525 - val_accuracy: 0.1042\n",
      "Epoch 582/1000\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 3.8328 - accuracy: 0.0852 - val_loss: 4.3525 - val_accuracy: 0.1042\n",
      "Epoch 583/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 3.8328 - accuracy: 0.0852 - val_loss: 4.3525 - val_accuracy: 0.1042\n",
      "Epoch 584/1000\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 3.8328 - accuracy: 0.0852 - val_loss: 4.3525 - val_accuracy: 0.1042\n",
      "Epoch 585/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 3.8328 - accuracy: 0.0852 - val_loss: 4.3525 - val_accuracy: 0.1042\n",
      "Epoch 586/1000\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 3.8328 - accuracy: 0.0852 - val_loss: 4.3525 - val_accuracy: 0.1042\n",
      "Epoch 587/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 3.8328 - accuracy: 0.0852 - val_loss: 4.3525 - val_accuracy: 0.1042\n",
      "Epoch 588/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 3.8328 - accuracy: 0.0852 - val_loss: 4.3525 - val_accuracy: 0.1042\n",
      "Epoch 589/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 3.8328 - accuracy: 0.0852 - val_loss: 4.3525 - val_accuracy: 0.1042\n",
      "Epoch 590/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 3.8328 - accuracy: 0.0852 - val_loss: 4.3525 - val_accuracy: 0.1042\n",
      "Epoch 591/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 3.8328 - accuracy: 0.0852 - val_loss: 4.3525 - val_accuracy: 0.1042\n",
      "Epoch 592/1000\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 3.8328 - accuracy: 0.0852 - val_loss: 4.3525 - val_accuracy: 0.1042\n",
      "Epoch 593/1000\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 3.8328 - accuracy: 0.0852 - val_loss: 4.3525 - val_accuracy: 0.1042\n",
      "Epoch 594/1000\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 3.8328 - accuracy: 0.0852 - val_loss: 4.3525 - val_accuracy: 0.1042\n",
      "Epoch 595/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 3.8328 - accuracy: 0.0852 - val_loss: 4.3525 - val_accuracy: 0.1042\n",
      "Epoch 596/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 3.8328 - accuracy: 0.0852 - val_loss: 4.3525 - val_accuracy: 0.1042\n",
      "Epoch 597/1000\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 3.8328 - accuracy: 0.0852 - val_loss: 4.3525 - val_accuracy: 0.1042\n",
      "Epoch 598/1000\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 3.8328 - accuracy: 0.0852 - val_loss: 4.3525 - val_accuracy: 0.1042\n",
      "Epoch 599/1000\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 3.8328 - accuracy: 0.0852 - val_loss: 4.3525 - val_accuracy: 0.1042\n",
      "Epoch 600/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 3.8328 - accuracy: 0.0852 - val_loss: 4.3525 - val_accuracy: 0.1042\n",
      "Epoch 601/1000\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 3.8328 - accuracy: 0.0852 - val_loss: 4.3525 - val_accuracy: 0.1042\n",
      "Epoch 602/1000\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 3.8328 - accuracy: 0.0852 - val_loss: 4.3525 - val_accuracy: 0.1042\n",
      "Epoch 603/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 3.8328 - accuracy: 0.0852 - val_loss: 4.3525 - val_accuracy: 0.1042\n",
      "Epoch 604/1000\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 3.8328 - accuracy: 0.0852 - val_loss: 4.3525 - val_accuracy: 0.1042\n",
      "Epoch 605/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 3.8328 - accuracy: 0.0852 - val_loss: 4.3525 - val_accuracy: 0.1042\n",
      "Epoch 606/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 3.8328 - accuracy: 0.0852 - val_loss: 4.3525 - val_accuracy: 0.1042\n",
      "Epoch 607/1000\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 3.8328 - accuracy: 0.1704 - val_loss: 4.3525 - val_accuracy: 0.1042\n",
      "Epoch 608/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 3.8328 - accuracy: 0.0852 - val_loss: 4.3525 - val_accuracy: 0.1042\n",
      "Epoch 609/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 3.8328 - accuracy: 0.0852 - val_loss: 4.3525 - val_accuracy: 0.1042\n",
      "Epoch 610/1000\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 3.8328 - accuracy: 0.0852 - val_loss: 4.3525 - val_accuracy: 0.1042\n",
      "Epoch 611/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 3.8328 - accuracy: 0.0852 - val_loss: 4.3525 - val_accuracy: 0.1042\n",
      "Epoch 612/1000\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 3.8328 - accuracy: 0.0852 - val_loss: 4.3525 - val_accuracy: 0.1042\n",
      "Epoch 613/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 3.8328 - accuracy: 0.0852 - val_loss: 4.3525 - val_accuracy: 0.1042\n",
      "Epoch 614/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 3.8328 - accuracy: 0.0852 - val_loss: 4.3525 - val_accuracy: 0.1042\n",
      "Epoch 615/1000\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 3.8328 - accuracy: 0.0852 - val_loss: 4.3525 - val_accuracy: 0.1042\n",
      "Epoch 616/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 3.8328 - accuracy: 0.0852 - val_loss: 4.3525 - val_accuracy: 0.1042\n",
      "Epoch 617/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 3.8328 - accuracy: 0.0852 - val_loss: 4.3525 - val_accuracy: 0.1042\n",
      "Epoch 618/1000\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 3.8328 - accuracy: 0.0852 - val_loss: 4.3525 - val_accuracy: 0.1042\n",
      "Epoch 619/1000\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 3.8328 - accuracy: 0.0852 - val_loss: 4.3525 - val_accuracy: 0.1042\n",
      "Epoch 620/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 3.8328 - accuracy: 0.0852 - val_loss: 4.3525 - val_accuracy: 0.1042\n",
      "Epoch 621/1000\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 3.8328 - accuracy: 0.0852 - val_loss: 4.3525 - val_accuracy: 0.1042\n",
      "Epoch 622/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 3.8328 - accuracy: 0.0852 - val_loss: 4.3525 - val_accuracy: 0.1042\n",
      "Epoch 623/1000\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 3.8328 - accuracy: 0.1480 - val_loss: 4.3525 - val_accuracy: 0.1354\n",
      "Epoch 624/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 3.8328 - accuracy: 0.2466 - val_loss: 4.3525 - val_accuracy: 0.1354\n",
      "Epoch 625/1000\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 3.8328 - accuracy: 0.2466 - val_loss: 4.3525 - val_accuracy: 0.1354\n",
      "Epoch 626/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 3.8328 - accuracy: 0.2466 - val_loss: 4.3525 - val_accuracy: 0.1354\n",
      "Epoch 627/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 3.8328 - accuracy: 0.2466 - val_loss: 4.3525 - val_accuracy: 0.1354\n",
      "Epoch 628/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 3.8328 - accuracy: 0.2466 - val_loss: 4.3525 - val_accuracy: 0.1354\n",
      "Epoch 629/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 3.8328 - accuracy: 0.2466 - val_loss: 4.3525 - val_accuracy: 0.1354\n",
      "Epoch 630/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 3.8328 - accuracy: 0.2422 - val_loss: 4.3525 - val_accuracy: 0.1354\n",
      "Epoch 631/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 3.8328 - accuracy: 0.2422 - val_loss: 4.3525 - val_accuracy: 0.1354\n",
      "Epoch 632/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 3.8328 - accuracy: 0.2422 - val_loss: 4.3525 - val_accuracy: 0.1354\n",
      "Epoch 633/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 3.8328 - accuracy: 0.2422 - val_loss: 4.3525 - val_accuracy: 0.1354\n",
      "Epoch 634/1000\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 3.8328 - accuracy: 0.2422 - val_loss: 4.3525 - val_accuracy: 0.1354\n",
      "Epoch 635/1000\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 3.8328 - accuracy: 0.2422 - val_loss: 4.3525 - val_accuracy: 0.1354\n",
      "Epoch 636/1000\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 3.8328 - accuracy: 0.2422 - val_loss: 4.3525 - val_accuracy: 0.1354\n",
      "Epoch 637/1000\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 3.8328 - accuracy: 0.2422 - val_loss: 4.3525 - val_accuracy: 0.1354\n",
      "Epoch 638/1000\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 3.8328 - accuracy: 0.2422 - val_loss: 4.3525 - val_accuracy: 0.1354\n",
      "Epoch 639/1000\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 3.8328 - accuracy: 0.2422 - val_loss: 4.3525 - val_accuracy: 0.1354\n",
      "Epoch 640/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 3.8328 - accuracy: 0.2422 - val_loss: 4.3525 - val_accuracy: 0.1354\n",
      "Epoch 641/1000\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 3.8328 - accuracy: 0.2422 - val_loss: 4.3525 - val_accuracy: 0.1354\n",
      "Epoch 642/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 3.8328 - accuracy: 0.2422 - val_loss: 4.3525 - val_accuracy: 0.1354\n",
      "Epoch 643/1000\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 3.8328 - accuracy: 0.2422 - val_loss: 4.3525 - val_accuracy: 0.1354\n",
      "Epoch 644/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 3.8328 - accuracy: 0.2422 - val_loss: 4.3525 - val_accuracy: 0.1354\n",
      "Epoch 645/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 3.8328 - accuracy: 0.2422 - val_loss: 4.3525 - val_accuracy: 0.1354\n",
      "Epoch 646/1000\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 3.8328 - accuracy: 0.2422 - val_loss: 4.3525 - val_accuracy: 0.1354\n",
      "Epoch 647/1000\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 3.8328 - accuracy: 0.2422 - val_loss: 4.3525 - val_accuracy: 0.1354\n",
      "Epoch 648/1000\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 3.8328 - accuracy: 0.2422 - val_loss: 4.3525 - val_accuracy: 0.1354\n",
      "Epoch 649/1000\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 3.8328 - accuracy: 0.2422 - val_loss: 4.3525 - val_accuracy: 0.1354\n",
      "Epoch 650/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 3.8328 - accuracy: 0.2242 - val_loss: 4.3525 - val_accuracy: 0.1146\n",
      "Epoch 651/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 3.8328 - accuracy: 0.0852 - val_loss: 4.3525 - val_accuracy: 0.1146\n",
      "Epoch 652/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 3.8328 - accuracy: 0.0852 - val_loss: 4.3525 - val_accuracy: 0.1146\n",
      "Epoch 653/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 3.8328 - accuracy: 0.0852 - val_loss: 4.3525 - val_accuracy: 0.1146\n",
      "Epoch 654/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 3.8328 - accuracy: 0.0852 - val_loss: 4.3525 - val_accuracy: 0.1146\n",
      "Epoch 655/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 3.8328 - accuracy: 0.0852 - val_loss: 4.3525 - val_accuracy: 0.1146\n",
      "Epoch 656/1000\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 3.8328 - accuracy: 0.0852 - val_loss: 4.3525 - val_accuracy: 0.1146\n",
      "Epoch 657/1000\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 3.8328 - accuracy: 0.0852 - val_loss: 4.3525 - val_accuracy: 0.1146\n",
      "Epoch 658/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 3.8328 - accuracy: 0.0852 - val_loss: 4.3525 - val_accuracy: 0.1146\n",
      "Epoch 659/1000\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 3.8328 - accuracy: 0.0852 - val_loss: 4.3525 - val_accuracy: 0.1146\n",
      "Epoch 660/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 3.8328 - accuracy: 0.0852 - val_loss: 4.3525 - val_accuracy: 0.1146\n",
      "Epoch 661/1000\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 3.8328 - accuracy: 0.0852 - val_loss: 4.3525 - val_accuracy: 0.1146\n",
      "Epoch 662/1000\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 3.8328 - accuracy: 0.0852 - val_loss: 4.3525 - val_accuracy: 0.1146\n",
      "Epoch 663/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 3.8328 - accuracy: 0.0852 - val_loss: 4.3525 - val_accuracy: 0.1146\n",
      "Epoch 664/1000\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 3.8328 - accuracy: 0.0852 - val_loss: 4.3525 - val_accuracy: 0.1146\n",
      "Epoch 665/1000\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 3.8328 - accuracy: 0.0852 - val_loss: 4.3525 - val_accuracy: 0.1146\n",
      "Epoch 666/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 3.8328 - accuracy: 0.0852 - val_loss: 4.3525 - val_accuracy: 0.1146\n",
      "Epoch 667/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 3.8328 - accuracy: 0.0852 - val_loss: 4.3525 - val_accuracy: 0.1146\n",
      "Epoch 668/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 3.8328 - accuracy: 0.0852 - val_loss: 4.3525 - val_accuracy: 0.1146\n",
      "Epoch 669/1000\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 3.8328 - accuracy: 0.0852 - val_loss: 4.3525 - val_accuracy: 0.1146\n",
      "Epoch 670/1000\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 3.8328 - accuracy: 0.0852 - val_loss: 4.3525 - val_accuracy: 0.1146\n",
      "Epoch 671/1000\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 3.8328 - accuracy: 0.0852 - val_loss: 4.3525 - val_accuracy: 0.1146\n",
      "Epoch 672/1000\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 3.8328 - accuracy: 0.0852 - val_loss: 4.3525 - val_accuracy: 0.1146\n",
      "Epoch 673/1000\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 3.8328 - accuracy: 0.0852 - val_loss: 4.3525 - val_accuracy: 0.1146\n",
      "Epoch 674/1000\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 3.8328 - accuracy: 0.0852 - val_loss: 4.3525 - val_accuracy: 0.1146\n",
      "Epoch 675/1000\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 3.8328 - accuracy: 0.0852 - val_loss: 4.3525 - val_accuracy: 0.1146\n",
      "Epoch 676/1000\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 3.8328 - accuracy: 0.0852 - val_loss: 4.3525 - val_accuracy: 0.1146\n",
      "Epoch 677/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 3.8328 - accuracy: 0.0852 - val_loss: 4.3525 - val_accuracy: 0.1146\n",
      "Epoch 678/1000\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 3.8328 - accuracy: 0.0852 - val_loss: 4.3525 - val_accuracy: 0.1146\n",
      "Epoch 679/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 3.8328 - accuracy: 0.0852 - val_loss: 4.3525 - val_accuracy: 0.1146\n",
      "Epoch 680/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 3.8328 - accuracy: 0.0852 - val_loss: 4.3525 - val_accuracy: 0.1146\n",
      "Epoch 681/1000\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 3.8328 - accuracy: 0.0852 - val_loss: 4.3525 - val_accuracy: 0.1146\n",
      "Epoch 682/1000\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 3.8328 - accuracy: 0.0852 - val_loss: 4.3525 - val_accuracy: 0.1146\n",
      "Epoch 683/1000\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 3.8328 - accuracy: 0.0852 - val_loss: 4.3525 - val_accuracy: 0.1146\n",
      "Epoch 684/1000\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 3.8328 - accuracy: 0.0852 - val_loss: 4.3525 - val_accuracy: 0.1146\n",
      "Epoch 685/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 3.8328 - accuracy: 0.0852 - val_loss: 4.3525 - val_accuracy: 0.1354\n",
      "Epoch 686/1000\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 3.8328 - accuracy: 0.2422 - val_loss: 4.3525 - val_accuracy: 0.1354\n",
      "Epoch 687/1000\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 3.8328 - accuracy: 0.2422 - val_loss: 4.3525 - val_accuracy: 0.1354\n",
      "Epoch 688/1000\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 3.8328 - accuracy: 0.2422 - val_loss: 4.3525 - val_accuracy: 0.1354\n",
      "Epoch 689/1000\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 3.8328 - accuracy: 0.2422 - val_loss: 4.3525 - val_accuracy: 0.1354\n",
      "Epoch 690/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 3.8328 - accuracy: 0.2422 - val_loss: 4.3525 - val_accuracy: 0.1354\n",
      "Epoch 691/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 3.8328 - accuracy: 0.2422 - val_loss: 4.3525 - val_accuracy: 0.1354\n",
      "Epoch 692/1000\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 3.8328 - accuracy: 0.2422 - val_loss: 4.3525 - val_accuracy: 0.1354\n",
      "Epoch 693/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 3.8328 - accuracy: 0.2422 - val_loss: 4.3525 - val_accuracy: 0.1354\n",
      "Epoch 694/1000\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 3.8328 - accuracy: 0.2422 - val_loss: 4.3525 - val_accuracy: 0.1354\n",
      "Epoch 695/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 3.8328 - accuracy: 0.2422 - val_loss: 4.3525 - val_accuracy: 0.1354\n",
      "Epoch 696/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 3.8328 - accuracy: 0.2422 - val_loss: 4.3525 - val_accuracy: 0.1354\n",
      "Epoch 697/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 3.8328 - accuracy: 0.2422 - val_loss: 4.3525 - val_accuracy: 0.1354\n",
      "Epoch 698/1000\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 3.8328 - accuracy: 0.2422 - val_loss: 4.3525 - val_accuracy: 0.1354\n",
      "Epoch 699/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 3.8328 - accuracy: 0.2422 - val_loss: 4.3525 - val_accuracy: 0.1354\n",
      "Epoch 700/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 3.8328 - accuracy: 0.2422 - val_loss: 4.3525 - val_accuracy: 0.1354\n",
      "Epoch 701/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 3.8328 - accuracy: 0.2422 - val_loss: 4.3525 - val_accuracy: 0.1354\n",
      "Epoch 702/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 3.8328 - accuracy: 0.2422 - val_loss: 4.3525 - val_accuracy: 0.1354\n",
      "Epoch 703/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 3.8328 - accuracy: 0.2422 - val_loss: 4.3525 - val_accuracy: 0.1354\n",
      "Epoch 704/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 3.8328 - accuracy: 0.2422 - val_loss: 4.3525 - val_accuracy: 0.1354\n",
      "Epoch 705/1000\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 3.8328 - accuracy: 0.2422 - val_loss: 4.3525 - val_accuracy: 0.1354\n",
      "Epoch 706/1000\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 3.8328 - accuracy: 0.2422 - val_loss: 4.3525 - val_accuracy: 0.1354\n",
      "Epoch 707/1000\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 3.8328 - accuracy: 0.2422 - val_loss: 4.3525 - val_accuracy: 0.1354\n",
      "Epoch 708/1000\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 3.8328 - accuracy: 0.2422 - val_loss: 4.3525 - val_accuracy: 0.1354\n",
      "Epoch 709/1000\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 3.8328 - accuracy: 0.2422 - val_loss: 4.3525 - val_accuracy: 0.1354\n",
      "Epoch 710/1000\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 3.8328 - accuracy: 0.2422 - val_loss: 4.3525 - val_accuracy: 0.1354\n",
      "Epoch 711/1000\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 3.8328 - accuracy: 0.2466 - val_loss: 4.3525 - val_accuracy: 0.1354\n",
      "Epoch 712/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 3.8328 - accuracy: 0.2466 - val_loss: 4.3525 - val_accuracy: 0.1354\n",
      "Epoch 713/1000\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 3.8328 - accuracy: 0.2466 - val_loss: 4.3525 - val_accuracy: 0.1354\n",
      "Epoch 714/1000\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 3.8328 - accuracy: 0.2466 - val_loss: 4.3525 - val_accuracy: 0.1354\n",
      "Epoch 715/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 3.8328 - accuracy: 0.2466 - val_loss: 4.3525 - val_accuracy: 0.1354\n",
      "Epoch 716/1000\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 3.8328 - accuracy: 0.2422 - val_loss: 4.3525 - val_accuracy: 0.1354\n",
      "Epoch 717/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 3.8328 - accuracy: 0.2422 - val_loss: 4.3525 - val_accuracy: 0.1354\n",
      "Epoch 718/1000\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 3.8328 - accuracy: 0.2422 - val_loss: 4.3525 - val_accuracy: 0.1354\n",
      "Epoch 719/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 3.8328 - accuracy: 0.2422 - val_loss: 4.3525 - val_accuracy: 0.1354\n",
      "Epoch 720/1000\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 3.8328 - accuracy: 0.2422 - val_loss: 4.3525 - val_accuracy: 0.1354\n",
      "Epoch 721/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 3.8328 - accuracy: 0.2422 - val_loss: 4.3525 - val_accuracy: 0.1354\n",
      "Epoch 722/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 3.8328 - accuracy: 0.2422 - val_loss: 4.3525 - val_accuracy: 0.1354\n",
      "Epoch 723/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 3.8328 - accuracy: 0.2422 - val_loss: 4.3525 - val_accuracy: 0.1354\n",
      "Epoch 724/1000\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 3.8328 - accuracy: 0.2422 - val_loss: 4.3525 - val_accuracy: 0.1354\n",
      "Epoch 725/1000\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 3.8328 - accuracy: 0.2422 - val_loss: 4.3525 - val_accuracy: 0.1354\n",
      "Epoch 726/1000\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 3.8328 - accuracy: 0.2422 - val_loss: 4.3525 - val_accuracy: 0.1354\n",
      "Epoch 727/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 3.8328 - accuracy: 0.2422 - val_loss: 4.3525 - val_accuracy: 0.1354\n",
      "Epoch 728/1000\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 3.8328 - accuracy: 0.2422 - val_loss: 4.3525 - val_accuracy: 0.1354\n",
      "Epoch 729/1000\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 3.8328 - accuracy: 0.2422 - val_loss: 4.3525 - val_accuracy: 0.1354\n",
      "Epoch 730/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 3.8328 - accuracy: 0.2422 - val_loss: 4.3525 - val_accuracy: 0.1354\n",
      "Epoch 731/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 3.8328 - accuracy: 0.2422 - val_loss: 4.3525 - val_accuracy: 0.1354\n",
      "Epoch 732/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 3.8328 - accuracy: 0.2422 - val_loss: 4.3525 - val_accuracy: 0.1354\n",
      "Epoch 733/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 3.8328 - accuracy: 0.2422 - val_loss: 4.3525 - val_accuracy: 0.1146\n",
      "Epoch 734/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 3.8328 - accuracy: 0.0852 - val_loss: 4.3525 - val_accuracy: 0.1146\n",
      "Epoch 735/1000\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 3.8328 - accuracy: 0.0852 - val_loss: 4.3525 - val_accuracy: 0.1146\n",
      "Epoch 736/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 3.8328 - accuracy: 0.0852 - val_loss: 4.3525 - val_accuracy: 0.1146\n",
      "Epoch 737/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 3.8328 - accuracy: 0.0852 - val_loss: 4.3525 - val_accuracy: 0.1146\n",
      "Epoch 738/1000\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 3.8328 - accuracy: 0.0852 - val_loss: 4.3525 - val_accuracy: 0.1146\n",
      "Epoch 739/1000\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 3.8328 - accuracy: 0.0852 - val_loss: 4.3525 - val_accuracy: 0.1146\n",
      "Epoch 740/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 3.8328 - accuracy: 0.0852 - val_loss: 4.3525 - val_accuracy: 0.1146\n",
      "Epoch 741/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 3.8328 - accuracy: 0.0852 - val_loss: 4.3525 - val_accuracy: 0.1146\n",
      "Epoch 742/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 3.8328 - accuracy: 0.0852 - val_loss: 4.3525 - val_accuracy: 0.1146\n",
      "Epoch 743/1000\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 3.8328 - accuracy: 0.0852 - val_loss: 4.3525 - val_accuracy: 0.1146\n",
      "Epoch 744/1000\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 3.8328 - accuracy: 0.0852 - val_loss: 4.3525 - val_accuracy: 0.1146\n",
      "Epoch 745/1000\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 3.8328 - accuracy: 0.0852 - val_loss: 4.3525 - val_accuracy: 0.1146\n",
      "Epoch 746/1000\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 3.8328 - accuracy: 0.1435 - val_loss: 4.3525 - val_accuracy: 0.1354\n",
      "Epoch 747/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 3.8328 - accuracy: 0.2422 - val_loss: 4.3525 - val_accuracy: 0.1354\n",
      "Epoch 748/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 3.8328 - accuracy: 0.2422 - val_loss: 4.3525 - val_accuracy: 0.1354\n",
      "Epoch 749/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 3.8328 - accuracy: 0.2422 - val_loss: 4.3525 - val_accuracy: 0.1354\n",
      "Epoch 750/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 3.8328 - accuracy: 0.2422 - val_loss: 4.3525 - val_accuracy: 0.1354\n",
      "Epoch 751/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 3.8328 - accuracy: 0.2422 - val_loss: 4.3525 - val_accuracy: 0.1354\n",
      "Epoch 752/1000\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 3.8328 - accuracy: 0.2422 - val_loss: 4.3525 - val_accuracy: 0.1354\n",
      "Epoch 753/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 3.8328 - accuracy: 0.2422 - val_loss: 4.3525 - val_accuracy: 0.1354\n",
      "Epoch 754/1000\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 3.8328 - accuracy: 0.2422 - val_loss: 4.3525 - val_accuracy: 0.1354\n",
      "Epoch 755/1000\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 3.8328 - accuracy: 0.2422 - val_loss: 4.3525 - val_accuracy: 0.1354\n",
      "Epoch 756/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 3.8328 - accuracy: 0.2422 - val_loss: 4.3525 - val_accuracy: 0.1354\n",
      "Epoch 757/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 3.8328 - accuracy: 0.2422 - val_loss: 4.3525 - val_accuracy: 0.1354\n",
      "Epoch 758/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 3.8328 - accuracy: 0.2422 - val_loss: 4.3525 - val_accuracy: 0.1354\n",
      "Epoch 759/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 3.8328 - accuracy: 0.2422 - val_loss: 4.3525 - val_accuracy: 0.1354\n",
      "Epoch 760/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 3.8328 - accuracy: 0.2422 - val_loss: 4.3525 - val_accuracy: 0.1354\n",
      "Epoch 761/1000\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 3.8328 - accuracy: 0.2422 - val_loss: 4.3525 - val_accuracy: 0.1354\n",
      "Epoch 762/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 3.8328 - accuracy: 0.2422 - val_loss: 4.3525 - val_accuracy: 0.1354\n",
      "Epoch 763/1000\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 3.8328 - accuracy: 0.1211 - val_loss: 4.3525 - val_accuracy: 0.1146\n",
      "Epoch 764/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 3.8328 - accuracy: 0.0852 - val_loss: 4.3525 - val_accuracy: 0.1146\n",
      "Epoch 765/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 3.8328 - accuracy: 0.0852 - val_loss: 4.3525 - val_accuracy: 0.1146\n",
      "Epoch 766/1000\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 3.8328 - accuracy: 0.0852 - val_loss: 4.3525 - val_accuracy: 0.1146\n",
      "Epoch 767/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 3.8328 - accuracy: 0.0852 - val_loss: 4.3525 - val_accuracy: 0.1146\n",
      "Epoch 768/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 3.8328 - accuracy: 0.0852 - val_loss: 4.3525 - val_accuracy: 0.1146\n",
      "Epoch 769/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 3.8328 - accuracy: 0.0852 - val_loss: 4.3525 - val_accuracy: 0.1146\n",
      "Epoch 770/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 3.8328 - accuracy: 0.0852 - val_loss: 4.3525 - val_accuracy: 0.1146\n",
      "Epoch 771/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 3.8328 - accuracy: 0.0852 - val_loss: 4.3525 - val_accuracy: 0.1146\n",
      "Epoch 772/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 3.8328 - accuracy: 0.0852 - val_loss: 4.3525 - val_accuracy: 0.1146\n",
      "Epoch 773/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 3.8328 - accuracy: 0.0852 - val_loss: 4.3525 - val_accuracy: 0.1146\n",
      "Epoch 774/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 3.8328 - accuracy: 0.0852 - val_loss: 4.3525 - val_accuracy: 0.1146\n",
      "Epoch 775/1000\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 3.8328 - accuracy: 0.0852 - val_loss: 4.3525 - val_accuracy: 0.1146\n",
      "Epoch 776/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 3.8328 - accuracy: 0.0852 - val_loss: 4.3525 - val_accuracy: 0.1146\n",
      "Epoch 777/1000\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 3.8328 - accuracy: 0.0852 - val_loss: 4.3525 - val_accuracy: 0.1146\n",
      "Epoch 778/1000\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 3.8328 - accuracy: 0.0852 - val_loss: 4.3525 - val_accuracy: 0.1146\n",
      "Epoch 779/1000\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 3.8328 - accuracy: 0.0852 - val_loss: 4.3525 - val_accuracy: 0.1146\n",
      "Epoch 780/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 3.8328 - accuracy: 0.0852 - val_loss: 4.3525 - val_accuracy: 0.1146\n",
      "Epoch 781/1000\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 3.8328 - accuracy: 0.0852 - val_loss: 4.3525 - val_accuracy: 0.1146\n",
      "Epoch 782/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 3.8328 - accuracy: 0.0852 - val_loss: 4.3525 - val_accuracy: 0.1146\n",
      "Epoch 783/1000\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 3.8328 - accuracy: 0.0852 - val_loss: 4.3525 - val_accuracy: 0.1146\n",
      "Epoch 784/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 3.8328 - accuracy: 0.0852 - val_loss: 4.3525 - val_accuracy: 0.1146\n",
      "Epoch 785/1000\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 3.8328 - accuracy: 0.0852 - val_loss: 4.3525 - val_accuracy: 0.1146\n",
      "Epoch 786/1000\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 3.8328 - accuracy: 0.0852 - val_loss: 4.3525 - val_accuracy: 0.1146\n",
      "Epoch 787/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 3.8328 - accuracy: 0.0852 - val_loss: 4.3525 - val_accuracy: 0.1146\n",
      "Epoch 788/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 3.8328 - accuracy: 0.0852 - val_loss: 4.3525 - val_accuracy: 0.1146\n",
      "Epoch 789/1000\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 3.8328 - accuracy: 0.0852 - val_loss: 4.3525 - val_accuracy: 0.1146\n",
      "Epoch 790/1000\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 3.8328 - accuracy: 0.0852 - val_loss: 4.3525 - val_accuracy: 0.1146\n",
      "Epoch 791/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 3.8328 - accuracy: 0.0852 - val_loss: 4.3525 - val_accuracy: 0.1146\n",
      "Epoch 792/1000\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 3.8328 - accuracy: 0.0852 - val_loss: 4.3525 - val_accuracy: 0.1146\n",
      "Epoch 793/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 3.8328 - accuracy: 0.0852 - val_loss: 4.3525 - val_accuracy: 0.1146\n",
      "Epoch 794/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 3.8328 - accuracy: 0.0852 - val_loss: 4.3525 - val_accuracy: 0.1146\n",
      "Epoch 795/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 3.8328 - accuracy: 0.0852 - val_loss: 4.3525 - val_accuracy: 0.1146\n",
      "Epoch 796/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 3.8328 - accuracy: 0.0852 - val_loss: 4.3525 - val_accuracy: 0.1146\n",
      "Epoch 797/1000\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 3.8328 - accuracy: 0.0852 - val_loss: 4.3525 - val_accuracy: 0.1146\n",
      "Epoch 798/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 3.8328 - accuracy: 0.0852 - val_loss: 4.3525 - val_accuracy: 0.1146\n",
      "Epoch 799/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 3.8328 - accuracy: 0.0852 - val_loss: 4.3525 - val_accuracy: 0.1146\n",
      "Epoch 800/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 3.8328 - accuracy: 0.0852 - val_loss: 4.3525 - val_accuracy: 0.1146\n",
      "Epoch 801/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 3.8328 - accuracy: 0.0852 - val_loss: 4.3525 - val_accuracy: 0.1146\n",
      "Epoch 802/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 3.8328 - accuracy: 0.0852 - val_loss: 4.3525 - val_accuracy: 0.1146\n",
      "Epoch 803/1000\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 3.8328 - accuracy: 0.0852 - val_loss: 4.3525 - val_accuracy: 0.1146\n",
      "Epoch 804/1000\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 3.8328 - accuracy: 0.0852 - val_loss: 4.3525 - val_accuracy: 0.1146\n",
      "Epoch 805/1000\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 3.8328 - accuracy: 0.0852 - val_loss: 4.3525 - val_accuracy: 0.1146\n",
      "Epoch 806/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 3.8328 - accuracy: 0.0852 - val_loss: 4.3525 - val_accuracy: 0.1146\n",
      "Epoch 807/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 3.8328 - accuracy: 0.0852 - val_loss: 4.3525 - val_accuracy: 0.1146\n",
      "Epoch 808/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 3.8328 - accuracy: 0.0852 - val_loss: 4.3525 - val_accuracy: 0.1146\n",
      "Epoch 809/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 3.8328 - accuracy: 0.0852 - val_loss: 4.3525 - val_accuracy: 0.1146\n",
      "Epoch 810/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 3.8328 - accuracy: 0.0852 - val_loss: 4.3525 - val_accuracy: 0.1146\n",
      "Epoch 811/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 3.8328 - accuracy: 0.0852 - val_loss: 4.3525 - val_accuracy: 0.1146\n",
      "Epoch 812/1000\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 3.8328 - accuracy: 0.0852 - val_loss: 4.3525 - val_accuracy: 0.1146\n",
      "Epoch 813/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 3.8328 - accuracy: 0.0852 - val_loss: 4.3525 - val_accuracy: 0.1146\n",
      "Epoch 814/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 3.8328 - accuracy: 0.0852 - val_loss: 4.3525 - val_accuracy: 0.1146\n",
      "Epoch 815/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 3.8328 - accuracy: 0.0852 - val_loss: 4.3525 - val_accuracy: 0.1146\n",
      "Epoch 816/1000\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 3.8328 - accuracy: 0.0852 - val_loss: 4.3525 - val_accuracy: 0.1146\n",
      "Epoch 817/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 3.8328 - accuracy: 0.0852 - val_loss: 4.3525 - val_accuracy: 0.1146\n",
      "Epoch 818/1000\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 3.8328 - accuracy: 0.0852 - val_loss: 4.3525 - val_accuracy: 0.1146\n",
      "Epoch 819/1000\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 3.8328 - accuracy: 0.0852 - val_loss: 4.3525 - val_accuracy: 0.1146\n",
      "Epoch 820/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 3.8328 - accuracy: 0.0852 - val_loss: 4.3525 - val_accuracy: 0.1146\n",
      "Epoch 821/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 3.8328 - accuracy: 0.1076 - val_loss: 4.3525 - val_accuracy: 0.1146\n",
      "Epoch 822/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 3.8328 - accuracy: 0.0852 - val_loss: 4.3525 - val_accuracy: 0.1146\n",
      "Epoch 823/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 3.8328 - accuracy: 0.0852 - val_loss: 4.3525 - val_accuracy: 0.1146\n",
      "Epoch 824/1000\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 3.8328 - accuracy: 0.0852 - val_loss: 4.3525 - val_accuracy: 0.1146\n",
      "Epoch 825/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 3.8328 - accuracy: 0.0852 - val_loss: 4.3525 - val_accuracy: 0.1146\n",
      "Epoch 826/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 3.8328 - accuracy: 0.0852 - val_loss: 4.3525 - val_accuracy: 0.1146\n",
      "Epoch 827/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 3.8328 - accuracy: 0.0852 - val_loss: 4.3525 - val_accuracy: 0.1146\n",
      "Epoch 828/1000\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 3.8328 - accuracy: 0.0852 - val_loss: 4.3525 - val_accuracy: 0.1146\n",
      "Epoch 829/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 3.8328 - accuracy: 0.0852 - val_loss: 4.3525 - val_accuracy: 0.1146\n",
      "Epoch 830/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 3.8328 - accuracy: 0.0852 - val_loss: 4.3525 - val_accuracy: 0.1146\n",
      "Epoch 831/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 3.8328 - accuracy: 0.0852 - val_loss: 4.3525 - val_accuracy: 0.1146\n",
      "Epoch 832/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 3.8328 - accuracy: 0.0852 - val_loss: 4.3525 - val_accuracy: 0.1146\n",
      "Epoch 833/1000\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 3.8328 - accuracy: 0.0852 - val_loss: 4.3525 - val_accuracy: 0.1354\n",
      "Epoch 834/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 3.8328 - accuracy: 0.2422 - val_loss: 4.3525 - val_accuracy: 0.1354\n",
      "Epoch 835/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 3.8328 - accuracy: 0.2422 - val_loss: 4.3525 - val_accuracy: 0.1354\n",
      "Epoch 836/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 3.8328 - accuracy: 0.2422 - val_loss: 4.3525 - val_accuracy: 0.1354\n",
      "Epoch 837/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 3.8328 - accuracy: 0.2422 - val_loss: 4.3525 - val_accuracy: 0.1354\n",
      "Epoch 838/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 3.8328 - accuracy: 0.2422 - val_loss: 4.3525 - val_accuracy: 0.1354\n",
      "Epoch 839/1000\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 3.8328 - accuracy: 0.2422 - val_loss: 4.3525 - val_accuracy: 0.1354\n",
      "Epoch 840/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 3.8328 - accuracy: 0.2332 - val_loss: 4.3525 - val_accuracy: 0.1146\n",
      "Epoch 841/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 3.8328 - accuracy: 0.0852 - val_loss: 4.3525 - val_accuracy: 0.1146\n",
      "Epoch 842/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 3.8328 - accuracy: 0.0852 - val_loss: 4.3525 - val_accuracy: 0.1146\n",
      "Epoch 843/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 3.8328 - accuracy: 0.0852 - val_loss: 4.3525 - val_accuracy: 0.1146\n",
      "Epoch 844/1000\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 3.8328 - accuracy: 0.0852 - val_loss: 4.3525 - val_accuracy: 0.1146\n",
      "Epoch 845/1000\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 3.8328 - accuracy: 0.0852 - val_loss: 4.3525 - val_accuracy: 0.1146\n",
      "Epoch 846/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 3.8328 - accuracy: 0.0852 - val_loss: 4.3525 - val_accuracy: 0.1146\n",
      "Epoch 847/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 3.8328 - accuracy: 0.0852 - val_loss: 4.3525 - val_accuracy: 0.1354\n",
      "Epoch 848/1000\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 3.8328 - accuracy: 0.2422 - val_loss: 4.3525 - val_accuracy: 0.1354\n",
      "Epoch 849/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 3.8328 - accuracy: 0.2422 - val_loss: 4.3525 - val_accuracy: 0.1354\n",
      "Epoch 850/1000\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 3.8328 - accuracy: 0.2422 - val_loss: 4.3525 - val_accuracy: 0.1354\n",
      "Epoch 851/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 3.8328 - accuracy: 0.2422 - val_loss: 4.3525 - val_accuracy: 0.1354\n",
      "Epoch 852/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 3.8328 - accuracy: 0.2422 - val_loss: 4.3525 - val_accuracy: 0.1354\n",
      "Epoch 853/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 3.8328 - accuracy: 0.2422 - val_loss: 4.3525 - val_accuracy: 0.1354\n",
      "Epoch 854/1000\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 3.8328 - accuracy: 0.2422 - val_loss: 4.3525 - val_accuracy: 0.1146\n",
      "Epoch 855/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 3.8328 - accuracy: 0.0852 - val_loss: 4.3525 - val_accuracy: 0.1146\n",
      "Epoch 856/1000\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 3.8328 - accuracy: 0.0852 - val_loss: 4.3525 - val_accuracy: 0.1146\n",
      "Epoch 857/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 3.8328 - accuracy: 0.0852 - val_loss: 4.3525 - val_accuracy: 0.1146\n",
      "Epoch 858/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 3.8328 - accuracy: 0.0852 - val_loss: 4.3525 - val_accuracy: 0.1146\n",
      "Epoch 859/1000\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 3.8328 - accuracy: 0.0852 - val_loss: 4.3525 - val_accuracy: 0.1146\n",
      "Epoch 860/1000\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 3.8328 - accuracy: 0.0852 - val_loss: 4.3525 - val_accuracy: 0.1146\n",
      "Epoch 861/1000\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 3.8328 - accuracy: 0.0852 - val_loss: 4.3525 - val_accuracy: 0.1146\n",
      "Epoch 862/1000\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 3.8328 - accuracy: 0.0852 - val_loss: 4.3525 - val_accuracy: 0.1146\n",
      "Epoch 863/1000\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 3.8328 - accuracy: 0.0852 - val_loss: 4.3525 - val_accuracy: 0.1146\n",
      "Epoch 864/1000\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 3.8328 - accuracy: 0.0852 - val_loss: 4.3525 - val_accuracy: 0.1146\n",
      "Epoch 865/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 3.8328 - accuracy: 0.0852 - val_loss: 4.3525 - val_accuracy: 0.1146\n",
      "Epoch 866/1000\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 3.8328 - accuracy: 0.0852 - val_loss: 4.3525 - val_accuracy: 0.1146\n",
      "Epoch 867/1000\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 3.8328 - accuracy: 0.0852 - val_loss: 4.3525 - val_accuracy: 0.1146\n",
      "Epoch 868/1000\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 3.8328 - accuracy: 0.0852 - val_loss: 4.3525 - val_accuracy: 0.1146\n",
      "Epoch 869/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 3.8328 - accuracy: 0.0852 - val_loss: 4.3525 - val_accuracy: 0.1146\n",
      "Epoch 870/1000\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 3.8328 - accuracy: 0.0852 - val_loss: 4.3525 - val_accuracy: 0.1146\n",
      "Epoch 871/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 3.8328 - accuracy: 0.0852 - val_loss: 4.3525 - val_accuracy: 0.1146\n",
      "Epoch 872/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 3.8328 - accuracy: 0.0852 - val_loss: 4.3525 - val_accuracy: 0.1146\n",
      "Epoch 873/1000\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 3.8328 - accuracy: 0.0852 - val_loss: 4.3525 - val_accuracy: 0.1146\n",
      "Epoch 874/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 3.8328 - accuracy: 0.0852 - val_loss: 4.3525 - val_accuracy: 0.1146\n",
      "Epoch 875/1000\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 3.8328 - accuracy: 0.0852 - val_loss: 4.3525 - val_accuracy: 0.1146\n",
      "Epoch 876/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 3.8328 - accuracy: 0.0852 - val_loss: 4.3525 - val_accuracy: 0.1146\n",
      "Epoch 877/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 3.8328 - accuracy: 0.0852 - val_loss: 4.3525 - val_accuracy: 0.1146\n",
      "Epoch 878/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 3.8328 - accuracy: 0.0852 - val_loss: 4.3525 - val_accuracy: 0.1146\n",
      "Epoch 879/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 3.8328 - accuracy: 0.0852 - val_loss: 4.3525 - val_accuracy: 0.1146\n",
      "Epoch 880/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 3.8328 - accuracy: 0.0852 - val_loss: 4.3525 - val_accuracy: 0.1146\n",
      "Epoch 881/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 3.8328 - accuracy: 0.0852 - val_loss: 4.3525 - val_accuracy: 0.1146\n",
      "Epoch 882/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 3.8328 - accuracy: 0.0852 - val_loss: 4.3525 - val_accuracy: 0.1146\n",
      "Epoch 883/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 3.8328 - accuracy: 0.0852 - val_loss: 4.3525 - val_accuracy: 0.1146\n",
      "Epoch 884/1000\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 3.8328 - accuracy: 0.0852 - val_loss: 4.3525 - val_accuracy: 0.1146\n",
      "Epoch 885/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 3.8328 - accuracy: 0.0852 - val_loss: 4.3525 - val_accuracy: 0.1146\n",
      "Epoch 886/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 3.8328 - accuracy: 0.0852 - val_loss: 4.3525 - val_accuracy: 0.1146\n",
      "Epoch 887/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 3.8328 - accuracy: 0.0852 - val_loss: 4.3525 - val_accuracy: 0.1146\n",
      "Epoch 888/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 3.8328 - accuracy: 0.0852 - val_loss: 4.3525 - val_accuracy: 0.1146\n",
      "Epoch 889/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 3.8328 - accuracy: 0.0852 - val_loss: 4.3525 - val_accuracy: 0.1146\n",
      "Epoch 890/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 3.8328 - accuracy: 0.0852 - val_loss: 4.3525 - val_accuracy: 0.1146\n",
      "Epoch 891/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 3.8328 - accuracy: 0.0852 - val_loss: 4.3525 - val_accuracy: 0.1146\n",
      "Epoch 892/1000\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 3.8328 - accuracy: 0.0852 - val_loss: 4.3525 - val_accuracy: 0.1146\n",
      "Epoch 893/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 3.8328 - accuracy: 0.0852 - val_loss: 4.3525 - val_accuracy: 0.1146\n",
      "Epoch 894/1000\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 3.8328 - accuracy: 0.0852 - val_loss: 4.3525 - val_accuracy: 0.1146\n",
      "Epoch 895/1000\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 3.8328 - accuracy: 0.0852 - val_loss: 4.3525 - val_accuracy: 0.1146\n",
      "Epoch 896/1000\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 3.8328 - accuracy: 0.0852 - val_loss: 4.3525 - val_accuracy: 0.1146\n",
      "Epoch 897/1000\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 3.8328 - accuracy: 0.0852 - val_loss: 4.3525 - val_accuracy: 0.1146\n",
      "Epoch 898/1000\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 3.8328 - accuracy: 0.0852 - val_loss: 4.3525 - val_accuracy: 0.1146\n",
      "Epoch 899/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 3.8328 - accuracy: 0.0852 - val_loss: 4.3525 - val_accuracy: 0.1146\n",
      "Epoch 900/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 3.8328 - accuracy: 0.0852 - val_loss: 4.3525 - val_accuracy: 0.1146\n",
      "Epoch 901/1000\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 3.8328 - accuracy: 0.0852 - val_loss: 4.3525 - val_accuracy: 0.1146\n",
      "Epoch 902/1000\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 3.8328 - accuracy: 0.0852 - val_loss: 4.3525 - val_accuracy: 0.1146\n",
      "Epoch 903/1000\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 3.8328 - accuracy: 0.0852 - val_loss: 4.3525 - val_accuracy: 0.1146\n",
      "Epoch 904/1000\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 3.8328 - accuracy: 0.0852 - val_loss: 4.3525 - val_accuracy: 0.1146\n",
      "Epoch 905/1000\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 3.8328 - accuracy: 0.0852 - val_loss: 4.3525 - val_accuracy: 0.1146\n",
      "Epoch 906/1000\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 3.8328 - accuracy: 0.0852 - val_loss: 4.3525 - val_accuracy: 0.1146\n",
      "Epoch 907/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 3.8328 - accuracy: 0.0852 - val_loss: 4.3525 - val_accuracy: 0.1146\n",
      "Epoch 908/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 3.8328 - accuracy: 0.0852 - val_loss: 4.3525 - val_accuracy: 0.1146\n",
      "Epoch 909/1000\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 3.8328 - accuracy: 0.0852 - val_loss: 4.3525 - val_accuracy: 0.1146\n",
      "Epoch 910/1000\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 3.8328 - accuracy: 0.0852 - val_loss: 4.3525 - val_accuracy: 0.1146\n",
      "Epoch 911/1000\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 3.8328 - accuracy: 0.0852 - val_loss: 4.3525 - val_accuracy: 0.1146\n",
      "Epoch 912/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 3.8328 - accuracy: 0.0852 - val_loss: 4.3525 - val_accuracy: 0.1146\n",
      "Epoch 913/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 3.8328 - accuracy: 0.0852 - val_loss: 4.3525 - val_accuracy: 0.1146\n",
      "Epoch 914/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 3.8328 - accuracy: 0.0852 - val_loss: 4.3525 - val_accuracy: 0.1146\n",
      "Epoch 915/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 3.8328 - accuracy: 0.0852 - val_loss: 4.3525 - val_accuracy: 0.1146\n",
      "Epoch 916/1000\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 3.8328 - accuracy: 0.0852 - val_loss: 4.3525 - val_accuracy: 0.1146\n",
      "Epoch 917/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 3.8328 - accuracy: 0.0852 - val_loss: 4.3525 - val_accuracy: 0.1146\n",
      "Epoch 918/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 3.8328 - accuracy: 0.0852 - val_loss: 4.3525 - val_accuracy: 0.1146\n",
      "Epoch 919/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 3.8328 - accuracy: 0.0852 - val_loss: 4.3525 - val_accuracy: 0.1146\n",
      "Epoch 920/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 3.8328 - accuracy: 0.0852 - val_loss: 4.3525 - val_accuracy: 0.1146\n",
      "Epoch 921/1000\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 3.8328 - accuracy: 0.0852 - val_loss: 4.3525 - val_accuracy: 0.1146\n",
      "Epoch 922/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 3.8328 - accuracy: 0.0852 - val_loss: 4.3525 - val_accuracy: 0.1146\n",
      "Epoch 923/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 3.8328 - accuracy: 0.0852 - val_loss: 4.3525 - val_accuracy: 0.1146\n",
      "Epoch 924/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 3.8328 - accuracy: 0.0852 - val_loss: 4.3525 - val_accuracy: 0.1146\n",
      "Epoch 925/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 3.8328 - accuracy: 0.0852 - val_loss: 4.3525 - val_accuracy: 0.1146\n",
      "Epoch 926/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 3.8328 - accuracy: 0.0852 - val_loss: 4.3525 - val_accuracy: 0.1146\n",
      "Epoch 927/1000\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 3.8328 - accuracy: 0.0852 - val_loss: 4.3525 - val_accuracy: 0.1146\n",
      "Epoch 928/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 3.8328 - accuracy: 0.0852 - val_loss: 4.3525 - val_accuracy: 0.1146\n",
      "Epoch 929/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 3.8328 - accuracy: 0.0852 - val_loss: 4.3525 - val_accuracy: 0.1146\n",
      "Epoch 930/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 3.8328 - accuracy: 0.0852 - val_loss: 4.3525 - val_accuracy: 0.1146\n",
      "Epoch 931/1000\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 3.8328 - accuracy: 0.0852 - val_loss: 4.3525 - val_accuracy: 0.1146\n",
      "Epoch 932/1000\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 3.8328 - accuracy: 0.0852 - val_loss: 4.3525 - val_accuracy: 0.1146\n",
      "Epoch 933/1000\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 3.8328 - accuracy: 0.0852 - val_loss: 4.3525 - val_accuracy: 0.1146\n",
      "Epoch 934/1000\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 3.8328 - accuracy: 0.0852 - val_loss: 4.3525 - val_accuracy: 0.1146\n",
      "Epoch 935/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 3.8328 - accuracy: 0.0852 - val_loss: 4.3525 - val_accuracy: 0.1146\n",
      "Epoch 936/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 3.8328 - accuracy: 0.0852 - val_loss: 4.3525 - val_accuracy: 0.1146\n",
      "Epoch 937/1000\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 3.8328 - accuracy: 0.0852 - val_loss: 4.3525 - val_accuracy: 0.1146\n",
      "Epoch 938/1000\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 3.8328 - accuracy: 0.0852 - val_loss: 4.3525 - val_accuracy: 0.1146\n",
      "Epoch 939/1000\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 3.8328 - accuracy: 0.0852 - val_loss: 4.3525 - val_accuracy: 0.1146\n",
      "Epoch 940/1000\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 3.8328 - accuracy: 0.0852 - val_loss: 4.3525 - val_accuracy: 0.1146\n",
      "Epoch 941/1000\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 3.8328 - accuracy: 0.0852 - val_loss: 4.3525 - val_accuracy: 0.1146\n",
      "Epoch 942/1000\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 3.8328 - accuracy: 0.0852 - val_loss: 4.3525 - val_accuracy: 0.1146\n",
      "Epoch 943/1000\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 3.8328 - accuracy: 0.0852 - val_loss: 4.3525 - val_accuracy: 0.1146\n",
      "Epoch 944/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 3.8328 - accuracy: 0.0852 - val_loss: 4.3525 - val_accuracy: 0.1146\n",
      "Epoch 945/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 3.8328 - accuracy: 0.0852 - val_loss: 4.3525 - val_accuracy: 0.1146\n",
      "Epoch 946/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 3.8328 - accuracy: 0.0852 - val_loss: 4.3525 - val_accuracy: 0.1146\n",
      "Epoch 947/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 3.8328 - accuracy: 0.0852 - val_loss: 4.3525 - val_accuracy: 0.1146\n",
      "Epoch 948/1000\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 3.8328 - accuracy: 0.0852 - val_loss: 4.3525 - val_accuracy: 0.1146\n",
      "Epoch 949/1000\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 3.8328 - accuracy: 0.0852 - val_loss: 4.3525 - val_accuracy: 0.1146\n",
      "Epoch 950/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 3.8328 - accuracy: 0.0852 - val_loss: 4.3525 - val_accuracy: 0.1146\n",
      "Epoch 951/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 3.8328 - accuracy: 0.0852 - val_loss: 4.3525 - val_accuracy: 0.1146\n",
      "Epoch 952/1000\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 3.8328 - accuracy: 0.0852 - val_loss: 4.3525 - val_accuracy: 0.1146\n",
      "Epoch 953/1000\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 3.8328 - accuracy: 0.0852 - val_loss: 4.3525 - val_accuracy: 0.1146\n",
      "Epoch 954/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 3.8328 - accuracy: 0.0852 - val_loss: 4.3525 - val_accuracy: 0.1146\n",
      "Epoch 955/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 3.8328 - accuracy: 0.0852 - val_loss: 4.3525 - val_accuracy: 0.1146\n",
      "Epoch 956/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 3.8328 - accuracy: 0.0852 - val_loss: 4.3525 - val_accuracy: 0.1146\n",
      "Epoch 957/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 3.8328 - accuracy: 0.0852 - val_loss: 4.3525 - val_accuracy: 0.1146\n",
      "Epoch 958/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 3.8328 - accuracy: 0.0852 - val_loss: 4.3525 - val_accuracy: 0.1146\n",
      "Epoch 959/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 3.8328 - accuracy: 0.0852 - val_loss: 4.3525 - val_accuracy: 0.1146\n",
      "Epoch 960/1000\n",
      "3/3 [==============================] - 0s 12ms/step - loss: 3.8328 - accuracy: 0.0852 - val_loss: 4.3525 - val_accuracy: 0.1146\n",
      "Epoch 961/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 3.8328 - accuracy: 0.0852 - val_loss: 4.3525 - val_accuracy: 0.1146\n",
      "Epoch 962/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 3.8328 - accuracy: 0.0852 - val_loss: 4.3525 - val_accuracy: 0.1146\n",
      "Epoch 963/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 3.8328 - accuracy: 0.0852 - val_loss: 4.3525 - val_accuracy: 0.1146\n",
      "Epoch 964/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 3.8328 - accuracy: 0.0852 - val_loss: 4.3525 - val_accuracy: 0.1146\n",
      "Epoch 965/1000\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 3.8328 - accuracy: 0.0852 - val_loss: 4.3525 - val_accuracy: 0.1146\n",
      "Epoch 966/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 3.8328 - accuracy: 0.0852 - val_loss: 4.3525 - val_accuracy: 0.1146\n",
      "Epoch 967/1000\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 3.8328 - accuracy: 0.0852 - val_loss: 4.3525 - val_accuracy: 0.1146\n",
      "Epoch 968/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 3.8328 - accuracy: 0.0852 - val_loss: 4.3525 - val_accuracy: 0.1146\n",
      "Epoch 969/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 3.8328 - accuracy: 0.0852 - val_loss: 4.3525 - val_accuracy: 0.1146\n",
      "Epoch 970/1000\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 3.8328 - accuracy: 0.0852 - val_loss: 4.3525 - val_accuracy: 0.1146\n",
      "Epoch 971/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 3.8328 - accuracy: 0.0852 - val_loss: 4.3525 - val_accuracy: 0.1146\n",
      "Epoch 972/1000\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 3.8328 - accuracy: 0.0852 - val_loss: 4.3525 - val_accuracy: 0.1146\n",
      "Epoch 973/1000\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 3.8328 - accuracy: 0.0852 - val_loss: 4.3525 - val_accuracy: 0.1146\n",
      "Epoch 974/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 3.8328 - accuracy: 0.0852 - val_loss: 4.3525 - val_accuracy: 0.1146\n",
      "Epoch 975/1000\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 3.8328 - accuracy: 0.0852 - val_loss: 4.3525 - val_accuracy: 0.1146\n",
      "Epoch 976/1000\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 3.8328 - accuracy: 0.0852 - val_loss: 4.3525 - val_accuracy: 0.1146\n",
      "Epoch 977/1000\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 3.8328 - accuracy: 0.0852 - val_loss: 4.3525 - val_accuracy: 0.1146\n",
      "Epoch 978/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 3.8328 - accuracy: 0.0852 - val_loss: 4.3525 - val_accuracy: 0.1146\n",
      "Epoch 979/1000\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 3.8328 - accuracy: 0.0852 - val_loss: 4.3525 - val_accuracy: 0.1146\n",
      "Epoch 980/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 3.8328 - accuracy: 0.0852 - val_loss: 4.3525 - val_accuracy: 0.1146\n",
      "Epoch 981/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 3.8328 - accuracy: 0.0852 - val_loss: 4.3525 - val_accuracy: 0.1146\n",
      "Epoch 982/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 3.8328 - accuracy: 0.0852 - val_loss: 4.3525 - val_accuracy: 0.1146\n",
      "Epoch 983/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 3.8328 - accuracy: 0.0852 - val_loss: 4.3525 - val_accuracy: 0.1146\n",
      "Epoch 984/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 3.8328 - accuracy: 0.0852 - val_loss: 4.3525 - val_accuracy: 0.1146\n",
      "Epoch 985/1000\n",
      "3/3 [==============================] - 0s 17ms/step - loss: 3.8328 - accuracy: 0.0852 - val_loss: 4.3525 - val_accuracy: 0.1146\n",
      "Epoch 986/1000\n",
      "3/3 [==============================] - 0s 19ms/step - loss: 3.8328 - accuracy: 0.0852 - val_loss: 4.3525 - val_accuracy: 0.1146\n",
      "Epoch 987/1000\n",
      "3/3 [==============================] - 0s 21ms/step - loss: 3.8328 - accuracy: 0.0852 - val_loss: 4.3525 - val_accuracy: 0.1146\n",
      "Epoch 988/1000\n",
      "3/3 [==============================] - 0s 15ms/step - loss: 3.8328 - accuracy: 0.0852 - val_loss: 4.3525 - val_accuracy: 0.1146\n",
      "Epoch 989/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 3.8328 - accuracy: 0.0852 - val_loss: 4.3525 - val_accuracy: 0.1146\n",
      "Epoch 990/1000\n",
      "3/3 [==============================] - 0s 20ms/step - loss: 3.8328 - accuracy: 0.0852 - val_loss: 4.3525 - val_accuracy: 0.1146\n",
      "Epoch 991/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 3.8328 - accuracy: 0.0852 - val_loss: 4.3525 - val_accuracy: 0.1146\n",
      "Epoch 992/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 3.8328 - accuracy: 0.0852 - val_loss: 4.3525 - val_accuracy: 0.1146\n",
      "Epoch 993/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 3.8328 - accuracy: 0.0852 - val_loss: 4.3525 - val_accuracy: 0.1146\n",
      "Epoch 994/1000\n",
      "3/3 [==============================] - 0s 13ms/step - loss: 3.8328 - accuracy: 0.0852 - val_loss: 4.3525 - val_accuracy: 0.1146\n",
      "Epoch 995/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 3.8328 - accuracy: 0.0852 - val_loss: 4.3525 - val_accuracy: 0.1146\n",
      "Epoch 996/1000\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 3.8328 - accuracy: 0.0852 - val_loss: 4.3525 - val_accuracy: 0.1146\n",
      "Epoch 997/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 3.8328 - accuracy: 0.0852 - val_loss: 4.3525 - val_accuracy: 0.1146\n",
      "Epoch 998/1000\n",
      "3/3 [==============================] - 0s 18ms/step - loss: 3.8328 - accuracy: 0.0852 - val_loss: 4.3525 - val_accuracy: 0.1146\n",
      "Epoch 999/1000\n",
      "3/3 [==============================] - 0s 14ms/step - loss: 3.8328 - accuracy: 0.0852 - val_loss: 4.3525 - val_accuracy: 0.1146\n",
      "Epoch 1000/1000\n",
      "3/3 [==============================] - 0s 16ms/step - loss: 3.8328 - accuracy: 0.0852 - val_loss: 4.3525 - val_accuracy: 0.1146\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "import random\n",
    "\n",
    "\n",
    "camadas_ocultas = 10\n",
    "funcoes_ativacao = ['relu', 'sigmoid','softmax','softplus','softsign','tanh','selu','elu','exponential']\n",
    "epochs = 1000\n",
    "\n",
    "\n",
    "\n",
    "model = keras.models.Sequential()\n",
    "\n",
    "model.add(keras.layers.Dense(\n",
    "        units=10,\n",
    "        input_dim=X_train.shape[1],\n",
    "        kernel_initializer='glorot_uniform',\n",
    "        bias_initializer='zeros',\n",
    "        activation='exponential')\n",
    "     )\n",
    "\n",
    "model.add(keras.layers.Dense(\n",
    "            units=7,\n",
    "            input_dim=10,\n",
    "            kernel_initializer='glorot_uniform',\n",
    "            bias_initializer='zeros',\n",
    "            activation='relu' ))\n",
    "        \n",
    "model.add(\n",
    "    keras.layers.Dense(\n",
    "    units=5,\n",
    "    input_dim=7,\n",
    "    kernel_initializer='glorot_uniform',\n",
    "    bias_initializer='zeros',\n",
    "    activation='softmax')\n",
    ")\n",
    "    \n",
    "model.compile(\n",
    "    optimizer=\"adam\",\n",
    "    loss='mse',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    batch_size=100, epochs=epochs,\n",
    "    verbose=1, validation_split=0.30\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "a22bdb8c-7719-43eb-b05a-0074329cc22e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import SGD\n",
    "from tensorflow.keras.metrics import BinaryAccuracy, Accuracy\n",
    "\n",
    "\n",
    "sgd_optimizer = SGD(\n",
    "    lr=0.001, decay=1e-7, momentum=0.9\n",
    ")\n",
    "\n",
    "# compile model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "fe4fe0e8-2aa1-43ce-9c5c-09e3c3865dcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "3/3 [==============================] - 1s 187ms/step - loss: 4.6090 - accuracy: 0.0000e+00 - val_loss: 4.6136 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/500\n",
      "3/3 [==============================] - 0s 50ms/step - loss: 4.6090 - accuracy: 0.0000e+00 - val_loss: 4.6136 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/500\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 4.6090 - accuracy: 0.0000e+00 - val_loss: 4.6136 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/500\n",
      "3/3 [==============================] - 0s 38ms/step - loss: 4.6090 - accuracy: 0.0000e+00 - val_loss: 4.6136 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/500\n",
      "3/3 [==============================] - 0s 38ms/step - loss: 4.6090 - accuracy: 0.0000e+00 - val_loss: 4.6136 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/500\n",
      "3/3 [==============================] - 0s 39ms/step - loss: 4.6090 - accuracy: 0.0000e+00 - val_loss: 4.6136 - val_accuracy: 0.0000e+00\n",
      "Epoch 7/500\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 4.6090 - accuracy: 0.0000e+00 - val_loss: 4.6136 - val_accuracy: 0.0000e+00\n",
      "Epoch 8/500\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 4.6090 - accuracy: 0.0000e+00 - val_loss: 4.6136 - val_accuracy: 0.0000e+00\n",
      "Epoch 9/500\n",
      "3/3 [==============================] - 0s 38ms/step - loss: 4.6090 - accuracy: 0.0000e+00 - val_loss: 4.6136 - val_accuracy: 0.0000e+00\n",
      "Epoch 10/500\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 4.6090 - accuracy: 0.0000e+00 - val_loss: 4.6136 - val_accuracy: 0.0000e+00\n",
      "Epoch 11/500\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 4.6090 - accuracy: 0.0000e+00 - val_loss: 4.6136 - val_accuracy: 0.0000e+00\n",
      "Epoch 12/500\n",
      "3/3 [==============================] - 0s 55ms/step - loss: 4.6090 - accuracy: 0.0000e+00 - val_loss: 4.6136 - val_accuracy: 0.0000e+00\n",
      "Epoch 13/500\n",
      "3/3 [==============================] - 0s 71ms/step - loss: 4.6090 - accuracy: 0.0000e+00 - val_loss: 4.6136 - val_accuracy: 0.0000e+00\n",
      "Epoch 14/500\n",
      "3/3 [==============================] - 0s 61ms/step - loss: 4.6090 - accuracy: 0.0000e+00 - val_loss: 4.6136 - val_accuracy: 0.0000e+00\n",
      "Epoch 15/500\n",
      "3/3 [==============================] - 0s 37ms/step - loss: 4.6090 - accuracy: 0.0000e+00 - val_loss: 4.6136 - val_accuracy: 0.0000e+00\n",
      "Epoch 16/500\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 4.6090 - accuracy: 0.0000e+00 - val_loss: 4.6136 - val_accuracy: 0.0000e+00\n",
      "Epoch 17/500\n",
      "3/3 [==============================] - 0s 38ms/step - loss: 4.6090 - accuracy: 0.0000e+00 - val_loss: 4.6136 - val_accuracy: 0.0000e+00\n",
      "Epoch 18/500\n",
      "3/3 [==============================] - 0s 37ms/step - loss: 4.6090 - accuracy: 0.0000e+00 - val_loss: 4.6136 - val_accuracy: 0.0000e+00\n",
      "Epoch 19/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 4.6090 - accuracy: 0.0000e+00 - val_loss: 4.6136 - val_accuracy: 0.0000e+00\n",
      "Epoch 20/500\n",
      "3/3 [==============================] - 0s 51ms/step - loss: 4.6090 - accuracy: 0.0000e+00 - val_loss: 4.6136 - val_accuracy: 0.0000e+00\n",
      "Epoch 21/500\n",
      "3/3 [==============================] - 0s 58ms/step - loss: 4.6090 - accuracy: 0.0000e+00 - val_loss: 4.6136 - val_accuracy: 0.0000e+00\n",
      "Epoch 22/500\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 4.6090 - accuracy: 0.0000e+00 - val_loss: 4.6136 - val_accuracy: 0.0000e+00\n",
      "Epoch 23/500\n",
      "3/3 [==============================] - 0s 58ms/step - loss: 4.6090 - accuracy: 0.0000e+00 - val_loss: 4.6136 - val_accuracy: 0.0000e+00\n",
      "Epoch 24/500\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 4.6090 - accuracy: 0.0000e+00 - val_loss: 4.6136 - val_accuracy: 0.0000e+00\n",
      "Epoch 25/500\n",
      "3/3 [==============================] - 0s 50ms/step - loss: 4.6090 - accuracy: 0.0000e+00 - val_loss: 4.6136 - val_accuracy: 0.0000e+00\n",
      "Epoch 26/500\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 4.6090 - accuracy: 0.0000e+00 - val_loss: 4.6136 - val_accuracy: 0.0000e+00\n",
      "Epoch 27/500\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 4.6090 - accuracy: 0.0000e+00 - val_loss: 4.6136 - val_accuracy: 0.0000e+00\n",
      "Epoch 28/500\n",
      "3/3 [==============================] - 0s 37ms/step - loss: 4.6090 - accuracy: 0.0000e+00 - val_loss: 4.6136 - val_accuracy: 0.0000e+00\n",
      "Epoch 29/500\n",
      "3/3 [==============================] - 0s 40ms/step - loss: 4.6090 - accuracy: 0.0035 - val_loss: 4.6136 - val_accuracy: 0.0000e+00\n",
      "Epoch 30/500\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 4.6090 - accuracy: 0.0314 - val_loss: 4.6136 - val_accuracy: 0.0312\n",
      "Epoch 31/500\n",
      "3/3 [==============================] - 0s 53ms/step - loss: 4.6090 - accuracy: 0.0314 - val_loss: 4.6136 - val_accuracy: 0.0000e+00\n",
      "Epoch 32/500\n",
      "3/3 [==============================] - 0s 38ms/step - loss: 4.6090 - accuracy: 0.0244 - val_loss: 4.6136 - val_accuracy: 0.0000e+00\n",
      "Epoch 33/500\n",
      "3/3 [==============================] - 0s 37ms/step - loss: 4.6090 - accuracy: 0.0279 - val_loss: 4.6136 - val_accuracy: 0.0000e+00\n",
      "Epoch 34/500\n",
      "3/3 [==============================] - 0s 37ms/step - loss: 4.6090 - accuracy: 0.0348 - val_loss: 4.6136 - val_accuracy: 0.0312\n",
      "Epoch 35/500\n",
      "3/3 [==============================] - 0s 38ms/step - loss: 4.6090 - accuracy: 0.0488 - val_loss: 4.6136 - val_accuracy: 0.0000e+00\n",
      "Epoch 36/500\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 4.6090 - accuracy: 0.0279 - val_loss: 4.6136 - val_accuracy: 0.0000e+00\n",
      "Epoch 37/500\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 4.6090 - accuracy: 0.0000e+00 - val_loss: 4.6136 - val_accuracy: 0.0000e+00\n",
      "Epoch 38/500\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 4.6090 - accuracy: 0.0000e+00 - val_loss: 4.6136 - val_accuracy: 0.0000e+00\n",
      "Epoch 39/500\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 4.6090 - accuracy: 0.0000e+00 - val_loss: 4.6136 - val_accuracy: 0.0000e+00\n",
      "Epoch 40/500\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 4.6090 - accuracy: 0.0000e+00 - val_loss: 4.6136 - val_accuracy: 0.0000e+00\n",
      "Epoch 41/500\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 4.6090 - accuracy: 0.0000e+00 - val_loss: 4.6136 - val_accuracy: 0.0000e+00\n",
      "Epoch 42/500\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 4.6090 - accuracy: 0.0000e+00 - val_loss: 4.6136 - val_accuracy: 0.0000e+00\n",
      "Epoch 43/500\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 4.6090 - accuracy: 0.0000e+00 - val_loss: 4.6136 - val_accuracy: 0.0000e+00\n",
      "Epoch 44/500\n",
      "3/3 [==============================] - 0s 37ms/step - loss: 4.6090 - accuracy: 0.0000e+00 - val_loss: 4.6136 - val_accuracy: 0.0000e+00\n",
      "Epoch 45/500\n",
      "3/3 [==============================] - 0s 39ms/step - loss: 4.6090 - accuracy: 0.0000e+00 - val_loss: 4.6136 - val_accuracy: 0.0000e+00\n",
      "Epoch 46/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 4.6090 - accuracy: 0.0000e+00 - val_loss: 4.6136 - val_accuracy: 0.0000e+00\n",
      "Epoch 47/500\n",
      "3/3 [==============================] - 0s 39ms/step - loss: 4.6090 - accuracy: 0.0000e+00 - val_loss: 4.6136 - val_accuracy: 0.0000e+00\n",
      "Epoch 48/500\n",
      "3/3 [==============================] - 0s 40ms/step - loss: 4.6090 - accuracy: 0.0000e+00 - val_loss: 4.6136 - val_accuracy: 0.0000e+00\n",
      "Epoch 49/500\n",
      "3/3 [==============================] - 0s 38ms/step - loss: 4.6090 - accuracy: 0.0000e+00 - val_loss: 4.6136 - val_accuracy: 0.0000e+00\n",
      "Epoch 50/500\n",
      "3/3 [==============================] - 0s 51ms/step - loss: 4.6090 - accuracy: 0.0000e+00 - val_loss: 4.6136 - val_accuracy: 0.0000e+00\n",
      "Epoch 51/500\n",
      "3/3 [==============================] - 0s 40ms/step - loss: 4.6090 - accuracy: 0.0000e+00 - val_loss: 4.6136 - val_accuracy: 0.0000e+00\n",
      "Epoch 52/500\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 4.6090 - accuracy: 0.0000e+00 - val_loss: 4.6136 - val_accuracy: 0.0000e+00\n",
      "Epoch 53/500\n",
      "3/3 [==============================] - 0s 73ms/step - loss: 4.6090 - accuracy: 0.0000e+00 - val_loss: 4.6136 - val_accuracy: 0.0000e+00\n",
      "Epoch 54/500\n",
      "3/3 [==============================] - 0s 54ms/step - loss: 4.6090 - accuracy: 0.0000e+00 - val_loss: 4.6136 - val_accuracy: 0.0000e+00\n",
      "Epoch 55/500\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 4.6090 - accuracy: 0.0000e+00 - val_loss: 4.6136 - val_accuracy: 0.0000e+00\n",
      "Epoch 56/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 4.6090 - accuracy: 0.0000e+00 - val_loss: 4.6136 - val_accuracy: 0.0000e+00\n",
      "Epoch 57/500\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 4.6090 - accuracy: 0.0000e+00 - val_loss: 4.6136 - val_accuracy: 0.0000e+00\n",
      "Epoch 58/500\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 4.6090 - accuracy: 0.0000e+00 - val_loss: 4.6136 - val_accuracy: 0.0000e+00\n",
      "Epoch 59/500\n",
      "3/3 [==============================] - 0s 37ms/step - loss: 4.6090 - accuracy: 0.0000e+00 - val_loss: 4.6136 - val_accuracy: 0.0000e+00\n",
      "Epoch 60/500\n",
      "3/3 [==============================] - 0s 37ms/step - loss: 4.6090 - accuracy: 0.0000e+00 - val_loss: 4.6136 - val_accuracy: 0.0000e+00\n",
      "Epoch 61/500\n",
      "3/3 [==============================] - 0s 40ms/step - loss: 4.6090 - accuracy: 0.0000e+00 - val_loss: 4.6136 - val_accuracy: 0.0000e+00\n",
      "Epoch 62/500\n",
      "3/3 [==============================] - 0s 39ms/step - loss: 4.6090 - accuracy: 0.0000e+00 - val_loss: 4.6136 - val_accuracy: 0.0000e+00\n",
      "Epoch 63/500\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 4.6090 - accuracy: 0.0000e+00 - val_loss: 4.6136 - val_accuracy: 0.0000e+00\n",
      "Epoch 64/500\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 4.6090 - accuracy: 0.0000e+00 - val_loss: 4.6136 - val_accuracy: 0.0000e+00\n",
      "Epoch 65/500\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 4.6090 - accuracy: 0.0000e+00 - val_loss: 4.6136 - val_accuracy: 0.0000e+00\n",
      "Epoch 66/500\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 4.6090 - accuracy: 0.0000e+00 - val_loss: 4.6136 - val_accuracy: 0.0000e+00\n",
      "Epoch 67/500\n",
      "3/3 [==============================] - 0s 38ms/step - loss: 4.6090 - accuracy: 0.0000e+00 - val_loss: 4.6136 - val_accuracy: 0.0000e+00\n",
      "Epoch 68/500\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 4.6090 - accuracy: 0.0000e+00 - val_loss: 4.6136 - val_accuracy: 0.0000e+00\n",
      "Epoch 69/500\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 4.6090 - accuracy: 0.0000e+00 - val_loss: 4.6136 - val_accuracy: 0.0000e+00\n",
      "Epoch 70/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 4.6090 - accuracy: 0.0000e+00 - val_loss: 4.6136 - val_accuracy: 0.0000e+00\n",
      "Epoch 71/500\n",
      "3/3 [==============================] - 0s 39ms/step - loss: 4.6090 - accuracy: 0.0000e+00 - val_loss: 4.6136 - val_accuracy: 0.0000e+00\n",
      "Epoch 72/500\n",
      "3/3 [==============================] - 0s 50ms/step - loss: 4.6090 - accuracy: 0.0000e+00 - val_loss: 4.6136 - val_accuracy: 0.0000e+00\n",
      "Epoch 73/500\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 4.6090 - accuracy: 0.0000e+00 - val_loss: 4.6136 - val_accuracy: 0.0000e+00\n",
      "Epoch 74/500\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 4.6090 - accuracy: 0.0000e+00 - val_loss: 4.6136 - val_accuracy: 0.0000e+00\n",
      "Epoch 75/500\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 4.6090 - accuracy: 0.0000e+00 - val_loss: 4.6136 - val_accuracy: 0.0000e+00\n",
      "Epoch 76/500\n",
      "3/3 [==============================] - 0s 56ms/step - loss: 4.6090 - accuracy: 0.0000e+00 - val_loss: 4.6136 - val_accuracy: 0.0000e+00\n",
      "Epoch 77/500\n",
      "3/3 [==============================] - 0s 51ms/step - loss: 4.6090 - accuracy: 0.0000e+00 - val_loss: 4.6136 - val_accuracy: 0.0000e+00\n",
      "Epoch 78/500\n",
      "3/3 [==============================] - 0s 71ms/step - loss: 4.6090 - accuracy: 0.0000e+00 - val_loss: 4.6136 - val_accuracy: 0.0000e+00\n",
      "Epoch 79/500\n",
      "3/3 [==============================] - 0s 60ms/step - loss: 4.6090 - accuracy: 0.0000e+00 - val_loss: 4.6136 - val_accuracy: 0.0000e+00\n",
      "Epoch 80/500\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 4.6090 - accuracy: 0.0000e+00 - val_loss: 4.6136 - val_accuracy: 0.0000e+00\n",
      "Epoch 81/500\n",
      "3/3 [==============================] - 0s 60ms/step - loss: 4.6090 - accuracy: 0.0000e+00 - val_loss: 4.6136 - val_accuracy: 0.0000e+00\n",
      "Epoch 82/500\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 4.6090 - accuracy: 0.0000e+00 - val_loss: 4.6136 - val_accuracy: 0.0000e+00\n",
      "Epoch 83/500\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 4.6090 - accuracy: 0.0000e+00 - val_loss: 4.6136 - val_accuracy: 0.0000e+00\n",
      "Epoch 84/500\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 4.6090 - accuracy: 0.0000e+00 - val_loss: 4.6136 - val_accuracy: 0.0000e+00\n",
      "Epoch 85/500\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 4.6090 - accuracy: 0.0000e+00 - val_loss: 4.6136 - val_accuracy: 0.0000e+00\n",
      "Epoch 86/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 4.6090 - accuracy: 0.0000e+00 - val_loss: 4.6136 - val_accuracy: 0.0000e+00\n",
      "Epoch 87/500\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 4.6090 - accuracy: 0.0000e+00 - val_loss: 4.6136 - val_accuracy: 0.0000e+00\n",
      "Epoch 88/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 4.6090 - accuracy: 0.0000e+00 - val_loss: 4.6136 - val_accuracy: 0.0000e+00\n",
      "Epoch 89/500\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 4.6090 - accuracy: 0.0000e+00 - val_loss: 4.6136 - val_accuracy: 0.0000e+00\n",
      "Epoch 90/500\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 4.6090 - accuracy: 0.0000e+00 - val_loss: 4.6136 - val_accuracy: 0.0000e+00\n",
      "Epoch 91/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 4.6090 - accuracy: 0.0000e+00 - val_loss: 4.6136 - val_accuracy: 0.0000e+00\n",
      "Epoch 92/500\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 4.6090 - accuracy: 0.0000e+00 - val_loss: 4.6136 - val_accuracy: 0.0000e+00\n",
      "Epoch 93/500\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 4.6090 - accuracy: 0.0000e+00 - val_loss: 4.6136 - val_accuracy: 0.0000e+00\n",
      "Epoch 94/500\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 4.6090 - accuracy: 0.0000e+00 - val_loss: 4.6136 - val_accuracy: 0.0000e+00\n",
      "Epoch 95/500\n",
      "3/3 [==============================] - 0s 39ms/step - loss: 4.6090 - accuracy: 0.0000e+00 - val_loss: 4.6136 - val_accuracy: 0.0000e+00\n",
      "Epoch 96/500\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 4.6090 - accuracy: 0.0000e+00 - val_loss: 4.6136 - val_accuracy: 0.0000e+00\n",
      "Epoch 97/500\n",
      "3/3 [==============================] - 0s 38ms/step - loss: 4.6090 - accuracy: 0.0000e+00 - val_loss: 4.6136 - val_accuracy: 0.0000e+00\n",
      "Epoch 98/500\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 4.6090 - accuracy: 0.0000e+00 - val_loss: 4.6136 - val_accuracy: 0.0000e+00\n",
      "Epoch 99/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 4.6090 - accuracy: 0.0000e+00 - val_loss: 4.6136 - val_accuracy: 0.0000e+00\n",
      "Epoch 100/500\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 4.6090 - accuracy: 0.0000e+00 - val_loss: 4.6136 - val_accuracy: 0.0000e+00\n",
      "Epoch 101/500\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 4.6090 - accuracy: 0.0000e+00 - val_loss: 4.6136 - val_accuracy: 0.0000e+00\n",
      "Epoch 102/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 4.6090 - accuracy: 0.0000e+00 - val_loss: 4.6136 - val_accuracy: 0.0000e+00\n",
      "Epoch 103/500\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 4.6090 - accuracy: 0.0000e+00 - val_loss: 4.6136 - val_accuracy: 0.0000e+00\n",
      "Epoch 104/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 4.6090 - accuracy: 0.0000e+00 - val_loss: 4.6136 - val_accuracy: 0.0000e+00\n",
      "Epoch 105/500\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 4.6090 - accuracy: 0.0000e+00 - val_loss: 4.6136 - val_accuracy: 0.0000e+00\n",
      "Epoch 106/500\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 4.6090 - accuracy: 0.0000e+00 - val_loss: 4.6136 - val_accuracy: 0.0000e+00\n",
      "Epoch 107/500\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 4.6090 - accuracy: 0.0000e+00 - val_loss: 4.6136 - val_accuracy: 0.0000e+00\n",
      "Epoch 108/500\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 4.6090 - accuracy: 0.0000e+00 - val_loss: 4.6136 - val_accuracy: 0.0000e+00\n",
      "Epoch 109/500\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 4.6090 - accuracy: 0.0000e+00 - val_loss: 4.6136 - val_accuracy: 0.0000e+00\n",
      "Epoch 110/500\n",
      "3/3 [==============================] - 0s 37ms/step - loss: 4.6090 - accuracy: 0.0000e+00 - val_loss: 4.6136 - val_accuracy: 0.0000e+00\n",
      "Epoch 111/500\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 4.6090 - accuracy: 0.0000e+00 - val_loss: 4.6136 - val_accuracy: 0.0000e+00\n",
      "Epoch 112/500\n",
      "3/3 [==============================] - 0s 40ms/step - loss: 4.6090 - accuracy: 0.0000e+00 - val_loss: 4.6136 - val_accuracy: 0.0000e+00\n",
      "Epoch 113/500\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 4.6090 - accuracy: 0.0000e+00 - val_loss: 4.6136 - val_accuracy: 0.0000e+00\n",
      "Epoch 114/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 4.6090 - accuracy: 0.0000e+00 - val_loss: 4.6136 - val_accuracy: 0.0000e+00\n",
      "Epoch 115/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 4.6090 - accuracy: 0.0000e+00 - val_loss: 4.6136 - val_accuracy: 0.0000e+00\n",
      "Epoch 116/500\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 4.6090 - accuracy: 0.0000e+00 - val_loss: 4.6136 - val_accuracy: 0.0000e+00\n",
      "Epoch 117/500\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 4.6090 - accuracy: 0.0000e+00 - val_loss: 4.6136 - val_accuracy: 0.0000e+00\n",
      "Epoch 118/500\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 4.6090 - accuracy: 0.0000e+00 - val_loss: 4.6136 - val_accuracy: 0.0000e+00\n",
      "Epoch 119/500\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 4.6090 - accuracy: 0.0000e+00 - val_loss: 4.6136 - val_accuracy: 0.0000e+00\n",
      "Epoch 120/500\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 4.6090 - accuracy: 0.0000e+00 - val_loss: 4.6136 - val_accuracy: 0.0000e+00\n",
      "Epoch 121/500\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 4.6090 - accuracy: 0.0000e+00 - val_loss: 4.6136 - val_accuracy: 0.0000e+00\n",
      "Epoch 122/500\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 4.6090 - accuracy: 0.0000e+00 - val_loss: 4.6136 - val_accuracy: 0.0000e+00\n",
      "Epoch 123/500\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 4.6090 - accuracy: 0.0000e+00 - val_loss: 4.6136 - val_accuracy: 0.0000e+00\n",
      "Epoch 124/500\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 4.6090 - accuracy: 0.0000e+00 - val_loss: 4.6136 - val_accuracy: 0.0000e+00\n",
      "Epoch 125/500\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 4.6090 - accuracy: 0.0000e+00 - val_loss: 4.6136 - val_accuracy: 0.0000e+00\n",
      "Epoch 126/500\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 4.6090 - accuracy: 0.0000e+00 - val_loss: 4.6136 - val_accuracy: 0.0000e+00\n",
      "Epoch 127/500\n",
      "3/3 [==============================] - 0s 39ms/step - loss: 4.6090 - accuracy: 0.0000e+00 - val_loss: 4.6136 - val_accuracy: 0.0000e+00\n",
      "Epoch 128/500\n",
      "3/3 [==============================] - 0s 37ms/step - loss: 4.6090 - accuracy: 0.0000e+00 - val_loss: 4.6136 - val_accuracy: 0.0000e+00\n",
      "Epoch 129/500\n",
      "3/3 [==============================] - 0s 38ms/step - loss: 4.6090 - accuracy: 0.0000e+00 - val_loss: 4.6136 - val_accuracy: 0.0000e+00\n",
      "Epoch 130/500\n",
      "3/3 [==============================] - 0s 38ms/step - loss: 4.6090 - accuracy: 0.0000e+00 - val_loss: 4.6136 - val_accuracy: 0.0000e+00\n",
      "Epoch 131/500\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 4.6090 - accuracy: 0.0000e+00 - val_loss: 4.6136 - val_accuracy: 0.0000e+00\n",
      "Epoch 132/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 4.6090 - accuracy: 0.0000e+00 - val_loss: 4.6136 - val_accuracy: 0.0000e+00\n",
      "Epoch 133/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 4.6090 - accuracy: 0.0000e+00 - val_loss: 4.6136 - val_accuracy: 0.0000e+00\n",
      "Epoch 134/500\n",
      "3/3 [==============================] - 0s 37ms/step - loss: 4.6090 - accuracy: 0.0000e+00 - val_loss: 4.6136 - val_accuracy: 0.0000e+00\n",
      "Epoch 135/500\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 4.6090 - accuracy: 0.0000e+00 - val_loss: 4.6136 - val_accuracy: 0.0000e+00\n",
      "Epoch 136/500\n",
      "3/3 [==============================] - 0s 37ms/step - loss: 4.6090 - accuracy: 0.0000e+00 - val_loss: 4.6136 - val_accuracy: 0.0000e+00\n",
      "Epoch 137/500\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 4.6090 - accuracy: 0.0000e+00 - val_loss: 4.6136 - val_accuracy: 0.0000e+00\n",
      "Epoch 138/500\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 4.6090 - accuracy: 0.0000e+00 - val_loss: 4.6136 - val_accuracy: 0.0000e+00\n",
      "Epoch 139/500\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 4.6090 - accuracy: 0.0000e+00 - val_loss: 4.6136 - val_accuracy: 0.0000e+00\n",
      "Epoch 140/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 4.6090 - accuracy: 0.0000e+00 - val_loss: 4.6136 - val_accuracy: 0.0000e+00\n",
      "Epoch 141/500\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 4.6090 - accuracy: 0.0000e+00 - val_loss: 4.6136 - val_accuracy: 0.0000e+00\n",
      "Epoch 142/500\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 4.6090 - accuracy: 0.0000e+00 - val_loss: 4.6136 - val_accuracy: 0.0000e+00\n",
      "Epoch 143/500\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 4.6090 - accuracy: 0.0000e+00 - val_loss: 4.6136 - val_accuracy: 0.0000e+00\n",
      "Epoch 144/500\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 4.6090 - accuracy: 0.0000e+00 - val_loss: 4.6136 - val_accuracy: 0.0000e+00\n",
      "Epoch 145/500\n",
      "3/3 [==============================] - 0s 37ms/step - loss: 4.6090 - accuracy: 0.0000e+00 - val_loss: 4.6136 - val_accuracy: 0.0000e+00\n",
      "Epoch 146/500\n",
      "3/3 [==============================] - 0s 38ms/step - loss: 4.6090 - accuracy: 0.0000e+00 - val_loss: 4.6136 - val_accuracy: 0.0000e+00\n",
      "Epoch 147/500\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 4.6090 - accuracy: 0.0000e+00 - val_loss: 4.6136 - val_accuracy: 0.0000e+00\n",
      "Epoch 148/500\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 4.6090 - accuracy: 0.0000e+00 - val_loss: 4.6136 - val_accuracy: 0.0000e+00\n",
      "Epoch 149/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 4.6090 - accuracy: 0.0000e+00 - val_loss: 4.6136 - val_accuracy: 0.0000e+00\n",
      "Epoch 150/500\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 4.6090 - accuracy: 0.0000e+00 - val_loss: 4.6136 - val_accuracy: 0.0000e+00\n",
      "Epoch 151/500\n",
      "3/3 [==============================] - 0s 37ms/step - loss: 4.6090 - accuracy: 0.0000e+00 - val_loss: 4.6136 - val_accuracy: 0.0000e+00\n",
      "Epoch 152/500\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 4.6090 - accuracy: 0.0000e+00 - val_loss: 4.6136 - val_accuracy: 0.0000e+00\n",
      "Epoch 153/500\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 4.6090 - accuracy: 0.0000e+00 - val_loss: 4.6136 - val_accuracy: 0.0000e+00\n",
      "Epoch 154/500\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 4.6090 - accuracy: 0.0000e+00 - val_loss: 4.6136 - val_accuracy: 0.0000e+00\n",
      "Epoch 155/500\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 4.6090 - accuracy: 0.0000e+00 - val_loss: 4.6136 - val_accuracy: 0.0000e+00\n",
      "Epoch 156/500\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 4.6090 - accuracy: 0.0000e+00 - val_loss: 4.6136 - val_accuracy: 0.0000e+00\n",
      "Epoch 157/500\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 4.6090 - accuracy: 0.0000e+00 - val_loss: 4.6136 - val_accuracy: 0.0000e+00\n",
      "Epoch 158/500\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 4.6090 - accuracy: 0.0000e+00 - val_loss: 4.6136 - val_accuracy: 0.0000e+00\n",
      "Epoch 159/500\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 4.6090 - accuracy: 0.0000e+00 - val_loss: 4.6136 - val_accuracy: 0.0000e+00\n",
      "Epoch 160/500\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 4.6090 - accuracy: 0.0000e+00 - val_loss: 4.6136 - val_accuracy: 0.0000e+00\n",
      "Epoch 161/500\n",
      "3/3 [==============================] - 0s 40ms/step - loss: 4.6090 - accuracy: 0.0000e+00 - val_loss: 4.6136 - val_accuracy: 0.0000e+00\n",
      "Epoch 162/500\n",
      "3/3 [==============================] - 0s 39ms/step - loss: 4.6090 - accuracy: 0.0000e+00 - val_loss: 4.6136 - val_accuracy: 0.0000e+00\n",
      "Epoch 163/500\n",
      "3/3 [==============================] - 0s 54ms/step - loss: 4.6090 - accuracy: 0.0000e+00 - val_loss: 4.6136 - val_accuracy: 0.0000e+00\n",
      "Epoch 164/500\n",
      "3/3 [==============================] - 0s 37ms/step - loss: 4.6090 - accuracy: 0.0000e+00 - val_loss: 4.6136 - val_accuracy: 0.0000e+00\n",
      "Epoch 165/500\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 4.6090 - accuracy: 0.0000e+00 - val_loss: 4.6136 - val_accuracy: 0.0000e+00\n",
      "Epoch 166/500\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 4.6090 - accuracy: 0.0000e+00 - val_loss: 4.6136 - val_accuracy: 0.0000e+00\n",
      "Epoch 167/500\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 4.6090 - accuracy: 0.0000e+00 - val_loss: 4.6136 - val_accuracy: 0.0000e+00\n",
      "Epoch 168/500\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 4.6090 - accuracy: 0.0000e+00 - val_loss: 4.6136 - val_accuracy: 0.0000e+00\n",
      "Epoch 169/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 4.6090 - accuracy: 0.0000e+00 - val_loss: 4.6136 - val_accuracy: 0.0000e+00\n",
      "Epoch 170/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 4.6090 - accuracy: 0.0000e+00 - val_loss: 4.6136 - val_accuracy: 0.0000e+00\n",
      "Epoch 171/500\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 4.6090 - accuracy: 0.0000e+00 - val_loss: 4.6136 - val_accuracy: 0.0000e+00\n",
      "Epoch 172/500\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 4.6090 - accuracy: 0.0000e+00 - val_loss: 4.6136 - val_accuracy: 0.0000e+00\n",
      "Epoch 173/500\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 4.6090 - accuracy: 0.0000e+00 - val_loss: 4.6136 - val_accuracy: 0.0000e+00\n",
      "Epoch 174/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 4.6090 - accuracy: 0.0000e+00 - val_loss: 4.6136 - val_accuracy: 0.0000e+00\n",
      "Epoch 175/500\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 4.6090 - accuracy: 0.0000e+00 - val_loss: 4.6136 - val_accuracy: 0.0000e+00\n",
      "Epoch 176/500\n",
      "3/3 [==============================] - 0s 38ms/step - loss: 4.6090 - accuracy: 0.0000e+00 - val_loss: 4.6136 - val_accuracy: 0.0000e+00\n",
      "Epoch 177/500\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 4.6090 - accuracy: 0.0000e+00 - val_loss: 4.6136 - val_accuracy: 0.0000e+00\n",
      "Epoch 178/500\n",
      "3/3 [==============================] - 0s 38ms/step - loss: 4.6090 - accuracy: 0.0000e+00 - val_loss: 4.6136 - val_accuracy: 0.0000e+00\n",
      "Epoch 179/500\n",
      "3/3 [==============================] - 0s 40ms/step - loss: 4.6090 - accuracy: 0.0000e+00 - val_loss: 4.6136 - val_accuracy: 0.0000e+00\n",
      "Epoch 180/500\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 4.6090 - accuracy: 0.0000e+00 - val_loss: 4.6136 - val_accuracy: 0.0000e+00\n",
      "Epoch 181/500\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 4.6090 - accuracy: 0.0000e+00 - val_loss: 4.6136 - val_accuracy: 0.0000e+00\n",
      "Epoch 182/500\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 4.6090 - accuracy: 0.0000e+00 - val_loss: 4.6136 - val_accuracy: 0.0000e+00\n",
      "Epoch 183/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 4.6090 - accuracy: 0.0000e+00 - val_loss: 4.6136 - val_accuracy: 0.0000e+00\n",
      "Epoch 184/500\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 4.6090 - accuracy: 0.0000e+00 - val_loss: 4.6136 - val_accuracy: 0.0000e+00\n",
      "Epoch 185/500\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 4.6090 - accuracy: 0.0000e+00 - val_loss: 4.6136 - val_accuracy: 0.0000e+00\n",
      "Epoch 186/500\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 4.6090 - accuracy: 0.0000e+00 - val_loss: 4.6136 - val_accuracy: 0.0000e+00\n",
      "Epoch 187/500\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 4.6090 - accuracy: 0.0000e+00 - val_loss: 4.6136 - val_accuracy: 0.0000e+00\n",
      "Epoch 188/500\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 4.6090 - accuracy: 0.0000e+00 - val_loss: 4.6136 - val_accuracy: 0.0000e+00\n",
      "Epoch 189/500\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 4.6090 - accuracy: 0.0000e+00 - val_loss: 4.6136 - val_accuracy: 0.0000e+00\n",
      "Epoch 190/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 4.6090 - accuracy: 0.0000e+00 - val_loss: 4.6136 - val_accuracy: 0.0000e+00\n",
      "Epoch 191/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 4.6090 - accuracy: 0.0000e+00 - val_loss: 4.6136 - val_accuracy: 0.0000e+00\n",
      "Epoch 192/500\n",
      "3/3 [==============================] - 0s 40ms/step - loss: 4.6090 - accuracy: 0.0000e+00 - val_loss: 4.6136 - val_accuracy: 0.0000e+00\n",
      "Epoch 193/500\n",
      "3/3 [==============================] - 0s 37ms/step - loss: 4.6090 - accuracy: 0.0000e+00 - val_loss: 4.6136 - val_accuracy: 0.0000e+00\n",
      "Epoch 194/500\n",
      "3/3 [==============================] - 0s 37ms/step - loss: 4.6090 - accuracy: 0.0000e+00 - val_loss: 4.6136 - val_accuracy: 0.0000e+00\n",
      "Epoch 195/500\n",
      "3/3 [==============================] - 0s 54ms/step - loss: 4.6090 - accuracy: 0.0000e+00 - val_loss: 4.6136 - val_accuracy: 0.0000e+00\n",
      "Epoch 196/500\n",
      "3/3 [==============================] - 0s 40ms/step - loss: 4.6090 - accuracy: 0.0000e+00 - val_loss: 4.6136 - val_accuracy: 0.0000e+00\n",
      "Epoch 197/500\n",
      "3/3 [==============================] - 0s 39ms/step - loss: 4.6090 - accuracy: 0.0000e+00 - val_loss: 4.6136 - val_accuracy: 0.0000e+00\n",
      "Epoch 198/500\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 4.6090 - accuracy: 0.0000e+00 - val_loss: 4.6136 - val_accuracy: 0.0000e+00\n",
      "Epoch 199/500\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 4.6090 - accuracy: 0.0000e+00 - val_loss: 4.6136 - val_accuracy: 0.0000e+00\n",
      "Epoch 200/500\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 4.6090 - accuracy: 0.0000e+00 - val_loss: 4.6136 - val_accuracy: 0.0000e+00\n",
      "Epoch 201/500\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 4.6090 - accuracy: 0.0000e+00 - val_loss: 4.6136 - val_accuracy: 0.0000e+00\n",
      "Epoch 202/500\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 4.6090 - accuracy: 0.0000e+00 - val_loss: 4.6136 - val_accuracy: 0.0000e+00\n",
      "Epoch 203/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 4.6090 - accuracy: 0.0000e+00 - val_loss: 4.6136 - val_accuracy: 0.0000e+00\n",
      "Epoch 204/500\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 4.6090 - accuracy: 0.0000e+00 - val_loss: 4.6136 - val_accuracy: 0.0000e+00\n",
      "Epoch 205/500\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 4.6090 - accuracy: 0.0000e+00 - val_loss: 4.6136 - val_accuracy: 0.0000e+00\n",
      "Epoch 206/500\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 4.6090 - accuracy: 0.0000e+00 - val_loss: 4.6136 - val_accuracy: 0.0000e+00\n",
      "Epoch 207/500\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 4.6090 - accuracy: 0.0000e+00 - val_loss: 4.6136 - val_accuracy: 0.0000e+00\n",
      "Epoch 208/500\n",
      "3/3 [==============================] - 0s 39ms/step - loss: 4.6090 - accuracy: 0.0000e+00 - val_loss: 4.6136 - val_accuracy: 0.0000e+00\n",
      "Epoch 209/500\n",
      "3/3 [==============================] - 0s 39ms/step - loss: 4.6090 - accuracy: 0.0000e+00 - val_loss: 4.6136 - val_accuracy: 0.0000e+00\n",
      "Epoch 210/500\n",
      "3/3 [==============================] - 0s 37ms/step - loss: 4.6090 - accuracy: 0.0000e+00 - val_loss: 4.6136 - val_accuracy: 0.0000e+00\n",
      "Epoch 211/500\n",
      "3/3 [==============================] - 0s 40ms/step - loss: 4.6090 - accuracy: 0.0000e+00 - val_loss: 4.6136 - val_accuracy: 0.0000e+00\n",
      "Epoch 212/500\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 4.6090 - accuracy: 0.0000e+00 - val_loss: 4.6136 - val_accuracy: 0.0000e+00\n",
      "Epoch 213/500\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 4.6090 - accuracy: 0.0000e+00 - val_loss: 4.6136 - val_accuracy: 0.0000e+00\n",
      "Epoch 214/500\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 4.6090 - accuracy: 0.0000e+00 - val_loss: 4.6136 - val_accuracy: 0.0000e+00\n",
      "Epoch 215/500\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 4.6090 - accuracy: 0.0000e+00 - val_loss: 4.6136 - val_accuracy: 0.0000e+00\n",
      "Epoch 216/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 4.6090 - accuracy: 0.0000e+00 - val_loss: 4.6136 - val_accuracy: 0.0000e+00\n",
      "Epoch 217/500\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 4.6090 - accuracy: 0.0000e+00 - val_loss: 4.6136 - val_accuracy: 0.0000e+00\n",
      "Epoch 218/500\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 4.6090 - accuracy: 0.0000e+00 - val_loss: 4.6136 - val_accuracy: 0.0000e+00\n",
      "Epoch 219/500\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 4.6090 - accuracy: 0.0000e+00 - val_loss: 4.6136 - val_accuracy: 0.0000e+00\n",
      "Epoch 220/500\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 4.6090 - accuracy: 0.0000e+00 - val_loss: 4.6136 - val_accuracy: 0.0000e+00\n",
      "Epoch 221/500\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 4.6090 - accuracy: 0.0000e+00 - val_loss: 4.6136 - val_accuracy: 0.0000e+00\n",
      "Epoch 222/500\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 4.6090 - accuracy: 0.0000e+00 - val_loss: 4.6136 - val_accuracy: 0.0000e+00\n",
      "Epoch 223/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 4.6090 - accuracy: 0.0000e+00 - val_loss: 4.6136 - val_accuracy: 0.0000e+00\n",
      "Epoch 224/500\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 4.6090 - accuracy: 0.0000e+00 - val_loss: 4.6136 - val_accuracy: 0.0000e+00\n",
      "Epoch 225/500\n",
      "3/3 [==============================] - 0s 39ms/step - loss: 4.6090 - accuracy: 0.0000e+00 - val_loss: 4.6136 - val_accuracy: 0.0000e+00\n",
      "Epoch 226/500\n",
      "3/3 [==============================] - 0s 38ms/step - loss: 4.6090 - accuracy: 0.0000e+00 - val_loss: 4.6136 - val_accuracy: 0.0000e+00\n",
      "Epoch 227/500\n",
      "3/3 [==============================] - 0s 38ms/step - loss: 4.6090 - accuracy: 0.0000e+00 - val_loss: 4.6136 - val_accuracy: 0.0000e+00\n",
      "Epoch 228/500\n",
      "3/3 [==============================] - 0s 38ms/step - loss: 4.6090 - accuracy: 0.0000e+00 - val_loss: 4.6136 - val_accuracy: 0.0000e+00\n",
      "Epoch 229/500\n",
      "3/3 [==============================] - 0s 39ms/step - loss: 4.6090 - accuracy: 0.0000e+00 - val_loss: 4.6136 - val_accuracy: 0.0000e+00\n",
      "Epoch 230/500\n",
      "3/3 [==============================] - 0s 40ms/step - loss: 4.6090 - accuracy: 0.0000e+00 - val_loss: 4.6136 - val_accuracy: 0.0000e+00\n",
      "Epoch 231/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 4.6090 - accuracy: 0.0000e+00 - val_loss: 4.6136 - val_accuracy: 0.0000e+00\n",
      "Epoch 232/500\n",
      "3/3 [==============================] - 0s 38ms/step - loss: 4.6090 - accuracy: 0.0000e+00 - val_loss: 4.6136 - val_accuracy: 0.0000e+00\n",
      "Epoch 233/500\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 4.6090 - accuracy: 0.0000e+00 - val_loss: 4.6136 - val_accuracy: 0.0000e+00\n",
      "Epoch 234/500\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 4.6090 - accuracy: 0.0000e+00 - val_loss: 4.6136 - val_accuracy: 0.0000e+00\n",
      "Epoch 235/500\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 4.6090 - accuracy: 0.0000e+00 - val_loss: 4.6136 - val_accuracy: 0.0000e+00\n",
      "Epoch 236/500\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 4.6090 - accuracy: 0.0000e+00 - val_loss: 4.6136 - val_accuracy: 0.0000e+00\n",
      "Epoch 237/500\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 4.6090 - accuracy: 0.0000e+00 - val_loss: 4.6136 - val_accuracy: 0.0000e+00\n",
      "Epoch 238/500\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 4.6090 - accuracy: 0.0000e+00 - val_loss: 4.6136 - val_accuracy: 0.0000e+00\n",
      "Epoch 239/500\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 4.6090 - accuracy: 0.0000e+00 - val_loss: 4.6136 - val_accuracy: 0.0000e+00\n",
      "Epoch 240/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 4.6090 - accuracy: 0.0000e+00 - val_loss: 4.6136 - val_accuracy: 0.0000e+00\n",
      "Epoch 241/500\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 4.6090 - accuracy: 0.0000e+00 - val_loss: 4.6136 - val_accuracy: 0.0000e+00\n",
      "Epoch 242/500\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 4.6090 - accuracy: 0.0000e+00 - val_loss: 4.6136 - val_accuracy: 0.0000e+00\n",
      "Epoch 243/500\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 4.6090 - accuracy: 0.0000e+00 - val_loss: 4.6136 - val_accuracy: 0.0000e+00\n",
      "Epoch 244/500\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 4.6090 - accuracy: 0.0000e+00 - val_loss: 4.6136 - val_accuracy: 0.0000e+00\n",
      "Epoch 245/500\n",
      "3/3 [==============================] - 0s 40ms/step - loss: 4.6090 - accuracy: 0.0000e+00 - val_loss: 4.6136 - val_accuracy: 0.0000e+00\n",
      "Epoch 246/500\n",
      "3/3 [==============================] - 0s 38ms/step - loss: 4.6090 - accuracy: 0.0000e+00 - val_loss: 4.6136 - val_accuracy: 0.0000e+00\n",
      "Epoch 247/500\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 4.6090 - accuracy: 0.0000e+00 - val_loss: 4.6136 - val_accuracy: 0.0000e+00\n",
      "Epoch 248/500\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 4.6090 - accuracy: 0.0000e+00 - val_loss: 4.6136 - val_accuracy: 0.0000e+00\n",
      "Epoch 249/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 4.6090 - accuracy: 0.0000e+00 - val_loss: 4.6136 - val_accuracy: 0.0000e+00\n",
      "Epoch 250/500\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 4.6090 - accuracy: 0.0000e+00 - val_loss: 4.6136 - val_accuracy: 0.0000e+00\n",
      "Epoch 251/500\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 4.6090 - accuracy: 0.0000e+00 - val_loss: 4.6136 - val_accuracy: 0.0000e+00\n",
      "Epoch 252/500\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 4.6090 - accuracy: 0.0000e+00 - val_loss: 4.6136 - val_accuracy: 0.0000e+00\n",
      "Epoch 253/500\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 4.6090 - accuracy: 0.0000e+00 - val_loss: 4.6136 - val_accuracy: 0.0000e+00\n",
      "Epoch 254/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 4.6090 - accuracy: 0.0000e+00 - val_loss: 4.6136 - val_accuracy: 0.0000e+00\n",
      "Epoch 255/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 4.6090 - accuracy: 0.0000e+00 - val_loss: 4.6136 - val_accuracy: 0.0000e+00\n",
      "Epoch 256/500\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 4.6090 - accuracy: 0.0000e+00 - val_loss: 4.6136 - val_accuracy: 0.0000e+00\n",
      "Epoch 257/500\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 4.6090 - accuracy: 0.0000e+00 - val_loss: 4.6136 - val_accuracy: 0.0000e+00\n",
      "Epoch 258/500\n",
      "3/3 [==============================] - 0s 37ms/step - loss: 4.6090 - accuracy: 0.0000e+00 - val_loss: 4.6136 - val_accuracy: 0.0000e+00\n",
      "Epoch 259/500\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 4.6090 - accuracy: 0.0000e+00 - val_loss: 4.6136 - val_accuracy: 0.0000e+00\n",
      "Epoch 260/500\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 4.6090 - accuracy: 0.0000e+00 - val_loss: 4.6136 - val_accuracy: 0.0000e+00\n",
      "Epoch 261/500\n",
      "3/3 [==============================] - 0s 37ms/step - loss: 4.6090 - accuracy: 0.0000e+00 - val_loss: 4.6136 - val_accuracy: 0.0000e+00\n",
      "Epoch 262/500\n",
      "3/3 [==============================] - 0s 74ms/step - loss: 4.6090 - accuracy: 0.0000e+00 - val_loss: 4.6136 - val_accuracy: 0.0000e+00\n",
      "Epoch 263/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 4.6090 - accuracy: 0.0000e+00 - val_loss: 4.6136 - val_accuracy: 0.0000e+00\n",
      "Epoch 264/500\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 4.6090 - accuracy: 0.0000e+00 - val_loss: 4.6136 - val_accuracy: 0.0000e+00\n",
      "Epoch 265/500\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 4.6090 - accuracy: 0.0000e+00 - val_loss: 4.6136 - val_accuracy: 0.0000e+00\n",
      "Epoch 266/500\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 4.6090 - accuracy: 0.0000e+00 - val_loss: 4.6136 - val_accuracy: 0.0000e+00\n",
      "Epoch 267/500\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 4.6090 - accuracy: 0.0000e+00 - val_loss: 4.6136 - val_accuracy: 0.0000e+00\n",
      "Epoch 268/500\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 4.6090 - accuracy: 0.0000e+00 - val_loss: 4.6136 - val_accuracy: 0.0000e+00\n",
      "Epoch 269/500\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 4.6090 - accuracy: 0.0000e+00 - val_loss: 4.6136 - val_accuracy: 0.0000e+00\n",
      "Epoch 270/500\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 4.6090 - accuracy: 0.0000e+00 - val_loss: 4.6136 - val_accuracy: 0.0000e+00\n",
      "Epoch 271/500\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 4.6090 - accuracy: 0.0000e+00 - val_loss: 4.6136 - val_accuracy: 0.0000e+00\n",
      "Epoch 272/500\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 4.6090 - accuracy: 0.0000e+00 - val_loss: 4.6136 - val_accuracy: 0.0000e+00\n",
      "Epoch 273/500\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 4.6090 - accuracy: 0.0000e+00 - val_loss: 4.6136 - val_accuracy: 0.0000e+00\n",
      "Epoch 274/500\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 4.6090 - accuracy: 0.0000e+00 - val_loss: 4.6136 - val_accuracy: 0.0000e+00\n",
      "Epoch 275/500\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 4.6090 - accuracy: 0.0000e+00 - val_loss: 4.6136 - val_accuracy: 0.0000e+00\n",
      "Epoch 276/500\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 4.6090 - accuracy: 0.0000e+00 - val_loss: 4.6136 - val_accuracy: 0.0000e+00\n",
      "Epoch 277/500\n",
      "3/3 [==============================] - 0s 37ms/step - loss: 4.6090 - accuracy: 0.0000e+00 - val_loss: 4.6136 - val_accuracy: 0.0000e+00\n",
      "Epoch 278/500\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 4.6090 - accuracy: 0.0000e+00 - val_loss: 4.6136 - val_accuracy: 0.0000e+00\n",
      "Epoch 279/500\n",
      "3/3 [==============================] - 0s 37ms/step - loss: 4.6090 - accuracy: 0.0000e+00 - val_loss: 4.6136 - val_accuracy: 0.0000e+00\n",
      "Epoch 280/500\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 4.6090 - accuracy: 0.0000e+00 - val_loss: 4.6136 - val_accuracy: 0.0000e+00\n",
      "Epoch 281/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 4.6090 - accuracy: 0.0000e+00 - val_loss: 4.6136 - val_accuracy: 0.0000e+00\n",
      "Epoch 282/500\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 4.6090 - accuracy: 0.0000e+00 - val_loss: 4.6136 - val_accuracy: 0.0000e+00\n",
      "Epoch 283/500\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 4.6090 - accuracy: 0.0000e+00 - val_loss: 4.6136 - val_accuracy: 0.0000e+00\n",
      "Epoch 284/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 4.6090 - accuracy: 0.0000e+00 - val_loss: 4.6136 - val_accuracy: 0.0000e+00\n",
      "Epoch 285/500\n",
      "3/3 [==============================] - 0s 38ms/step - loss: 4.6090 - accuracy: 0.0000e+00 - val_loss: 4.6136 - val_accuracy: 0.0000e+00\n",
      "Epoch 286/500\n",
      "3/3 [==============================] - 0s 37ms/step - loss: 4.6090 - accuracy: 0.0000e+00 - val_loss: 4.6136 - val_accuracy: 0.0000e+00\n",
      "Epoch 287/500\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 4.6090 - accuracy: 0.0000e+00 - val_loss: 4.6136 - val_accuracy: 0.0000e+00\n",
      "Epoch 288/500\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 4.6090 - accuracy: 0.0000e+00 - val_loss: 4.6136 - val_accuracy: 0.0000e+00\n",
      "Epoch 289/500\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 4.6090 - accuracy: 0.0000e+00 - val_loss: 4.6136 - val_accuracy: 0.0000e+00\n",
      "Epoch 290/500\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 4.6090 - accuracy: 0.0000e+00 - val_loss: 4.6136 - val_accuracy: 0.0000e+00\n",
      "Epoch 291/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 4.6090 - accuracy: 0.0000e+00 - val_loss: 4.6136 - val_accuracy: 0.0000e+00\n",
      "Epoch 292/500\n",
      "3/3 [==============================] - 0s 40ms/step - loss: 4.6090 - accuracy: 0.0000e+00 - val_loss: 4.6136 - val_accuracy: 0.0000e+00\n",
      "Epoch 293/500\n",
      "3/3 [==============================] - 0s 40ms/step - loss: 4.6090 - accuracy: 0.0000e+00 - val_loss: 4.6136 - val_accuracy: 0.0000e+00\n",
      "Epoch 294/500\n",
      "3/3 [==============================] - 0s 37ms/step - loss: 4.6090 - accuracy: 0.0000e+00 - val_loss: 4.6136 - val_accuracy: 0.0000e+00\n",
      "Epoch 295/500\n",
      "3/3 [==============================] - 0s 49ms/step - loss: 4.6090 - accuracy: 0.0000e+00 - val_loss: 4.6136 - val_accuracy: 0.0000e+00\n",
      "Epoch 296/500\n",
      "3/3 [==============================] - 0s 39ms/step - loss: 4.6090 - accuracy: 0.0000e+00 - val_loss: 4.6136 - val_accuracy: 0.0000e+00\n",
      "Epoch 297/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 4.6090 - accuracy: 0.0000e+00 - val_loss: 4.6136 - val_accuracy: 0.0000e+00\n",
      "Epoch 298/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 4.6090 - accuracy: 0.0000e+00 - val_loss: 4.6136 - val_accuracy: 0.0000e+00\n",
      "Epoch 299/500\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 4.6090 - accuracy: 0.0000e+00 - val_loss: 4.6136 - val_accuracy: 0.0000e+00\n",
      "Epoch 300/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 4.6090 - accuracy: 0.0000e+00 - val_loss: 4.6136 - val_accuracy: 0.0000e+00\n",
      "Epoch 301/500\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 4.6090 - accuracy: 0.0000e+00 - val_loss: 4.6136 - val_accuracy: 0.0000e+00\n",
      "Epoch 302/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 4.6090 - accuracy: 0.0000e+00 - val_loss: 4.6136 - val_accuracy: 0.0000e+00\n",
      "Epoch 303/500\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 4.6090 - accuracy: 0.0000e+00 - val_loss: 4.6136 - val_accuracy: 0.0000e+00\n",
      "Epoch 304/500\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 4.6090 - accuracy: 0.0000e+00 - val_loss: 4.6136 - val_accuracy: 0.0000e+00\n",
      "Epoch 305/500\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 4.6090 - accuracy: 0.0000e+00 - val_loss: 4.6136 - val_accuracy: 0.0000e+00\n",
      "Epoch 306/500\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 4.6090 - accuracy: 0.0000e+00 - val_loss: 4.6136 - val_accuracy: 0.0000e+00\n",
      "Epoch 307/500\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 4.6090 - accuracy: 0.0000e+00 - val_loss: 4.6136 - val_accuracy: 0.0000e+00\n",
      "Epoch 308/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 4.6090 - accuracy: 0.0000e+00 - val_loss: 4.6136 - val_accuracy: 0.0000e+00\n",
      "Epoch 309/500\n",
      "3/3 [==============================] - 0s 40ms/step - loss: 4.6090 - accuracy: 0.0000e+00 - val_loss: 4.6136 - val_accuracy: 0.0000e+00\n",
      "Epoch 310/500\n",
      "3/3 [==============================] - 0s 38ms/step - loss: 4.6090 - accuracy: 0.0000e+00 - val_loss: 4.6136 - val_accuracy: 0.0000e+00\n",
      "Epoch 311/500\n",
      "3/3 [==============================] - 0s 37ms/step - loss: 4.6090 - accuracy: 0.0000e+00 - val_loss: 4.6136 - val_accuracy: 0.0000e+00\n",
      "Epoch 312/500\n",
      "3/3 [==============================] - 0s 40ms/step - loss: 4.6090 - accuracy: 0.0000e+00 - val_loss: 4.6136 - val_accuracy: 0.0000e+00\n",
      "Epoch 313/500\n",
      "3/3 [==============================] - 0s 38ms/step - loss: 4.6090 - accuracy: 0.0000e+00 - val_loss: 4.6136 - val_accuracy: 0.0000e+00\n",
      "Epoch 314/500\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 4.6090 - accuracy: 0.0000e+00 - val_loss: 4.6136 - val_accuracy: 0.0000e+00\n",
      "Epoch 315/500\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 4.6090 - accuracy: 0.0000e+00 - val_loss: 4.6136 - val_accuracy: 0.0000e+00\n",
      "Epoch 316/500\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 4.6090 - accuracy: 0.0000e+00 - val_loss: 4.6136 - val_accuracy: 0.0000e+00\n",
      "Epoch 317/500\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 4.6090 - accuracy: 0.0000e+00 - val_loss: 4.6136 - val_accuracy: 0.0000e+00\n",
      "Epoch 318/500\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 4.6090 - accuracy: 0.0000e+00 - val_loss: 4.6136 - val_accuracy: 0.0000e+00\n",
      "Epoch 319/500\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 4.6090 - accuracy: 0.0000e+00 - val_loss: 4.6136 - val_accuracy: 0.0000e+00\n",
      "Epoch 320/500\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 4.6090 - accuracy: 0.0000e+00 - val_loss: 4.6136 - val_accuracy: 0.0000e+00\n",
      "Epoch 321/500\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 4.6090 - accuracy: 0.0000e+00 - val_loss: 4.6136 - val_accuracy: 0.0000e+00\n",
      "Epoch 322/500\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 4.6090 - accuracy: 0.0000e+00 - val_loss: 4.6136 - val_accuracy: 0.0000e+00\n",
      "Epoch 323/500\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 4.6090 - accuracy: 0.0000e+00 - val_loss: 4.6136 - val_accuracy: 0.0000e+00\n",
      "Epoch 324/500\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 4.6090 - accuracy: 0.0000e+00 - val_loss: 4.6136 - val_accuracy: 0.0000e+00\n",
      "Epoch 325/500\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 4.6090 - accuracy: 0.0000e+00 - val_loss: 4.6136 - val_accuracy: 0.0000e+00\n",
      "Epoch 326/500\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 4.6090 - accuracy: 0.0000e+00 - val_loss: 4.6136 - val_accuracy: 0.0000e+00\n",
      "Epoch 327/500\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 4.6090 - accuracy: 0.0000e+00 - val_loss: 4.6136 - val_accuracy: 0.0000e+00\n",
      "Epoch 328/500\n",
      "3/3 [==============================] - 0s 39ms/step - loss: 4.6090 - accuracy: 0.0000e+00 - val_loss: 4.6136 - val_accuracy: 0.0000e+00\n",
      "Epoch 329/500\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 4.6090 - accuracy: 0.0000e+00 - val_loss: 4.6136 - val_accuracy: 0.0000e+00\n",
      "Epoch 330/500\n",
      "3/3 [==============================] - 0s 52ms/step - loss: 4.6090 - accuracy: 0.0000e+00 - val_loss: 4.6136 - val_accuracy: 0.0000e+00\n",
      "Epoch 331/500\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 4.6090 - accuracy: 0.0000e+00 - val_loss: 4.6136 - val_accuracy: 0.0000e+00\n",
      "Epoch 332/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 4.6090 - accuracy: 0.0000e+00 - val_loss: 4.6136 - val_accuracy: 0.0000e+00\n",
      "Epoch 333/500\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 4.6090 - accuracy: 0.0000e+00 - val_loss: 4.6136 - val_accuracy: 0.0000e+00\n",
      "Epoch 334/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 4.6090 - accuracy: 0.0000e+00 - val_loss: 4.6136 - val_accuracy: 0.0000e+00\n",
      "Epoch 335/500\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 4.6090 - accuracy: 0.0000e+00 - val_loss: 4.6136 - val_accuracy: 0.0000e+00\n",
      "Epoch 336/500\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 4.6090 - accuracy: 0.0000e+00 - val_loss: 4.6136 - val_accuracy: 0.0000e+00\n",
      "Epoch 337/500\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 4.6090 - accuracy: 0.0000e+00 - val_loss: 4.6136 - val_accuracy: 0.0000e+00\n",
      "Epoch 338/500\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 4.6090 - accuracy: 0.0000e+00 - val_loss: 4.6136 - val_accuracy: 0.0000e+00\n",
      "Epoch 339/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 4.6090 - accuracy: 0.0000e+00 - val_loss: 4.6136 - val_accuracy: 0.0000e+00\n",
      "Epoch 340/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 4.6090 - accuracy: 0.0000e+00 - val_loss: 4.6136 - val_accuracy: 0.0000e+00\n",
      "Epoch 341/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 4.6090 - accuracy: 0.0000e+00 - val_loss: 4.6136 - val_accuracy: 0.0000e+00\n",
      "Epoch 342/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 4.6090 - accuracy: 0.0000e+00 - val_loss: 4.6136 - val_accuracy: 0.0000e+00\n",
      "Epoch 343/500\n",
      "3/3 [==============================] - 0s 37ms/step - loss: 4.6090 - accuracy: 0.0000e+00 - val_loss: 4.6136 - val_accuracy: 0.0000e+00\n",
      "Epoch 344/500\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 4.6090 - accuracy: 0.0000e+00 - val_loss: 4.6136 - val_accuracy: 0.0000e+00\n",
      "Epoch 345/500\n",
      "3/3 [==============================] - 0s 39ms/step - loss: 4.6090 - accuracy: 0.0000e+00 - val_loss: 4.6136 - val_accuracy: 0.0000e+00\n",
      "Epoch 346/500\n",
      "3/3 [==============================] - 0s 39ms/step - loss: 4.6090 - accuracy: 0.0000e+00 - val_loss: 4.6136 - val_accuracy: 0.0000e+00\n",
      "Epoch 347/500\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 4.6090 - accuracy: 0.0000e+00 - val_loss: 4.6136 - val_accuracy: 0.0000e+00\n",
      "Epoch 348/500\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 4.6090 - accuracy: 0.0000e+00 - val_loss: 4.6136 - val_accuracy: 0.0000e+00\n",
      "Epoch 349/500\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 4.6090 - accuracy: 0.0000e+00 - val_loss: 4.6136 - val_accuracy: 0.0000e+00\n",
      "Epoch 350/500\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 4.6090 - accuracy: 0.0000e+00 - val_loss: 4.6136 - val_accuracy: 0.0000e+00\n",
      "Epoch 351/500\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 4.6090 - accuracy: 0.0000e+00 - val_loss: 4.6136 - val_accuracy: 0.0000e+00\n",
      "Epoch 352/500\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 4.6090 - accuracy: 0.0000e+00 - val_loss: 4.6136 - val_accuracy: 0.0000e+00\n",
      "Epoch 353/500\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 4.6090 - accuracy: 0.0000e+00 - val_loss: 4.6136 - val_accuracy: 0.0000e+00\n",
      "Epoch 354/500\n",
      "3/3 [==============================] - 0s 51ms/step - loss: 4.6090 - accuracy: 0.0000e+00 - val_loss: 4.6136 - val_accuracy: 0.0000e+00\n",
      "Epoch 355/500\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 4.6090 - accuracy: 0.0000e+00 - val_loss: 4.6136 - val_accuracy: 0.0000e+00\n",
      "Epoch 356/500\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 4.6090 - accuracy: 0.0000e+00 - val_loss: 4.6136 - val_accuracy: 0.0000e+00\n",
      "Epoch 357/500\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 4.6090 - accuracy: 0.0000e+00 - val_loss: 4.6136 - val_accuracy: 0.0000e+00\n",
      "Epoch 358/500\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 4.6090 - accuracy: 0.0000e+00 - val_loss: 4.6136 - val_accuracy: 0.0000e+00\n",
      "Epoch 359/500\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 4.6090 - accuracy: 0.0000e+00 - val_loss: 4.6136 - val_accuracy: 0.0000e+00\n",
      "Epoch 360/500\n",
      "3/3 [==============================] - 0s 40ms/step - loss: 4.6090 - accuracy: 0.0000e+00 - val_loss: 4.6136 - val_accuracy: 0.0000e+00\n",
      "Epoch 361/500\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 4.6090 - accuracy: 0.0000e+00 - val_loss: 4.6136 - val_accuracy: 0.0000e+00\n",
      "Epoch 362/500\n",
      "3/3 [==============================] - 0s 50ms/step - loss: 4.6090 - accuracy: 0.0000e+00 - val_loss: 4.6136 - val_accuracy: 0.0000e+00\n",
      "Epoch 363/500\n",
      "3/3 [==============================] - 0s 38ms/step - loss: 4.6090 - accuracy: 0.0000e+00 - val_loss: 4.6136 - val_accuracy: 0.0000e+00\n",
      "Epoch 364/500\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 4.6090 - accuracy: 0.0000e+00 - val_loss: 4.6136 - val_accuracy: 0.0000e+00\n",
      "Epoch 365/500\n",
      "3/3 [==============================] - 0s 37ms/step - loss: 4.6090 - accuracy: 0.0000e+00 - val_loss: 4.6136 - val_accuracy: 0.0000e+00\n",
      "Epoch 366/500\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 4.6090 - accuracy: 0.0000e+00 - val_loss: 4.6136 - val_accuracy: 0.0000e+00\n",
      "Epoch 367/500\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 4.6090 - accuracy: 0.0000e+00 - val_loss: 4.6136 - val_accuracy: 0.0000e+00\n",
      "Epoch 368/500\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 4.6090 - accuracy: 0.0000e+00 - val_loss: 4.6136 - val_accuracy: 0.0000e+00\n",
      "Epoch 369/500\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 4.6090 - accuracy: 0.0000e+00 - val_loss: 4.6136 - val_accuracy: 0.0000e+00\n",
      "Epoch 370/500\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 4.6090 - accuracy: 0.0000e+00 - val_loss: 4.6136 - val_accuracy: 0.0000e+00\n",
      "Epoch 371/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 4.6090 - accuracy: 0.0000e+00 - val_loss: 4.6136 - val_accuracy: 0.0000e+00\n",
      "Epoch 372/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 4.6090 - accuracy: 0.0000e+00 - val_loss: 4.6136 - val_accuracy: 0.0000e+00\n",
      "Epoch 373/500\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 4.6090 - accuracy: 0.0000e+00 - val_loss: 4.6136 - val_accuracy: 0.0000e+00\n",
      "Epoch 374/500\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 4.6090 - accuracy: 0.0000e+00 - val_loss: 4.6136 - val_accuracy: 0.0000e+00\n",
      "Epoch 375/500\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 4.6090 - accuracy: 0.0000e+00 - val_loss: 4.6136 - val_accuracy: 0.0000e+00\n",
      "Epoch 376/500\n",
      "3/3 [==============================] - 0s 55ms/step - loss: 4.6090 - accuracy: 0.0000e+00 - val_loss: 4.6136 - val_accuracy: 0.0000e+00\n",
      "Epoch 377/500\n",
      "3/3 [==============================] - 0s 40ms/step - loss: 4.6090 - accuracy: 0.0000e+00 - val_loss: 4.6136 - val_accuracy: 0.0000e+00\n",
      "Epoch 378/500\n",
      "3/3 [==============================] - 0s 39ms/step - loss: 4.6090 - accuracy: 0.0000e+00 - val_loss: 4.6136 - val_accuracy: 0.0000e+00\n",
      "Epoch 379/500\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 4.6090 - accuracy: 0.0000e+00 - val_loss: 4.6136 - val_accuracy: 0.0000e+00\n",
      "Epoch 380/500\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 4.6090 - accuracy: 0.0000e+00 - val_loss: 4.6136 - val_accuracy: 0.0000e+00\n",
      "Epoch 381/500\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 4.6090 - accuracy: 0.0000e+00 - val_loss: 4.6136 - val_accuracy: 0.0000e+00\n",
      "Epoch 382/500\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 4.6090 - accuracy: 0.0000e+00 - val_loss: 4.6136 - val_accuracy: 0.0000e+00\n",
      "Epoch 383/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 4.6090 - accuracy: 0.0000e+00 - val_loss: 4.6136 - val_accuracy: 0.0000e+00\n",
      "Epoch 384/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 4.6090 - accuracy: 0.0000e+00 - val_loss: 4.6136 - val_accuracy: 0.0000e+00\n",
      "Epoch 385/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 4.6090 - accuracy: 0.0000e+00 - val_loss: 4.6136 - val_accuracy: 0.0000e+00\n",
      "Epoch 386/500\n",
      "3/3 [==============================] - 0s 37ms/step - loss: 4.6090 - accuracy: 0.0000e+00 - val_loss: 4.6136 - val_accuracy: 0.0000e+00\n",
      "Epoch 387/500\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 4.6090 - accuracy: 0.0000e+00 - val_loss: 4.6136 - val_accuracy: 0.0000e+00\n",
      "Epoch 388/500\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 4.6090 - accuracy: 0.0000e+00 - val_loss: 4.6136 - val_accuracy: 0.0000e+00\n",
      "Epoch 389/500\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 4.6090 - accuracy: 0.0000e+00 - val_loss: 4.6136 - val_accuracy: 0.0000e+00\n",
      "Epoch 390/500\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 4.6090 - accuracy: 0.0000e+00 - val_loss: 4.6136 - val_accuracy: 0.0000e+00\n",
      "Epoch 391/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 4.6090 - accuracy: 0.0000e+00 - val_loss: 4.6136 - val_accuracy: 0.0000e+00\n",
      "Epoch 392/500\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 4.6090 - accuracy: 0.0000e+00 - val_loss: 4.6136 - val_accuracy: 0.0000e+00\n",
      "Epoch 393/500\n",
      "3/3 [==============================] - 0s 53ms/step - loss: 4.6090 - accuracy: 0.0000e+00 - val_loss: 4.6136 - val_accuracy: 0.0000e+00\n",
      "Epoch 394/500\n",
      "3/3 [==============================] - 0s 49ms/step - loss: 4.6090 - accuracy: 0.0000e+00 - val_loss: 4.6136 - val_accuracy: 0.0000e+00\n",
      "Epoch 395/500\n",
      "3/3 [==============================] - 0s 53ms/step - loss: 4.6090 - accuracy: 0.0000e+00 - val_loss: 4.6136 - val_accuracy: 0.0000e+00\n",
      "Epoch 396/500\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 4.6090 - accuracy: 0.0000e+00 - val_loss: 4.6136 - val_accuracy: 0.0000e+00\n",
      "Epoch 397/500\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 4.6090 - accuracy: 0.0000e+00 - val_loss: 4.6136 - val_accuracy: 0.0000e+00\n",
      "Epoch 398/500\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 4.6090 - accuracy: 0.0000e+00 - val_loss: 4.6136 - val_accuracy: 0.0000e+00\n",
      "Epoch 399/500\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 4.6090 - accuracy: 0.0000e+00 - val_loss: 4.6136 - val_accuracy: 0.0000e+00\n",
      "Epoch 400/500\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 4.6090 - accuracy: 0.0000e+00 - val_loss: 4.6136 - val_accuracy: 0.0000e+00\n",
      "Epoch 401/500\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 4.6090 - accuracy: 0.0000e+00 - val_loss: 4.6136 - val_accuracy: 0.0000e+00\n",
      "Epoch 402/500\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 4.6090 - accuracy: 0.0000e+00 - val_loss: 4.6136 - val_accuracy: 0.0000e+00\n",
      "Epoch 403/500\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 4.6090 - accuracy: 0.0000e+00 - val_loss: 4.6136 - val_accuracy: 0.0000e+00\n",
      "Epoch 404/500\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 4.6090 - accuracy: 0.0000e+00 - val_loss: 4.6136 - val_accuracy: 0.0000e+00\n",
      "Epoch 405/500\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 4.6090 - accuracy: 0.0000e+00 - val_loss: 4.6136 - val_accuracy: 0.0000e+00\n",
      "Epoch 406/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 4.6090 - accuracy: 0.0000e+00 - val_loss: 4.6136 - val_accuracy: 0.0000e+00\n",
      "Epoch 407/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 4.6090 - accuracy: 0.0000e+00 - val_loss: 4.6136 - val_accuracy: 0.0000e+00\n",
      "Epoch 408/500\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 4.6090 - accuracy: 0.0000e+00 - val_loss: 4.6136 - val_accuracy: 0.0000e+00\n",
      "Epoch 409/500\n",
      "3/3 [==============================] - 0s 37ms/step - loss: 4.6090 - accuracy: 0.0000e+00 - val_loss: 4.6136 - val_accuracy: 0.0000e+00\n",
      "Epoch 410/500\n",
      "3/3 [==============================] - 0s 39ms/step - loss: 4.6090 - accuracy: 0.0000e+00 - val_loss: 4.6136 - val_accuracy: 0.0000e+00\n",
      "Epoch 411/500\n",
      "3/3 [==============================] - 0s 40ms/step - loss: 4.6090 - accuracy: 0.0000e+00 - val_loss: 4.6136 - val_accuracy: 0.0000e+00\n",
      "Epoch 412/500\n",
      "3/3 [==============================] - 0s 37ms/step - loss: 4.6090 - accuracy: 0.0000e+00 - val_loss: 4.6136 - val_accuracy: 0.0000e+00\n",
      "Epoch 413/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 4.6090 - accuracy: 0.0000e+00 - val_loss: 4.6136 - val_accuracy: 0.0000e+00\n",
      "Epoch 414/500\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 4.6090 - accuracy: 0.0000e+00 - val_loss: 4.6136 - val_accuracy: 0.0000e+00\n",
      "Epoch 415/500\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 4.6090 - accuracy: 0.0000e+00 - val_loss: 4.6136 - val_accuracy: 0.0000e+00\n",
      "Epoch 416/500\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 4.6090 - accuracy: 0.0000e+00 - val_loss: 4.6136 - val_accuracy: 0.0000e+00\n",
      "Epoch 417/500\n",
      "3/3 [==============================] - 0s 38ms/step - loss: 4.6090 - accuracy: 0.0000e+00 - val_loss: 4.6136 - val_accuracy: 0.0000e+00\n",
      "Epoch 418/500\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 4.6090 - accuracy: 0.0000e+00 - val_loss: 4.6136 - val_accuracy: 0.0000e+00\n",
      "Epoch 419/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 4.6090 - accuracy: 0.0000e+00 - val_loss: 4.6136 - val_accuracy: 0.0000e+00\n",
      "Epoch 420/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 4.6090 - accuracy: 0.0000e+00 - val_loss: 4.6136 - val_accuracy: 0.0000e+00\n",
      "Epoch 421/500\n",
      "3/3 [==============================] - 0s 37ms/step - loss: 4.6090 - accuracy: 0.0000e+00 - val_loss: 4.6136 - val_accuracy: 0.0000e+00\n",
      "Epoch 422/500\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 4.6090 - accuracy: 0.0000e+00 - val_loss: 4.6136 - val_accuracy: 0.0000e+00\n",
      "Epoch 423/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 4.6090 - accuracy: 0.0000e+00 - val_loss: 4.6136 - val_accuracy: 0.0000e+00\n",
      "Epoch 424/500\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 4.6090 - accuracy: 0.0000e+00 - val_loss: 4.6136 - val_accuracy: 0.0000e+00\n",
      "Epoch 425/500\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 4.6090 - accuracy: 0.0000e+00 - val_loss: 4.6136 - val_accuracy: 0.0000e+00\n",
      "Epoch 426/500\n",
      "3/3 [==============================] - 0s 57ms/step - loss: 4.6090 - accuracy: 0.0000e+00 - val_loss: 4.6136 - val_accuracy: 0.0000e+00\n",
      "Epoch 427/500\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 4.6090 - accuracy: 0.0000e+00 - val_loss: 4.6136 - val_accuracy: 0.0000e+00\n",
      "Epoch 428/500\n",
      "3/3 [==============================] - 0s 58ms/step - loss: 4.6090 - accuracy: 0.0000e+00 - val_loss: 4.6136 - val_accuracy: 0.0000e+00\n",
      "Epoch 429/500\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 4.6090 - accuracy: 0.0000e+00 - val_loss: 4.6136 - val_accuracy: 0.0000e+00\n",
      "Epoch 430/500\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 4.6090 - accuracy: 0.0000e+00 - val_loss: 4.6136 - val_accuracy: 0.0000e+00\n",
      "Epoch 431/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 4.6090 - accuracy: 0.0000e+00 - val_loss: 4.6136 - val_accuracy: 0.0000e+00\n",
      "Epoch 432/500\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 4.6090 - accuracy: 0.0000e+00 - val_loss: 4.6136 - val_accuracy: 0.0000e+00\n",
      "Epoch 433/500\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 4.6090 - accuracy: 0.0000e+00 - val_loss: 4.6136 - val_accuracy: 0.0000e+00\n",
      "Epoch 434/500\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 4.6090 - accuracy: 0.0000e+00 - val_loss: 4.6136 - val_accuracy: 0.0000e+00\n",
      "Epoch 435/500\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 4.6090 - accuracy: 0.0000e+00 - val_loss: 4.6136 - val_accuracy: 0.0000e+00\n",
      "Epoch 436/500\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 4.6090 - accuracy: 0.0000e+00 - val_loss: 4.6136 - val_accuracy: 0.0000e+00\n",
      "Epoch 437/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 4.6090 - accuracy: 0.0000e+00 - val_loss: 4.6136 - val_accuracy: 0.0000e+00\n",
      "Epoch 438/500\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 4.6090 - accuracy: 0.0000e+00 - val_loss: 4.6136 - val_accuracy: 0.0000e+00\n",
      "Epoch 439/500\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 4.6090 - accuracy: 0.0000e+00 - val_loss: 4.6136 - val_accuracy: 0.0000e+00\n",
      "Epoch 440/500\n",
      "3/3 [==============================] - 0s 38ms/step - loss: 4.6090 - accuracy: 0.0000e+00 - val_loss: 4.6136 - val_accuracy: 0.0000e+00\n",
      "Epoch 441/500\n",
      "3/3 [==============================] - 0s 39ms/step - loss: 4.6090 - accuracy: 0.0000e+00 - val_loss: 4.6136 - val_accuracy: 0.0000e+00\n",
      "Epoch 442/500\n",
      "3/3 [==============================] - 0s 73ms/step - loss: 4.6090 - accuracy: 0.0000e+00 - val_loss: 4.6136 - val_accuracy: 0.0000e+00\n",
      "Epoch 443/500\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 4.6090 - accuracy: 0.0000e+00 - val_loss: 4.6136 - val_accuracy: 0.0000e+00\n",
      "Epoch 444/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 4.6090 - accuracy: 0.0000e+00 - val_loss: 4.6136 - val_accuracy: 0.0000e+00\n",
      "Epoch 445/500\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 4.6090 - accuracy: 0.0000e+00 - val_loss: 4.6136 - val_accuracy: 0.0000e+00\n",
      "Epoch 446/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 4.6090 - accuracy: 0.0000e+00 - val_loss: 4.6136 - val_accuracy: 0.0000e+00\n",
      "Epoch 447/500\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 4.6090 - accuracy: 0.0000e+00 - val_loss: 4.6136 - val_accuracy: 0.0000e+00\n",
      "Epoch 448/500\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 4.6090 - accuracy: 0.0000e+00 - val_loss: 4.6136 - val_accuracy: 0.0000e+00\n",
      "Epoch 449/500\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 4.6090 - accuracy: 0.0000e+00 - val_loss: 4.6136 - val_accuracy: 0.0000e+00\n",
      "Epoch 450/500\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 4.6090 - accuracy: 0.0000e+00 - val_loss: 4.6136 - val_accuracy: 0.0000e+00\n",
      "Epoch 451/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 4.6090 - accuracy: 0.0000e+00 - val_loss: 4.6136 - val_accuracy: 0.0000e+00\n",
      "Epoch 452/500\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 4.6090 - accuracy: 0.0000e+00 - val_loss: 4.6136 - val_accuracy: 0.0000e+00\n",
      "Epoch 453/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 4.6090 - accuracy: 0.0000e+00 - val_loss: 4.6136 - val_accuracy: 0.0000e+00\n",
      "Epoch 454/500\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 4.6090 - accuracy: 0.0000e+00 - val_loss: 4.6136 - val_accuracy: 0.0000e+00\n",
      "Epoch 455/500\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 4.6090 - accuracy: 0.0000e+00 - val_loss: 4.6136 - val_accuracy: 0.0000e+00\n",
      "Epoch 456/500\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 4.6090 - accuracy: 0.0000e+00 - val_loss: 4.6136 - val_accuracy: 0.0000e+00\n",
      "Epoch 457/500\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 4.6090 - accuracy: 0.0000e+00 - val_loss: 4.6136 - val_accuracy: 0.0000e+00\n",
      "Epoch 458/500\n",
      "3/3 [==============================] - 0s 48ms/step - loss: 4.6090 - accuracy: 0.0000e+00 - val_loss: 4.6136 - val_accuracy: 0.0000e+00\n",
      "Epoch 459/500\n",
      "3/3 [==============================] - 0s 52ms/step - loss: 4.6090 - accuracy: 0.0000e+00 - val_loss: 4.6136 - val_accuracy: 0.0000e+00\n",
      "Epoch 460/500\n",
      "3/3 [==============================] - 0s 39ms/step - loss: 4.6090 - accuracy: 0.0000e+00 - val_loss: 4.6136 - val_accuracy: 0.0000e+00\n",
      "Epoch 461/500\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 4.6090 - accuracy: 0.0000e+00 - val_loss: 4.6136 - val_accuracy: 0.0000e+00\n",
      "Epoch 462/500\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 4.6090 - accuracy: 0.0000e+00 - val_loss: 4.6136 - val_accuracy: 0.0000e+00\n",
      "Epoch 463/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 4.6090 - accuracy: 0.0000e+00 - val_loss: 4.6136 - val_accuracy: 0.0000e+00\n",
      "Epoch 464/500\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 4.6090 - accuracy: 0.0000e+00 - val_loss: 4.6136 - val_accuracy: 0.0000e+00\n",
      "Epoch 465/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 4.6090 - accuracy: 0.0000e+00 - val_loss: 4.6136 - val_accuracy: 0.0000e+00\n",
      "Epoch 466/500\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 4.6090 - accuracy: 0.0000e+00 - val_loss: 4.6136 - val_accuracy: 0.0000e+00\n",
      "Epoch 467/500\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 4.6090 - accuracy: 0.0000e+00 - val_loss: 4.6136 - val_accuracy: 0.0000e+00\n",
      "Epoch 468/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 4.6090 - accuracy: 0.0000e+00 - val_loss: 4.6136 - val_accuracy: 0.0000e+00\n",
      "Epoch 469/500\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 4.6090 - accuracy: 0.0000e+00 - val_loss: 4.6136 - val_accuracy: 0.0000e+00\n",
      "Epoch 470/500\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 4.6090 - accuracy: 0.0000e+00 - val_loss: 4.6136 - val_accuracy: 0.0000e+00\n",
      "Epoch 471/500\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 4.6090 - accuracy: 0.0000e+00 - val_loss: 4.6136 - val_accuracy: 0.0000e+00\n",
      "Epoch 472/500\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 4.6090 - accuracy: 0.0000e+00 - val_loss: 4.6136 - val_accuracy: 0.0000e+00\n",
      "Epoch 473/500\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 4.6090 - accuracy: 0.0000e+00 - val_loss: 4.6136 - val_accuracy: 0.0000e+00\n",
      "Epoch 474/500\n",
      "3/3 [==============================] - 0s 50ms/step - loss: 4.6090 - accuracy: 0.0000e+00 - val_loss: 4.6136 - val_accuracy: 0.0000e+00\n",
      "Epoch 475/500\n",
      "3/3 [==============================] - 0s 63ms/step - loss: 4.6090 - accuracy: 0.0000e+00 - val_loss: 4.6136 - val_accuracy: 0.0000e+00\n",
      "Epoch 476/500\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 4.6090 - accuracy: 0.0000e+00 - val_loss: 4.6136 - val_accuracy: 0.0000e+00\n",
      "Epoch 477/500\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 4.6090 - accuracy: 0.0000e+00 - val_loss: 4.6136 - val_accuracy: 0.0000e+00\n",
      "Epoch 478/500\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 4.6090 - accuracy: 0.0000e+00 - val_loss: 4.6136 - val_accuracy: 0.0000e+00\n",
      "Epoch 479/500\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 4.6090 - accuracy: 0.0000e+00 - val_loss: 4.6136 - val_accuracy: 0.0000e+00\n",
      "Epoch 480/500\n",
      "3/3 [==============================] - 0s 39ms/step - loss: 4.6090 - accuracy: 0.0000e+00 - val_loss: 4.6136 - val_accuracy: 0.0000e+00\n",
      "Epoch 481/500\n",
      "3/3 [==============================] - 0s 38ms/step - loss: 4.6090 - accuracy: 0.0000e+00 - val_loss: 4.6136 - val_accuracy: 0.0000e+00\n",
      "Epoch 482/500\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 4.6090 - accuracy: 0.0000e+00 - val_loss: 4.6136 - val_accuracy: 0.0000e+00\n",
      "Epoch 483/500\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 4.6090 - accuracy: 0.0000e+00 - val_loss: 4.6136 - val_accuracy: 0.0000e+00\n",
      "Epoch 484/500\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 4.6090 - accuracy: 0.0000e+00 - val_loss: 4.6136 - val_accuracy: 0.0000e+00\n",
      "Epoch 485/500\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 4.6090 - accuracy: 0.0000e+00 - val_loss: 4.6136 - val_accuracy: 0.0000e+00\n",
      "Epoch 486/500\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 4.6090 - accuracy: 0.0000e+00 - val_loss: 4.6136 - val_accuracy: 0.0000e+00\n",
      "Epoch 487/500\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 4.6090 - accuracy: 0.0000e+00 - val_loss: 4.6136 - val_accuracy: 0.0000e+00\n",
      "Epoch 488/500\n",
      "3/3 [==============================] - 0s 38ms/step - loss: 4.6090 - accuracy: 0.0000e+00 - val_loss: 4.6136 - val_accuracy: 0.0000e+00\n",
      "Epoch 489/500\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 4.6090 - accuracy: 0.0000e+00 - val_loss: 4.6136 - val_accuracy: 0.0000e+00\n",
      "Epoch 490/500\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 4.6090 - accuracy: 0.0000e+00 - val_loss: 4.6136 - val_accuracy: 0.0000e+00\n",
      "Epoch 491/500\n",
      "3/3 [==============================] - 0s 39ms/step - loss: 4.6090 - accuracy: 0.0000e+00 - val_loss: 4.6136 - val_accuracy: 0.0000e+00\n",
      "Epoch 492/500\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 4.6090 - accuracy: 0.0000e+00 - val_loss: 4.6136 - val_accuracy: 0.0000e+00\n",
      "Epoch 493/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 4.6090 - accuracy: 0.0000e+00 - val_loss: 4.6136 - val_accuracy: 0.0000e+00\n",
      "Epoch 494/500\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 4.6090 - accuracy: 0.0000e+00 - val_loss: 4.6136 - val_accuracy: 0.0000e+00\n",
      "Epoch 495/500\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 4.6090 - accuracy: 0.0000e+00 - val_loss: 4.6136 - val_accuracy: 0.0000e+00\n",
      "Epoch 496/500\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 4.6090 - accuracy: 0.0000e+00 - val_loss: 4.6136 - val_accuracy: 0.0000e+00\n",
      "Epoch 497/500\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 4.6090 - accuracy: 0.0000e+00 - val_loss: 4.6136 - val_accuracy: 0.0000e+00\n",
      "Epoch 498/500\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 4.6090 - accuracy: 0.0000e+00 - val_loss: 4.6136 - val_accuracy: 0.0000e+00\n",
      "Epoch 499/500\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 4.6090 - accuracy: 0.0000e+00 - val_loss: 4.6136 - val_accuracy: 0.0000e+00\n",
      "Epoch 500/500\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 4.6090 - accuracy: 0.0000e+00 - val_loss: 4.6136 - val_accuracy: 0.0000e+00\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40022060-1380-469e-9f9f-30bc1eb9c8fe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62bc37f5-6db0-441f-8516-d2dfe925864e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da786542-da7a-4e2c-a703-acce112b420d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "941d1ff4-b1ca-4a04-87d1-c7ba54bfe035",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(max_depth=320, random_state=1)"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "max_depth = 320\n",
    "model = RandomForestClassifier(n_estimators=100, max_depth=max_depth, random_state=1)\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0411e0e1-3b13-460e-b648-90f2831b501d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "ccd27cff-9db8-419d-941f-23bbcd16d73b",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = cross_val_score(model, X_train, y_train, cv=10)\n",
    "scores2 = cross_val_score(model, X_test, y_test, cv=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "6f7727df-688b-4816-94dc-adf31a0b94ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AcurÃ¡cia de treino 24.46%  com desvio padrÃ£o de 0.04\n",
      "\n",
      "AcurÃ¡cia de teste 24.18%  com desvio padrÃ£o de 0.09\n"
     ]
    }
   ],
   "source": [
    "print(\"AcurÃ¡cia de treino %0.2f%%  com desvio padrÃ£o de %0.2f\" % (scores.mean()*100, scores.std()))\n",
    "print()\n",
    "print(\"AcurÃ¡cia de teste %0.2f%%  com desvio padrÃ£o de %0.2f\" % (scores2.mean()*100, scores2.std()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "7da1c2aa-1ead-40cf-8c16-b4cec16bc5db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 576x576 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_confusion_matrix(model, X_train, y_train)\n",
    "plt.figure(figsize=(8,8))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "7b27f49f-5f0c-4e3b-8cb3-7111a8f23a71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 576x576 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_confusion_matrix(model, X_test, y_test)\n",
    "plt.figure(figsize=(8,8))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5fc7ede8-f325-4de4-94b5-5a83f3119fad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1678832116788321"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "c59e3b2e-3e07-489e-b81f-b71c0c63e0eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.0, 0.2846715328467153)"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_pred = model.predict(X_train)\n",
    "y_test_pred = model.predict(X_test)\n",
    "\n",
    "accuracy_score(y_train, y_train_pred), accuracy_score(y_test, y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "982e9859-1307-406f-b4a3-251bb89dc3df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        precision    recall  f1-score   support\n",
      "\n",
      "MUITO ABAIXO DO NORMAL       0.38      0.29      0.33        28\n",
      "      ABAIXO DO NORMAL       0.13      0.22      0.16        23\n",
      "                NORMAL       0.34      0.44      0.38        39\n",
      "       ACIMA DO NORMAL       0.21      0.14      0.17        29\n",
      " MUITO ACIMA DO NORMAL       0.56      0.28      0.37        18\n",
      "\n",
      "              accuracy                           0.28       137\n",
      "             macro avg       0.32      0.27      0.28       137\n",
      "          weighted avg       0.31      0.28      0.29       137\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, y_test_pred, target_names=['MUITO ABAIXO DO NORMAL', 'ABAIXO DO NORMAL', 'NORMAL', 'ACIMA DO NORMAL', 'MUITO ACIMA DO NORMAL']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "ae9772aa-cf17-43b2-b14e-b026ca12ba9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TSM-AN1(1)</th>\n",
       "      <th>TSM-AN2(1)</th>\n",
       "      <th>TSM-AN3(1)</th>\n",
       "      <th>TSM-AN4(1)</th>\n",
       "      <th>TSM-AN5(1)</th>\n",
       "      <th>TSM-AN6(1)</th>\n",
       "      <th>TSM-AN7(1)</th>\n",
       "      <th>TSM-AN8(1)</th>\n",
       "      <th>TSM-AN9(1)</th>\n",
       "      <th>TSM-AN10(1)</th>\n",
       "      <th>...</th>\n",
       "      <th>PRM15</th>\n",
       "      <th>PRM16</th>\n",
       "      <th>PRM17</th>\n",
       "      <th>PRM18</th>\n",
       "      <th>PRM19</th>\n",
       "      <th>PRM20</th>\n",
       "      <th>PRM21</th>\n",
       "      <th>PRM22</th>\n",
       "      <th>PRM23</th>\n",
       "      <th>PRM24</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Data</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1983-01-01</th>\n",
       "      <td>26.2016</td>\n",
       "      <td>25.5037</td>\n",
       "      <td>24.5607</td>\n",
       "      <td>23.3048</td>\n",
       "      <td>26.8786</td>\n",
       "      <td>26.0494</td>\n",
       "      <td>25.4426</td>\n",
       "      <td>24.8366</td>\n",
       "      <td>26.9741</td>\n",
       "      <td>26.8861</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1983-02-01</th>\n",
       "      <td>25.5559</td>\n",
       "      <td>24.7772</td>\n",
       "      <td>23.9713</td>\n",
       "      <td>22.2504</td>\n",
       "      <td>26.4919</td>\n",
       "      <td>25.4557</td>\n",
       "      <td>24.4777</td>\n",
       "      <td>23.8309</td>\n",
       "      <td>26.5949</td>\n",
       "      <td>26.4474</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1983-03-01</th>\n",
       "      <td>25.3834</td>\n",
       "      <td>24.7222</td>\n",
       "      <td>23.6243</td>\n",
       "      <td>22.1148</td>\n",
       "      <td>26.3955</td>\n",
       "      <td>25.2389</td>\n",
       "      <td>24.3920</td>\n",
       "      <td>23.8205</td>\n",
       "      <td>26.9062</td>\n",
       "      <td>26.6183</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1983-04-01</th>\n",
       "      <td>25.7558</td>\n",
       "      <td>25.0295</td>\n",
       "      <td>23.9576</td>\n",
       "      <td>22.7620</td>\n",
       "      <td>26.7540</td>\n",
       "      <td>25.7155</td>\n",
       "      <td>25.0205</td>\n",
       "      <td>24.6016</td>\n",
       "      <td>27.4812</td>\n",
       "      <td>27.4107</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1983-05-01</th>\n",
       "      <td>26.1880</td>\n",
       "      <td>25.6453</td>\n",
       "      <td>24.6446</td>\n",
       "      <td>22.8974</td>\n",
       "      <td>27.2128</td>\n",
       "      <td>26.5240</td>\n",
       "      <td>25.6601</td>\n",
       "      <td>24.8870</td>\n",
       "      <td>27.6576</td>\n",
       "      <td>27.8526</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-08-01</th>\n",
       "      <td>28.4059</td>\n",
       "      <td>27.0806</td>\n",
       "      <td>25.8670</td>\n",
       "      <td>24.8474</td>\n",
       "      <td>28.5955</td>\n",
       "      <td>27.6551</td>\n",
       "      <td>27.2614</td>\n",
       "      <td>27.1523</td>\n",
       "      <td>28.9170</td>\n",
       "      <td>28.4266</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-09-01</th>\n",
       "      <td>28.4721</td>\n",
       "      <td>27.3896</td>\n",
       "      <td>26.5677</td>\n",
       "      <td>26.1410</td>\n",
       "      <td>28.9465</td>\n",
       "      <td>28.2160</td>\n",
       "      <td>27.9531</td>\n",
       "      <td>27.6894</td>\n",
       "      <td>29.2388</td>\n",
       "      <td>29.0570</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-10-01</th>\n",
       "      <td>28.6614</td>\n",
       "      <td>27.6689</td>\n",
       "      <td>27.1493</td>\n",
       "      <td>27.4002</td>\n",
       "      <td>29.1244</td>\n",
       "      <td>28.3055</td>\n",
       "      <td>28.1015</td>\n",
       "      <td>27.8288</td>\n",
       "      <td>28.9657</td>\n",
       "      <td>28.9848</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-11-01</th>\n",
       "      <td>28.4023</td>\n",
       "      <td>27.6131</td>\n",
       "      <td>27.3763</td>\n",
       "      <td>27.2015</td>\n",
       "      <td>28.9573</td>\n",
       "      <td>28.2666</td>\n",
       "      <td>27.9994</td>\n",
       "      <td>28.2323</td>\n",
       "      <td>29.1334</td>\n",
       "      <td>29.0081</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-12-01</th>\n",
       "      <td>27.6801</td>\n",
       "      <td>27.0970</td>\n",
       "      <td>26.6494</td>\n",
       "      <td>26.2036</td>\n",
       "      <td>28.3641</td>\n",
       "      <td>27.7229</td>\n",
       "      <td>27.4578</td>\n",
       "      <td>27.9825</td>\n",
       "      <td>28.6752</td>\n",
       "      <td>28.4644</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>456 rows Ã— 1176 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            TSM-AN1(1)  TSM-AN2(1)  TSM-AN3(1)  TSM-AN4(1)  TSM-AN5(1)  \\\n",
       "Data                                                                     \n",
       "1983-01-01     26.2016     25.5037     24.5607     23.3048     26.8786   \n",
       "1983-02-01     25.5559     24.7772     23.9713     22.2504     26.4919   \n",
       "1983-03-01     25.3834     24.7222     23.6243     22.1148     26.3955   \n",
       "1983-04-01     25.7558     25.0295     23.9576     22.7620     26.7540   \n",
       "1983-05-01     26.1880     25.6453     24.6446     22.8974     27.2128   \n",
       "...                ...         ...         ...         ...         ...   \n",
       "2020-08-01     28.4059     27.0806     25.8670     24.8474     28.5955   \n",
       "2020-09-01     28.4721     27.3896     26.5677     26.1410     28.9465   \n",
       "2020-10-01     28.6614     27.6689     27.1493     27.4002     29.1244   \n",
       "2020-11-01     28.4023     27.6131     27.3763     27.2015     28.9573   \n",
       "2020-12-01     27.6801     27.0970     26.6494     26.2036     28.3641   \n",
       "\n",
       "            TSM-AN6(1)  TSM-AN7(1)  TSM-AN8(1)  TSM-AN9(1)  TSM-AN10(1)  ...  \\\n",
       "Data                                                                     ...   \n",
       "1983-01-01     26.0494     25.4426     24.8366     26.9741      26.8861  ...   \n",
       "1983-02-01     25.4557     24.4777     23.8309     26.5949      26.4474  ...   \n",
       "1983-03-01     25.2389     24.3920     23.8205     26.9062      26.6183  ...   \n",
       "1983-04-01     25.7155     25.0205     24.6016     27.4812      27.4107  ...   \n",
       "1983-05-01     26.5240     25.6601     24.8870     27.6576      27.8526  ...   \n",
       "...                ...         ...         ...         ...          ...  ...   \n",
       "2020-08-01     27.6551     27.2614     27.1523     28.9170      28.4266  ...   \n",
       "2020-09-01     28.2160     27.9531     27.6894     29.2388      29.0570  ...   \n",
       "2020-10-01     28.3055     28.1015     27.8288     28.9657      28.9848  ...   \n",
       "2020-11-01     28.2666     27.9994     28.2323     29.1334      29.0081  ...   \n",
       "2020-12-01     27.7229     27.4578     27.9825     28.6752      28.4644  ...   \n",
       "\n",
       "            PRM15  PRM16  PRM17  PRM18  PRM19  PRM20  PRM21  PRM22  PRM23  \\\n",
       "Data                                                                        \n",
       "1983-01-01      2      2      2      3      1      1      2      2      3   \n",
       "1983-02-01      1      1      2      2      2      2      1      0      1   \n",
       "1983-03-01      2      2      2      2      2      2      2      2      2   \n",
       "1983-04-01      0      0      0      0      0      0      0      0      0   \n",
       "1983-05-01      0      0      0      0      0      0      0      0      0   \n",
       "...           ...    ...    ...    ...    ...    ...    ...    ...    ...   \n",
       "2020-08-01      2      3      2      2      0      1      2      3      3   \n",
       "2020-09-01      0      2      4      3      0      0      0      0      1   \n",
       "2020-10-01      0      0      1      1      1      0      0      0      0   \n",
       "2020-11-01      3      4      4      4      2      3      3      4      4   \n",
       "2020-12-01      0      0      1      0      0      0      0      0      0   \n",
       "\n",
       "            PRM24  \n",
       "Data               \n",
       "1983-01-01      4  \n",
       "1983-02-01      2  \n",
       "1983-03-01      2  \n",
       "1983-04-01      0  \n",
       "1983-05-01      0  \n",
       "...           ...  \n",
       "2020-08-01      2  \n",
       "2020-09-01      0  \n",
       "2020-10-01      0  \n",
       "2020-11-01      3  \n",
       "2020-12-01      0  \n",
       "\n",
       "[456 rows x 1176 columns]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data2 = pd.read_excel('tsmxprecipitacao.xlsx', index_col=[0]).dropna()\n",
    "data2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "7dd01958-c732-4d9a-832b-72d23babb3fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = gen_fit_test_data(data2, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "481903e4-8d25-4b7d-81f4-f4b3009ab228",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(criterion='entropy', max_depth=2000, min_samples_split=3,\n",
       "                       random_state=1)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_depth = 2000\n",
    "model = RandomForestClassifier(n_estimators=100, max_depth=max_depth, random_state=1, min_samples_split=3, criterion=\"entropy\")\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "72a4fa4e-c997-4f1f-8a53-ba0151995e98",
   "metadata": {},
   "outputs": [],
   "source": [
    "scores = cross_val_score(model, X_train, y_train, cv=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "0f6e07b0-d9ba-478a-85b2-6fd02ba16464",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.21314484126984126"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(scores) / len(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "cbb096e9-e9d8-4aa1-80ad-c9f336cdfd22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TSM-AN1(1)</th>\n",
       "      <th>TSM-AN2(1)</th>\n",
       "      <th>TSM-AN3(1)</th>\n",
       "      <th>TSM-AN4(1)</th>\n",
       "      <th>TSM-AN5(1)</th>\n",
       "      <th>TSM-AN6(1)</th>\n",
       "      <th>TSM-AN7(1)</th>\n",
       "      <th>TSM-AN8(1)</th>\n",
       "      <th>TSM-AN9(1)</th>\n",
       "      <th>TSM-AN10(1)</th>\n",
       "      <th>...</th>\n",
       "      <th>PRM15</th>\n",
       "      <th>PRM16</th>\n",
       "      <th>PRM17</th>\n",
       "      <th>PRM18</th>\n",
       "      <th>PRM19</th>\n",
       "      <th>PRM20</th>\n",
       "      <th>PRM21</th>\n",
       "      <th>PRM22</th>\n",
       "      <th>PRM23</th>\n",
       "      <th>PRM24</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Data</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1983-01-01</th>\n",
       "      <td>26.2016</td>\n",
       "      <td>25.5037</td>\n",
       "      <td>24.5607</td>\n",
       "      <td>23.3048</td>\n",
       "      <td>26.8786</td>\n",
       "      <td>26.0494</td>\n",
       "      <td>25.4426</td>\n",
       "      <td>24.8366</td>\n",
       "      <td>26.9741</td>\n",
       "      <td>26.8861</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1983-02-01</th>\n",
       "      <td>25.5559</td>\n",
       "      <td>24.7772</td>\n",
       "      <td>23.9713</td>\n",
       "      <td>22.2504</td>\n",
       "      <td>26.4919</td>\n",
       "      <td>25.4557</td>\n",
       "      <td>24.4777</td>\n",
       "      <td>23.8309</td>\n",
       "      <td>26.5949</td>\n",
       "      <td>26.4474</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1983-03-01</th>\n",
       "      <td>25.3834</td>\n",
       "      <td>24.7222</td>\n",
       "      <td>23.6243</td>\n",
       "      <td>22.1148</td>\n",
       "      <td>26.3955</td>\n",
       "      <td>25.2389</td>\n",
       "      <td>24.3920</td>\n",
       "      <td>23.8205</td>\n",
       "      <td>26.9062</td>\n",
       "      <td>26.6183</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1983-04-01</th>\n",
       "      <td>25.7558</td>\n",
       "      <td>25.0295</td>\n",
       "      <td>23.9576</td>\n",
       "      <td>22.7620</td>\n",
       "      <td>26.7540</td>\n",
       "      <td>25.7155</td>\n",
       "      <td>25.0205</td>\n",
       "      <td>24.6016</td>\n",
       "      <td>27.4812</td>\n",
       "      <td>27.4107</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1983-05-01</th>\n",
       "      <td>26.1880</td>\n",
       "      <td>25.6453</td>\n",
       "      <td>24.6446</td>\n",
       "      <td>22.8974</td>\n",
       "      <td>27.2128</td>\n",
       "      <td>26.5240</td>\n",
       "      <td>25.6601</td>\n",
       "      <td>24.8870</td>\n",
       "      <td>27.6576</td>\n",
       "      <td>27.8526</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-08-01</th>\n",
       "      <td>28.4059</td>\n",
       "      <td>27.0806</td>\n",
       "      <td>25.8670</td>\n",
       "      <td>24.8474</td>\n",
       "      <td>28.5955</td>\n",
       "      <td>27.6551</td>\n",
       "      <td>27.2614</td>\n",
       "      <td>27.1523</td>\n",
       "      <td>28.9170</td>\n",
       "      <td>28.4266</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-09-01</th>\n",
       "      <td>28.4721</td>\n",
       "      <td>27.3896</td>\n",
       "      <td>26.5677</td>\n",
       "      <td>26.1410</td>\n",
       "      <td>28.9465</td>\n",
       "      <td>28.2160</td>\n",
       "      <td>27.9531</td>\n",
       "      <td>27.6894</td>\n",
       "      <td>29.2388</td>\n",
       "      <td>29.0570</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-10-01</th>\n",
       "      <td>28.6614</td>\n",
       "      <td>27.6689</td>\n",
       "      <td>27.1493</td>\n",
       "      <td>27.4002</td>\n",
       "      <td>29.1244</td>\n",
       "      <td>28.3055</td>\n",
       "      <td>28.1015</td>\n",
       "      <td>27.8288</td>\n",
       "      <td>28.9657</td>\n",
       "      <td>28.9848</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-11-01</th>\n",
       "      <td>28.4023</td>\n",
       "      <td>27.6131</td>\n",
       "      <td>27.3763</td>\n",
       "      <td>27.2015</td>\n",
       "      <td>28.9573</td>\n",
       "      <td>28.2666</td>\n",
       "      <td>27.9994</td>\n",
       "      <td>28.2323</td>\n",
       "      <td>29.1334</td>\n",
       "      <td>29.0081</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-12-01</th>\n",
       "      <td>27.6801</td>\n",
       "      <td>27.0970</td>\n",
       "      <td>26.6494</td>\n",
       "      <td>26.2036</td>\n",
       "      <td>28.3641</td>\n",
       "      <td>27.7229</td>\n",
       "      <td>27.4578</td>\n",
       "      <td>27.9825</td>\n",
       "      <td>28.6752</td>\n",
       "      <td>28.4644</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>456 rows Ã— 1176 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            TSM-AN1(1)  TSM-AN2(1)  TSM-AN3(1)  TSM-AN4(1)  TSM-AN5(1)  \\\n",
       "Data                                                                     \n",
       "1983-01-01     26.2016     25.5037     24.5607     23.3048     26.8786   \n",
       "1983-02-01     25.5559     24.7772     23.9713     22.2504     26.4919   \n",
       "1983-03-01     25.3834     24.7222     23.6243     22.1148     26.3955   \n",
       "1983-04-01     25.7558     25.0295     23.9576     22.7620     26.7540   \n",
       "1983-05-01     26.1880     25.6453     24.6446     22.8974     27.2128   \n",
       "...                ...         ...         ...         ...         ...   \n",
       "2020-08-01     28.4059     27.0806     25.8670     24.8474     28.5955   \n",
       "2020-09-01     28.4721     27.3896     26.5677     26.1410     28.9465   \n",
       "2020-10-01     28.6614     27.6689     27.1493     27.4002     29.1244   \n",
       "2020-11-01     28.4023     27.6131     27.3763     27.2015     28.9573   \n",
       "2020-12-01     27.6801     27.0970     26.6494     26.2036     28.3641   \n",
       "\n",
       "            TSM-AN6(1)  TSM-AN7(1)  TSM-AN8(1)  TSM-AN9(1)  TSM-AN10(1)  ...  \\\n",
       "Data                                                                     ...   \n",
       "1983-01-01     26.0494     25.4426     24.8366     26.9741      26.8861  ...   \n",
       "1983-02-01     25.4557     24.4777     23.8309     26.5949      26.4474  ...   \n",
       "1983-03-01     25.2389     24.3920     23.8205     26.9062      26.6183  ...   \n",
       "1983-04-01     25.7155     25.0205     24.6016     27.4812      27.4107  ...   \n",
       "1983-05-01     26.5240     25.6601     24.8870     27.6576      27.8526  ...   \n",
       "...                ...         ...         ...         ...          ...  ...   \n",
       "2020-08-01     27.6551     27.2614     27.1523     28.9170      28.4266  ...   \n",
       "2020-09-01     28.2160     27.9531     27.6894     29.2388      29.0570  ...   \n",
       "2020-10-01     28.3055     28.1015     27.8288     28.9657      28.9848  ...   \n",
       "2020-11-01     28.2666     27.9994     28.2323     29.1334      29.0081  ...   \n",
       "2020-12-01     27.7229     27.4578     27.9825     28.6752      28.4644  ...   \n",
       "\n",
       "            PRM15  PRM16  PRM17  PRM18  PRM19  PRM20  PRM21  PRM22  PRM23  \\\n",
       "Data                                                                        \n",
       "1983-01-01      2      2      2      3      1      1      2      2      3   \n",
       "1983-02-01      1      1      2      2      2      2      1      0      1   \n",
       "1983-03-01      2      2      2      2      2      2      2      2      2   \n",
       "1983-04-01      0      0      0      0      0      0      0      0      0   \n",
       "1983-05-01      0      0      0      0      0      0      0      0      0   \n",
       "...           ...    ...    ...    ...    ...    ...    ...    ...    ...   \n",
       "2020-08-01      2      3      2      2      0      1      2      3      3   \n",
       "2020-09-01      0      2      4      3      0      0      0      0      1   \n",
       "2020-10-01      0      0      1      1      1      0      0      0      0   \n",
       "2020-11-01      3      4      4      4      2      3      3      4      4   \n",
       "2020-12-01      0      0      1      0      0      0      0      0      0   \n",
       "\n",
       "            PRM24  \n",
       "Data               \n",
       "1983-01-01      4  \n",
       "1983-02-01      2  \n",
       "1983-03-01      2  \n",
       "1983-04-01      0  \n",
       "1983-05-01      0  \n",
       "...           ...  \n",
       "2020-08-01      2  \n",
       "2020-09-01      0  \n",
       "2020-10-01      0  \n",
       "2020-11-01      3  \n",
       "2020-12-01      0  \n",
       "\n",
       "[456 rows x 1176 columns]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeb6db47-c734-42a8-a867-610b5ec23960",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
